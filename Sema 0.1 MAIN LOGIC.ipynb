{"cells":[{"cell_type":"markdown","metadata":{"id":"0N0o6eLorq6K","deepnote_app_block_visible":true,"cell_id":"10feb2e288194cd4be7eadcd85a07f4d","deepnote_cell_type":"markdown"},"source":"# SEMA Semantic Agent. Arxiv search powered by LLMs","block_group":"5433b36a96a84de4a5e7f3fd312964bc"},{"cell_type":"markdown","metadata":{"id":"DZtnkrGgcPZd","deepnote_app_block_visible":true,"cell_id":"8fd14e7465dc48159f0d4493170ace6a","deepnote_cell_type":"markdown"},"source":"What it does:\n- Convert user query into keyword search queries\n- Google search top 10 results with SERP API\n- Scrape html for each result, convert to markdown\n- Structure output using function calling -> json to get paper, title\n- Call arxiv to get paper, abstract, metadata\n- Call Google Scholar to get citations, ...\n- Use LLM to answer user query based on the paper, evaluate answer relevance\n- Rank results based on citations, relevance to user query\n- Print results in structured format, give links to download, or to use in notebook LM","block_group":"8ac24ea88e3c4de9bd85ad5825ecaadf"},{"cell_type":"markdown","metadata":{"id":"xLlMdqkpwwFV","deepnote_app_block_visible":true,"cell_id":"9b284d467385405697127d5f6d19d5dc","deepnote_cell_type":"markdown"},"source":"# Setup","block_group":"a4064cec25cc4539b8783c1c50a4ff7b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"a7aa33f707ad49f290f4ac570e4994a3","deepnote_cell_type":"text-cell-p"},"source":"load secret variables","block_group":"61701f62befd4d9188a9d672a2342f2c"},{"cell_type":"code","metadata":{"id":"udzkaNSJlQtZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8afda221-8b65-4c34-cb39-a98c4c8f5957","source_hash":"879c255","execution_start":1709953213815,"execution_millis":264,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"f544246d8b4b4dad9a505de9fd73b72e","deepnote_cell_type":"code"},"source":"import os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nopenai_api_key = os.environ.get(\"OPENAI_API_KEY\")\nserp_api_key = os.environ.get(\"SERP_API_KEY\")\ngemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\nllamaindex_api_key = os.environ.get(\"LLAMAINDEX_API_KEY\")\n\n# Hide part of the key\nopenai_api_key_hidden = openai_api_key[:3] + \"*\" * (len(openai_api_key) - 6) + openai_api_key[-3:]\nserp_api_key_hidden = serp_api_key[:3] + \"*\" * (len(serp_api_key) - 6) + serp_api_key[-3:]\ngemini_api_key_hidden = gemini_api_key[:3] + \"*\" * (len(gemini_api_key) - 6) + gemini_api_key[-3:]\nllamaindex_api_key_hidden = llamaindex_api_key[:3] + \"*\" * (len(llamaindex_api_key) - 6) + llamaindex_api_key[-3:]\n\n# Print the hidden keys\nprint(f\"OpenAI API Key (hidden): {openai_api_key_hidden}\")\nprint(f\"Serp API Key (hidden): {serp_api_key_hidden}\")\nprint(f\"Gemini API Key (hidden): {gemini_api_key_hidden}\")\nprint(f\"Llamaindex API Key (hidden): {llamaindex_api_key_hidden}\")","block_group":"ec6919e96c944f4ca1306d0196fb4368","execution_count":40,"outputs":[{"name":"stdout","text":"OpenAI API Key (hidden): sk-*********************************************0jF\nSerp API Key (hidden): 68c**********************************************************266\nGemini API Key (hidden): AIz*********************************MUc\nLlamaindex API Key (hidden): llx**********************************************hA3\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/72f6f189-3885-4e52-9ac1-3ce941ce3076"},{"cell_type":"code","metadata":{"id":"kQlg-GSNcDkc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a710e607-5778-4782-800c-0d18a9c60cde","source_hash":"ae373b63","execution_start":1709953213918,"execution_millis":454,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"a1aca2dfefa54140b8c63124b5f6fd24","deepnote_cell_type":"code"},"source":"import requests\nimport json\n\n# Set up your SERP API key\n# It's better to use an environment variable for API keys\n\ndef search_google(query):\n    params = {\n        \"engine\": \"google\",\n        \"q\": query,\n        \"api_key\": serp_api_key,\n        \"location\": \"San Francisco Bay Area, United States\",\n        \"google_domain\": \"google.com\",\n        \"gl\": \"us\",\n        \"hl\": \"en\",\n        \"num\": \"10\"\n    }\n    response = requests.get(\"https://serpapi.com/search\", params=params)\n    response.raise_for_status()  # Raises an HTTPError if the HTTP request returned an unsuccessful status code\n    results = response.json()\n    # Extracting only the needed information\n    formatted_data = {\n        \"organic_results\": [\n            {\n                \"link\": result[\"link\"],\n                \"title\": result[\"title\"],\n                \"snippet\": result.get(\"snippet\", \"\")\n            } for result in results.get(\"organic_results\", [])\n        ]\n    }\n    # Assuming search_results is your JSON dictionary obtained from the search\n    organic_results = formatted_data.get('organic_results', [])\n\n    # Initialize an empty list to store all the links\n    all_links = []\n\n    # Loop through each result in the organic results\n    for result in organic_results:\n        # Extract the link if it exists and add it to the list\n        if 'link' in result:\n            all_links.append(result['link'])\n    return all_links\n\n# Example usage\nquery = \"Top academic papers on LLMs\"\nsearch_google(query)","block_group":"e455b5ec168e43f2b26a6e7d94fd7da3","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"['https://www.topbots.com/top-llm-research-papers-2023/',\n 'https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f',\n 'https://levelup.gitconnected.com/best-papers-on-large-language-models-ac01b13b94b3',\n 'https://community.openai.com/t/foundational-must-read-gpt-llm-papers/197003',\n 'https://www.reddit.com/r/MLQuestions/comments/ze9e5x/can_anyone_recommend_an_llm_that_handles_research/',\n 'https://analyticsindiamag.com/13-not-to-miss-research-papers-on-llms/',\n 'https://github.com/Hannibal046/Awesome-LLM',\n 'https://yousefhosni.medium.com/top-important-llm-papers-for-the-week-from-01-01-to-07-01-4e3be08ac69b',\n 'https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023']"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/bd9329cd-7a90-497a-bee7-a0adaf1dd662"},{"cell_type":"markdown","metadata":{"source_hash":"512e8d6","execution_start":1709515167081,"execution_millis":9,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"8707b09ca5a24cfd814ed8656ea7fee8","deepnote_cell_type":"markdown"},"source":"# Main logic","block_group":"2ee1adc93b4e4ed8884aa912fa071dd0"},{"cell_type":"markdown","metadata":{"id":"PGhfirytcDkd","deepnote_app_block_visible":true,"cell_id":"2e779478d9f547b2a9682a8163537b97","deepnote_cell_type":"markdown"},"source":"### Scrape the content of the page displayed in the search results","block_group":"ee6c7fb7d3ad4320ae7b3997ed1e253d"},{"cell_type":"code","metadata":{"id":"KmYe0sLncDke","colab":{"base_uri":"https://localhost:8080/"},"outputId":"180473ad-84fd-4623-b3bc-500e7b60e2a8","source_hash":"d92a16f6","execution_start":1710017838544,"execution_millis":310,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"e0bb61fb8e5e45169f873d360edf04fd","deepnote_cell_type":"code"},"source":"import requests\nfrom bs4 import BeautifulSoup\n\ndef fetch_url_content(url):\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n    }\n    response = requests.get(url, headers=headers)\n\n    # Initialize the default response structure\n    result = {\n        \"status\": response.status_code,\n        \"soup\": None\n    }\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Adjusts encoding to match what the response seems to use\n        response.encoding = response.apparent_encoding\n        \n        # Now using response.text to utilize the corrected encoding rather than response.content\n        result['soup'] = BeautifulSoup(response.text, 'html.parser')\n    else:\n        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n\n    return result\n\n# Test the function with a URL\nurl = 'https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f'\nresponse = fetch_url_content(url)\nprint(\"Status Code:\", response['status'])\nprint(\"Soup:\", response['soup'])","block_group":"a0e9a61cee0f4dbf8c675a5f13096b69","execution_count":104,"outputs":[{"name":"stdout","text":"Status Code: 200\nSoup: <!DOCTYPE html>\n<html lang=\"en\"><head><title data-rh=\"true\">Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications | by The Data Beast | Medium</title><meta charset=\"utf-8\" data-rh=\"true\"/><meta content=\"width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1\" data-rh=\"true\" name=\"viewport\"/><meta content=\"#000000\" data-rh=\"true\" name=\"theme-color\"/><meta content=\"Medium\" data-rh=\"true\" name=\"twitter:app:name:iphone\"/><meta content=\"828256236\" data-rh=\"true\" name=\"twitter:app:id:iphone\"/><meta content=\"Medium\" data-rh=\"true\" property=\"al:ios:app_name\"/><meta content=\"828256236\" data-rh=\"true\" property=\"al:ios:app_store_id\"/><meta content=\"com.medium.reader\" data-rh=\"true\" property=\"al:android:package\"/><meta content=\"542599432471018\" data-rh=\"true\" property=\"fb:app_id\"/><meta content=\"Medium\" data-rh=\"true\" property=\"og:site_name\"/><meta content=\"article\" data-rh=\"true\" property=\"og:type\"/><meta content=\"2023-11-13T09:09:19.152Z\" data-rh=\"true\" property=\"article:published_time\"/><meta content=\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications | by The Data Beast | Medium\" data-rh=\"true\" name=\"title\"/><meta content=\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering…\" data-rh=\"true\" property=\"og:title\"/><meta content=\"medium://p/7abfcb69da7f\" data-rh=\"true\" property=\"al:android:url\"/><meta content=\"medium://p/7abfcb69da7f\" data-rh=\"true\" property=\"al:ios:url\"/><meta content=\"Medium\" data-rh=\"true\" property=\"al:android:app_name\"/><meta content=\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering…. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\" data-rh=\"true\" name=\"description\"/><meta content=\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" data-rh=\"true\" property=\"og:description\"/><meta content=\"https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\" data-rh=\"true\" property=\"og:url\"/><meta content=\"https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\" data-rh=\"true\" property=\"al:web:url\"/><meta content=\"https://miro.medium.com/v2/resize:fit:1024/1*DJCRL6_IaSlWcebV_rDzjw.png\" data-rh=\"true\" property=\"og:image\"/><meta content=\"https://medium.com/@thedatabeast\" data-rh=\"true\" property=\"article:author\"/><meta content=\"The Data Beast\" data-rh=\"true\" name=\"author\"/><meta content=\"index,follow,max-image-preview:large\" data-rh=\"true\" name=\"robots\"/><meta content=\"unsafe-url\" data-rh=\"true\" name=\"referrer\"/><meta content=\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering…\" data-rh=\"true\" property=\"twitter:title\"/><meta content=\"@Medium\" data-rh=\"true\" name=\"twitter:site\"/><meta content=\"medium://p/7abfcb69da7f\" data-rh=\"true\" name=\"twitter:app:url:iphone\"/><meta content=\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" data-rh=\"true\" property=\"twitter:description\"/><meta content=\"https://miro.medium.com/v2/resize:fit:1024/1*DJCRL6_IaSlWcebV_rDzjw.png\" data-rh=\"true\" name=\"twitter:image:src\"/><meta content=\"summary_large_image\" data-rh=\"true\" name=\"twitter:card\"/><meta content=\"@the_data_beast\" data-rh=\"true\" name=\"twitter:creator\"/><meta content=\"Reading time\" data-rh=\"true\" name=\"twitter:label1\"/><meta content=\"2 min read\" data-rh=\"true\" name=\"twitter:data1\"/><meta content=\"2\" data-rh=\"true\" name=\"twitter:tile:template:testing\"/><meta content=\"https://miro.medium.com/v2/resize:fit:1024/1*DJCRL6_IaSlWcebV_rDzjw.png\" data-rh=\"true\" name=\"twitter:tile:image\"/><meta content=\"Person\" data-rh=\"true\" name=\"twitter:tile:info1:icon\"/><meta content=\"The Data Beast\" data-rh=\"true\" name=\"twitter:tile:info1:text\"/><meta content=\"Calendar\" data-rh=\"true\" name=\"twitter:tile:info2:icon\"/><meta content=\"Nov 13, 2023\" data-rh=\"true\" name=\"twitter:tile:info2:text\"/><meta content=\"Read on Medium\" data-rh=\"true\" name=\"twitter:cta\"/><link data-rh=\"true\" href=\"https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png\" rel=\"icon\"/><link data-rh=\"true\" href=\"/osd.xml\" rel=\"search\" title=\"Medium\" type=\"application/opensearchdescription+xml\"/><link data-rh=\"true\" href=\"https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\" rel=\"apple-touch-icon\" sizes=\"152x152\"/><link data-rh=\"true\" href=\"https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\" rel=\"apple-touch-icon\" sizes=\"120x120\"/><link data-rh=\"true\" href=\"https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\" rel=\"apple-touch-icon\" sizes=\"76x76\"/><link data-rh=\"true\" href=\"https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png\" rel=\"apple-touch-icon\" sizes=\"60x60\"/><link color=\"#171717\" data-rh=\"true\" href=\"https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg\" rel=\"mask-icon\"/><link crossorigin=\"\" data-rh=\"true\" href=\"https://glyph.medium.com\" rel=\"preconnect\"/><link as=\"style\" data-rh=\"true\" href=\"https://glyph.medium.com/css/unbound.css\" id=\"glyph_preload_link\" rel=\"preload\" type=\"text/css\"/><link data-rh=\"true\" href=\"https://glyph.medium.com/css/unbound.css\" id=\"glyph_link\" rel=\"stylesheet\" type=\"text/css\"/><link data-rh=\"true\" href=\"https://medium.com/@thedatabeast\" rel=\"author\"/><link data-rh=\"true\" href=\"https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\" rel=\"canonical\"/><link data-rh=\"true\" href=\"android-app://com.medium.reader/https/medium.com/p/7abfcb69da7f\" rel=\"alternate\"/><script data-rh=\"true\" type=\"application/ld+json\">{\"@context\":\"http:\\u002F\\u002Fschema.org\",\"@type\":\"NewsArticle\",\"image\":[\"https:\\u002F\\u002Fmiro.medium.com\\u002Fv2\\u002Fresize:fit:1200\\u002F1*DJCRL6_IaSlWcebV_rDzjw.png\"],\"url\":\"https:\\u002F\\u002Fmedium.com\\u002F@thedatabeast\\u002Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\",\"dateCreated\":\"2023-11-13T09:09:19.152Z\",\"datePublished\":\"2023-11-13T09:09:19.152Z\",\"dateModified\":\"2023-11-14T05:31:34.681Z\",\"headline\":\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications\",\"name\":\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications\",\"description\":\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering…. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\",\"identifier\":\"7abfcb69da7f\",\"author\":{\"@type\":\"Person\",\"name\":\"The Data Beast\",\"url\":\"https:\\u002F\\u002Fmedium.com\\u002F@thedatabeast\"},\"creator\":[\"The Data Beast\"],\"publisher\":{\"@type\":\"Organization\",\"name\":\"Medium\",\"url\":\"https:\\u002F\\u002Fmedium.com\\u002F\",\"logo\":{\"@type\":\"ImageObject\",\"width\":308,\"height\":60,\"url\":\"https:\\u002F\\u002Fmiro.medium.com\\u002Fv2\\u002Fresize:fit:616\\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png\"}},\"mainEntityOfPage\":\"https:\\u002F\\u002Fmedium.com\\u002F@thedatabeast\\u002Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\",\"isAccessibleForFree\":\"False\",\"hasPart\":{\"@type\":\"WebPageElement\",\"isAccessibleForFree\":\"False\",\"cssSelector\":\".meteredContent\"}}</script><style data-fela-rehydration=\"447\" data-fela-type=\"STATIC\" type=\"text/css\">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden=\"true\"]{visibility:hidden;pointer-events:none}\n/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;\n}/* Gray DOCTYPE selectors like WebKit */\n.xml .hljs-meta {color: #c0c0c0;\n}.hljs-comment,\n.hljs-quote {color: #007400;\n}.hljs-tag,\n.hljs-attribute,\n.hljs-keyword,\n.hljs-selector-tag,\n.hljs-literal,\n.hljs-name {color: #aa0d91;\n}.hljs-variable,\n.hljs-template-variable {color: #3F6E74;\n}.hljs-code,\n.hljs-string,\n.hljs-meta .hljs-string {color: #c41a16;\n}.hljs-regexp,\n.hljs-link {color: #0E0EFF;\n}.hljs-title,\n.hljs-symbol,\n.hljs-bullet,\n.hljs-number {color: #1c00cf;\n}.hljs-section,\n.hljs-meta {color: #643820;\n}.hljs-title.class_,\n.hljs-class .hljs-title,\n.hljs-type,\n.hljs-built_in,\n.hljs-params {color: #5c2699;\n}.hljs-attr {color: #836C28;\n}.hljs-subst {color: #000;\n}.hljs-formula {background-color: #eee;font-style: italic;\n}.hljs-addition {background-color: #baeeba;\n}.hljs-deletion {background-color: #ffc8bd;\n}.hljs-selector-id,\n.hljs-selector-class {color: #9b703f;\n}.hljs-doctag,\n.hljs-strong {font-weight: bold;\n}.hljs-emphasis {font-style: italic;\n}\n</style><style data-fela-rehydration=\"447\" data-fela-type=\"KEYFRAME\" type=\"text/css\">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" type=\"text/css\">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Oxygen, Ubuntu, Cantarell, \"Open Sans\", \"Helvetica Neue\", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, \"Helvetica Neue\", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:#6B6B6B}.du{font-size:13px}.dv{height:100%}.eo{color:#FFFFFF}.ep{fill:#FFFFFF}.eq{background:#1A8917}.er{border-color:#1A8917}.ev:disabled{cursor:inherit !important}.ew:disabled{opacity:0.3}.ex:disabled:hover{background:#1A8917}.ey:disabled:hover{border-color:#1A8917}.ez{border-radius:99em}.fa{border-width:1px}.fb{border-style:solid}.fc{box-sizing:border-box}.fd{text-decoration:none}.fe{text-align:center}.fh{margin-right:32px}.fi{position:relative}.fj{fill:#6B6B6B}.fm{background:transparent}.fn svg{margin-left:4px}.fo svg{fill:#6B6B6B}.fq{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fr{position:absolute}.fy{margin:0 24px}.gc{background:rgba(255, 255, 255, 1)}.gd{border:1px solid #F2F2F2}.ge{box-shadow:0 1px 4px #F2F2F2}.gf{max-height:100vh}.gg{overflow-y:auto}.gh{left:0}.gi{top:calc(100vh + 100px)}.gj{bottom:calc(100vh + 100px)}.gk{width:10px}.gl{pointer-events:none}.gr{margin-right:4px}.gs{margin-top:2px}.gt{box-sizing:content-box}.gu{word-break:break-word}.gv{word-wrap:break-word}.gw:after{display:block}.gx:after{content:\"\"}.gy:after{clear:both}.gz{line-height:1.23}.ha{letter-spacing:0}.hb{font-style:normal}.hc{font-weight:700}.hx{margin-top:0px}.hy{@media all and (max-width: 551.98px):8px}.hz{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.ia{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.ib{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.ic{@media all and (min-width: 1080px):16px}.ii{align-items:baseline}.ij{width:48px}.ik{height:48px}.il{border:2px solid rgba(255, 255, 255, 1)}.im{z-index:0}.in{box-shadow:none}.io{border:1px solid rgba(0, 0, 0, 0.05)}.ip{margin-bottom:2px}.iq{flex-wrap:nowrap}.ir{font-size:16px}.is{line-height:24px}.iu{margin:0 8px}.iv{display:inline}.iw{color:#1A8917}.ix{fill:#1A8917}.ja{flex:0 0 auto}.jd{flex-wrap:wrap}.je{padding-left:8px}.jf{padding-right:8px}.kg> *{flex-shrink:0}.kh{overflow-x:scroll}.ki::-webkit-scrollbar{display:none}.kj{scrollbar-width:none}.kk{-ms-overflow-style:none}.kl{width:74px}.km{flex-direction:row}.kp{-webkit-user-select:none}.kq{border:0}.kr{fill:rgba(117, 117, 117, 1)}.ku{outline:0}.kv{user-select:none}.kw> svg{pointer-events:none}.lf{cursor:progress}.lg{margin-left:4px}.lh{opacity:1}.li{padding:4px 0}.ll{width:16px}.ln{display:inline-flex}.lt{max-width:100%}.lu{padding:8px 2px}.lv svg{color:#6B6B6B}.mm{margin-left:auto}.mn{margin-right:auto}.mo{max-width:1024px}.mp{clear:both}.mr{cursor:zoom-in}.ms{z-index:auto}.mu{height:auto}.mv{line-height:1.58}.mw{letter-spacing:-0.004em}.mx{font-family:source-serif-pro, Georgia, Cambria, \"Times New Roman\", Times, serif}.ns{margin-bottom:-0.46em}.nt{list-style-type:decimal}.nu{margin-left:30px}.nv{padding-left:0px}.nw{list-style-type:disc}.nx{text-decoration:underline}.od{border-top:none}.oj{height:52px}.ok{max-height:52px}.ol{position:static}.om{z-index:1}.oo{max-width:155px}.ou{margin-right:20px}.pa{align-items:flex-end}.pb{width:76px}.pc{height:76px}.pd{border:2px solid #F9F9F9}.pe{height:72px}.pf{width:72px}.pg{padding:8px 16px}.ph{width:auto}.pi{stroke:#F2F2F2}.pj{height:36px}.pk{width:36px}.pl{color:#F2F2F2}.pm{fill:#F2F2F2}.pn{background:#F2F2F2}.po{border-color:#F2F2F2}.pu{font-weight:500}.pv{font-size:24px}.pw{line-height:30px}.px{letter-spacing:-0.016em}.py{margin-top:8px}.pz{margin-top:16px}.qa{height:0px}.qb{border-bottom:solid 1px #E5E5E5}.qc{margin-top:72px}.qd{padding:24px 0}.qe{margin-bottom:0px}.qf{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.es:hover{background:#156D12}.et:hover{border-color:#156D12}.eu:hover{cursor:pointer}.fk:hover{color:#242424}.fl:hover{fill:#242424}.fp:hover svg{fill:#242424}.fs:hover{background-color:rgba(0, 0, 0, 0.1)}.it:hover{text-decoration:underline}.iy:hover:not(:disabled){color:#156D12}.iz:hover:not(:disabled){fill:#156D12}.kt:hover{fill:rgba(8, 8, 8, 1)}.lj:hover{fill:#000000}.lk:hover p{color:#000000}.lm:hover{color:#000000}.lw:hover svg{color:#000000}.pp:hover{background:#F2F2F2}.pq:hover{border-color:#F2F2F2}.pr:hover{cursor:wait}.ps:hover{color:#F2F2F2}.pt:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.ks:focus{fill:rgba(8, 8, 8, 1)}.lx:focus svg{color:#000000}.mt:focus{transform:scale(1.01)}.kx:active{border-style:none}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (min-width: 1080px)\" type=\"text/css\">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.el{font-size:13px}.em{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.gq{margin-top:40px}.ht{font-size:42px}.hu{margin-bottom:32px}.hv{line-height:52px}.hw{letter-spacing:-0.011em}.ih{align-items:center}.js{border-top:solid 1px #F2F2F2}.jt{border-bottom:solid 1px #F2F2F2}.ju{margin:32px 0 0}.jv{padding:3px 8px}.ke> *{margin-right:24px}.kf> :last-child{margin-right:0}.le{margin-top:0px}.ls{margin:0}.no{font-size:20px}.np{margin-top:2.14em}.nq{line-height:32px}.nr{letter-spacing:-0.003em}.oc{margin-top:1.14em}.oi{margin-bottom:88px}.ot{display:inline-block}.oz{padding-top:72px}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (max-width: 1079.98px)\" type=\"text/css\">.e{display:none}.ld{margin-top:0px}.os{display:inline-block}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (max-width: 903.98px)\" type=\"text/css\">.f{display:none}.lc{margin-top:0px}.or{display:inline-block}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (max-width: 727.98px)\" type=\"text/css\">.g{display:none}.la{margin-top:0px}.lb{margin-right:0px}.oq{display:inline-block}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (max-width: 551.98px)\" type=\"text/css\">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.ft{margin-bottom:4px}.gm{margin-top:32px}.hd{font-size:32px}.he{margin-bottom:24px}.hf{line-height:38px}.hg{letter-spacing:-0.014em}.id{align-items:flex-start}.jb{flex-direction:column}.jg{margin:24px -24px 0}.jh{padding:0}.jw> *{margin-right:8px}.jx> :last-child{margin-right:24px}.kn{margin-left:0px}.ky{margin-top:0px}.kz{margin-right:0px}.lo{margin:0}.ly{border:1px solid #F2F2F2}.lz{border-radius:99em}.ma{padding:0px 16px 0px 12px}.mb{height:38px}.mc{align-items:center}.me svg{margin-right:8px}.my{font-size:18px}.mz{margin-top:1.56em}.na{line-height:28px}.nb{letter-spacing:-0.003em}.ny{margin-top:1.34em}.oe{margin-bottom:80px}.op{display:inline-block}.ov{padding-top:48px}.md:hover{border-color:#E5E5E5}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (min-width: 904px) and (max-width: 1079.98px)\" type=\"text/css\">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{font-size:13px}.ek{padding:5px 12px}.ff{display:flex}.fw{margin-bottom:68px}.ga{max-width:680px}.gp{margin-top:40px}.hp{font-size:42px}.hq{margin-bottom:32px}.hr{line-height:52px}.hs{letter-spacing:-0.011em}.ig{align-items:center}.jo{border-top:solid 1px #F2F2F2}.jp{border-bottom:solid 1px #F2F2F2}.jq{margin:32px 0 0}.jr{padding:3px 8px}.kc> *{margin-right:24px}.kd> :last-child{margin-right:0}.lr{margin:0}.nk{font-size:20px}.nl{margin-top:2.14em}.nm{line-height:32px}.nn{letter-spacing:-0.003em}.ob{margin-top:1.14em}.oh{margin-bottom:88px}.oy{padding-top:72px}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (min-width: 728px) and (max-width: 903.98px)\" type=\"text/css\">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:68px}.fz{max-width:680px}.go{margin-top:40px}.hl{font-size:42px}.hm{margin-bottom:32px}.hn{line-height:52px}.ho{letter-spacing:-0.011em}.if{align-items:center}.jk{border-top:solid 1px #F2F2F2}.jl{border-bottom:solid 1px #F2F2F2}.jm{margin:32px 0 0}.jn{padding:3px 8px}.ka> *{margin-right:24px}.kb> :last-child{margin-right:0}.lq{margin:0}.ng{font-size:20px}.nh{margin-top:2.14em}.ni{line-height:32px}.nj{letter-spacing:-0.003em}.oa{margin-top:1.14em}.og{margin-bottom:88px}.ox{padding-top:72px}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"all and (min-width: 552px) and (max-width: 727.98px)\" type=\"text/css\">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gn{margin-top:32px}.hh{font-size:32px}.hi{margin-bottom:24px}.hj{line-height:38px}.hk{letter-spacing:-0.014em}.ie{align-items:flex-start}.jc{flex-direction:column}.ji{margin:24px 0 0}.jj{padding:0}.jy> *{margin-right:8px}.jz> :last-child{margin-right:8px}.ko{margin-left:0px}.lp{margin:0}.mf{border:1px solid #F2F2F2}.mg{border-radius:99em}.mh{padding:0px 16px 0px 12px}.mi{height:38px}.mj{align-items:center}.ml svg{margin-right:8px}.nc{font-size:18px}.nd{margin-top:1.56em}.ne{line-height:28px}.nf{letter-spacing:-0.003em}.nz{margin-top:1.34em}.of{margin-bottom:80px}.ow{padding-top:48px}.mk:hover{border-color:#E5E5E5}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"print\" type=\"text/css\">.on{display:none}</style><style data-fela-rehydration=\"447\" data-fela-type=\"RULE\" media=\"(prefers-reduced-motion: no-preference)\" type=\"text/css\">.mq{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id=\"root\"><div class=\"a b c\"><div class=\"d e f g h i j k\"></div><script>document.domain = document.domain;</script><div class=\"l c\"><div class=\"l m n o c\"><div class=\"p q r s t u v w x i d y z\"><a class=\"dt ag du be ak b am an ao ap aq ar as at s u w i d q dv z\" href=\"https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7abfcb69da7f&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderUser&amp;source=---two_column_layout_nav----------------------------------\" rel=\"noopener follow\">Open in app<svg class=\"ds\" fill=\"none\" height=\"10\" viewbox=\"0 0 10 10\" width=\"10\"><path d=\"M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z\" fill=\"currentColor\"></path></svg></a><div class=\"ab q\"><p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><button class=\"be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe\" data-testid=\"headerSignUpButton\">Sign up</button></span></p><div class=\"aw l\"><p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSignInButton\" href=\"/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign in</a></span></p></div></div></div><div class=\"p q r ab ac\"><div class=\"ab q ae\"><a aria-label=\"Homepage\" class=\"af ag ah ai aj ak al am an ao ap aq ar as at ab\" data-testid=\"headerMediumLogo\" href=\"/?source=---two_column_layout_nav----------------------------------\" rel=\"noopener follow\"><svg class=\"au av\" viewbox=\"0 0 3940 610\"><path d=\"M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z\"></path></svg></a><div class=\"aw h\"><div class=\"ab ax ay az ba q bb bc\"><div aria-describedby=\"searchResults\" aria-hidden=\"false\" aria-labelledby=\"searchResults\" class=\"bl\"></div><div class=\"bm bn ab\"><svg fill=\"none\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></div><input aria-controls=\"searchResults\" aria-expanded=\"false\" aria-label=\"search\" class=\"ax bd be bf z bg bh bi bj bk\" data-testid=\"headerSearchInput\" placeholder=\"Search\" role=\"combobox\" tabindex=\"0\" value=\"\"/></div></div></div><div class=\"h k w ff fg\"><div class=\"fh ab\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerWriteButton\" href=\"/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------\" rel=\"noopener follow\"><div class=\"be b bf z dt fi fj ab q fk fl\"><svg aria-label=\"Write\" fill=\"none\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z\" fill=\"currentColor\"></path><path d=\"M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2\" stroke=\"currentColor\"></path></svg><div class=\"ds l\">Write</div></div></a></span></div></div><div class=\"k j i d\"><div class=\"fh ab\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSearchButton\" href=\"/search?source=---two_column_layout_nav----------------------------------\" rel=\"noopener follow\"><div class=\"be b bf z dt fi fj ab q fk fl\"><svg aria-label=\"Search\" fill=\"none\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></div></a></div></div><div class=\"fh h k j\"><div class=\"ab q\"><p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><button class=\"be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe\" data-testid=\"headerSignUpButton\">Sign up</button></span></p><div class=\"aw l\"><p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSignInButton\" href=\"/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign in</a></span></p></div></div></div><div aria-hidden=\"false\" class=\"l\"><button aria-label=\"user options menu\" class=\"ax fm am ab q ao fn fo fp\" data-testid=\"headerUserIcon\"><div class=\"l fi\"><img alt=\"\" class=\"l fc bx by bz cw\" height=\"32\" loading=\"lazy\" role=\"presentation\" src=\"https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png\" width=\"32\"/><div class=\"fq bx l by bz fr n ax fs\"></div></div></button></div></div></div><div class=\"l\"><div class=\"ft fu fv fw fx l\"><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"></div></div><article class=\"meteredContent\"><div class=\"l\"><div class=\"l\"><span class=\"l\"></span><section><div><div class=\"fr gh gi gj gk gl\"></div><div><div class=\"speechify-ignore l\"><div class=\"gm gn go gp gq l\"></div><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"><div class=\"ck l\"><div class=\"gt ab\"><div aria-hidden=\"false\" class=\"bl\"><button aria-label=\"Member-only story\" class=\"l ax ao am\"><div class=\"h k j i d\"><div><div aria-hidden=\"false\" class=\"bl\"><svg fill=\"none\" height=\"16\" viewbox=\"0 0 64 64\" width=\"16\"><path d=\"M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z\" fill=\"#FFC017\"></path></svg></div></div></div><div class=\"s u w ff fg q\"><svg class=\"gr gs\" fill=\"none\" height=\"16\" viewbox=\"0 0 64 64\" width=\"16\"><path d=\"M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z\" fill=\"#FFC017\"></path></svg><p class=\"be b bf z dt\">Member-only story</p></div></button></div></div></div></div></div></div></div><div class=\"gu gv gw gx gy\"><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"><div><h1 class=\"pw-post-title gz ha hb be hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx bj\" data-testid=\"storyTitle\" id=\"1be4\">Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications</h1><div class=\"hy hz ia ib ic\"><div class=\"speechify-ignore ab co\"><div class=\"speechify-ignore bg l\"><div class=\"id ie if ig ih ab\"><div><div class=\"ab ii\"><a href=\"/@thedatabeast?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><div><div aria-hidden=\"false\" class=\"bl\"><div class=\"l ij ik bx il im\"><div class=\"l fi\"><img alt=\"The Data Beast\" class=\"l fc bx dc dd cw\" data-testid=\"authorPhoto\" height=\"44\" loading=\"lazy\" src=\"https://miro.medium.com/v2/resize:fill:88:88/1*A7eSHxmpHV-LOcc4-DxVnw.png\" width=\"44\"/><div class=\"in bx l dc dd fr n io fs\"></div></div></div></div></div></a></div></div><div class=\"bm bg l\"><div class=\"ab\"><div style=\"flex:1\"><span class=\"be b bf z bj\"><div class=\"ip ab q\"><div class=\"ab q iq\"><div class=\"ab q\"><div><div aria-hidden=\"false\" class=\"bl\"><p class=\"be b ir is bj\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar it\" data-testid=\"authorName\" href=\"/@thedatabeast?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\">The Data Beast</a></p></div></div></div><span aria-hidden=\"true\" class=\"iu iv\"><span class=\"be b bf z dt\">·</span></span><p class=\"be b ir is dt\"><span><a class=\"iw ix ah ai aj ak al am an ao ap aq ar ew iy iz\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff6bbc6865a96&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;user=The+Data+Beast&amp;userId=f6bbc6865a96&amp;source=post_page-f6bbc6865a96----7abfcb69da7f---------------------post_header-----------\" rel=\"noopener follow\">Follow</a></span></p></div></div></span></div></div><div class=\"l ja\"><span class=\"be b bf z dt\"><div class=\"ab cm jb jc jd\"><span class=\"be b bf z dt\"><div class=\"ab ae\"><span data-testid=\"storyReadTime\">2 min read</span><div aria-hidden=\"true\" class=\"je jf l\"><span aria-hidden=\"true\" class=\"l\"><span class=\"be b bf z dt\">·</span></span></div><span data-testid=\"storyPublishDate\">Nov 13, 2023</span></div></span></div></span></div></div></div><div class=\"ab co jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv\"><div class=\"h k w ff fg q\"><div class=\"kl l\"><div class=\"ab q km\"><div class=\"pw-multi-vote-icon fi gr kn ko kp\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerClapButton\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7abfcb69da7f&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;user=The+Data+Beast&amp;userId=f6bbc6865a96&amp;source=-----7abfcb69da7f---------------------clap_footer-----------\" rel=\"noopener follow\"><div><div aria-hidden=\"false\" class=\"bl\"><div class=\"kq ao kr ks kt ku am kv kw kx kp\"><svg aria-label=\"clap\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z\" fill-rule=\"evenodd\"></path></svg></div></div></div></a></span></div><div class=\"pw-multi-vote-count l ky kz la lb lc ld le\"><p class=\"be b du z dt\"><span class=\"lf\">--</span></p></div></div></div><div><div aria-hidden=\"false\" class=\"bl\"><button aria-label=\"responses\" class=\"ao kq lh li ab q fj lj lk\"><svg class=\"hx\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z\"></path></svg><p class=\"be b du z dt\"><span class=\"pw-responses-count lg hx\">1</span></p></button></div></div></div><div class=\"ab q jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk\"><div class=\"ll k j i d\"></div><div class=\"h k\"><div><div aria-hidden=\"false\" class=\"bl\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerBookmarkButton\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7abfcb69da7f&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;source=-----7abfcb69da7f---------------------bookmark_footer-----------\" rel=\"noopener follow\"><svg aria-label=\"Add to list bookmark button\" class=\"dt lm\" fill=\"none\" height=\"25\" viewbox=\"0 0 25 25\" width=\"25\"><path d=\"M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z\" fill=\"currentColor\"></path></svg></a></span></div></div></div><div class=\"fc ln cm\"><div class=\"l ae\"><div class=\"ab ca\"><div class=\"lo lp lq lr ls lt ch bg\"><div class=\"ab\"></div></div></div></div></div><div aria-describedby=\"postFooterSocialMenu\" aria-hidden=\"false\" aria-labelledby=\"postFooterSocialMenu\" class=\"bl\"><div><div aria-hidden=\"false\" class=\"bl\"><button aria-controls=\"postFooterSocialMenu\" aria-expanded=\"false\" aria-label=\"Share Post\" class=\"af fj ah ai aj ak al lu an ao ap ew lv lw lk lx ly lz ma mb s mc md me mf mg mh mi u mj mk ml\" data-testid=\"headerSocialShareButton\"><svg fill=\"none\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg><div class=\"j i d\"><p class=\"be b bf z dt\">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class=\"gm gn go gp gq mp mm mn paragraph-image\"><div class=\"mq mr fi ms bg mt\" role=\"button\" tabindex=\"0\"><div class=\"mm mn mo\"><picture><source sizes=\"(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px\" srcset=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJCRL6_IaSlWcebV_rDzjw.png 1400w\" type=\"image/webp\"/><source data-testid=\"og\" sizes=\"(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px\" srcset=\"https://miro.medium.com/v2/resize:fit:640/1*DJCRL6_IaSlWcebV_rDzjw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*DJCRL6_IaSlWcebV_rDzjw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*DJCRL6_IaSlWcebV_rDzjw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*DJCRL6_IaSlWcebV_rDzjw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*DJCRL6_IaSlWcebV_rDzjw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*DJCRL6_IaSlWcebV_rDzjw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*DJCRL6_IaSlWcebV_rDzjw.png 1400w\"/><img alt=\"\" class=\"bg lt mu c\" height=\"700\" loading=\"eager\" role=\"presentation\" width=\"700\"/></picture></div></div></figure><ol class=\"\"><li class=\"mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv bj\" id=\"62b7\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</li></ol><ul class=\"\"><li class=\"mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nw nu nv bj\" id=\"b27d\">Link: <a class=\"af nx\" href=\"https://arxiv.org/abs/1810.04805\" rel=\"noopener ugc nofollow\" target=\"_blank\">BERT Paper</a></li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"6118\">Details: Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.</li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"d23e\">Practical Implementation: Used for state-of-the-art (SOTA) models in language inference and simple question-answer tasks​​.</li></ul><p class=\"pw-post-body-paragraph mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns gu bj\" id=\"2349\">2. BlenderBot 3: A deployed conversational agent that continually learns to responsibly engage</p><ul class=\"\"><li class=\"mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nw nu nv bj\" id=\"685c\">Link: <a class=\"af nx\" href=\"https://arxiv.org/abs/2208.03188\" rel=\"noopener ugc nofollow\" target=\"_blank\">BlenderBot 3 Paper</a></li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"d33f\">Details: From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.</li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"7127\">Practical Implementation: Continually learns from deployment data, enhancing engagement and response quality​​.</li></ul><p class=\"pw-post-body-paragraph mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns gu bj\" id=\"3dc8\">3. Improving alignment of dialogue agents via targeted human judgements</p><ul class=\"\"><li class=\"mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nw nu nv bj\" id=\"0d47\">Link: <a class=\"af nx\" href=\"https://arxiv.org/abs/2209.14375\" rel=\"noopener ugc nofollow\" target=\"_blank\">Sparrow Paper</a></li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"3ef2\">Details: DeepMind’s Sparrow employs the RLHF method for training, focusing on using human feedback for generative models.</li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"3e22\">Practical Implementation: Helps in building complex goals in chatbots by integrating human feedback effectively​​.</li></ul><p class=\"pw-post-body-paragraph mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns gu bj\" id=\"2012\">4. Improving Language Understanding by Generative Pre-Training</p><ul class=\"\"><li class=\"mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nw nu nv bj\" id=\"51bc\">Link: <a class=\"af nx\" href=\"https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035\" rel=\"noopener ugc nofollow\" target=\"_blank\">GPT Paper</a></li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"1e7c\">Details: OpenAI’s paper on GPT, demonstrating the use of a decoder-style LLM for generative modeling.</li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"979b\">Practical Implementation: Pioneered NLP tasks by generative pre-training of a language model​​.</li></ul><p class=\"pw-post-body-paragraph mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns gu bj\" id=\"5157\">5. Scaling Laws for Neural Language Models</p><ul class=\"\"><li class=\"mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nw nu nv bj\" id=\"0dfe\">Link: <a class=\"af nx\" href=\"https://arxiv.org/abs/2001.08361\" rel=\"noopener ugc nofollow\" target=\"_blank\">Scaling Laws Paper</a></li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"52b8\">Details: OpenAI’s theoretical investigation into the relationship between the size of a language model and its performance.</li><li class=\"mv mw hb mx b my ny na nb nc nz ne nf ng oa ni nj nk ob nm nn no oc nq nr ns nw nu nv bj\" id=\"292b\">Practical Implementation: Provides empirical evidence for the scaling laws that govern model performance​​.</li></ul><p class=\"pw-post-body-paragraph mv mw hb mx b my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns gu bj\" id=\"2f6f\">6. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation…</p></div></div></div></div></section></div></div></article><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"></div></div></div><div class=\"l\"></div><footer class=\"od oe of og oh oi oj ok gt ab q ol om c\"><div class=\"l ae\"><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"><div class=\"ab co on\"><div class=\"ab q km\"><div class=\"oo l\"><span class=\"l op oq or e d\"><div class=\"ab q km\"><div class=\"pw-multi-vote-icon fi gr kn ko kp\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"footerClapButton\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7abfcb69da7f&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;user=The+Data+Beast&amp;userId=f6bbc6865a96&amp;source=-----7abfcb69da7f---------------------clap_footer-----------\" rel=\"noopener follow\"><div><div aria-hidden=\"false\" class=\"bl\"><div class=\"kq ao kr ks kt ku am kv kw kx kp\"><svg aria-label=\"clap\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z\" fill-rule=\"evenodd\"></path></svg></div></div></div></a></span></div><div class=\"pw-multi-vote-count l ky kz la lb lc ld le\"><p class=\"be b du z dt\"><span class=\"lf\">--</span></p></div></div></span><span class=\"l h g f os ot\"><div class=\"ab q km\"><div class=\"pw-multi-vote-icon fi gr kn ko kp\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"footerClapButton\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7abfcb69da7f&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;user=The+Data+Beast&amp;userId=f6bbc6865a96&amp;source=-----7abfcb69da7f---------------------clap_footer-----------\" rel=\"noopener follow\"><div><div aria-hidden=\"false\" class=\"bl\"><div class=\"kq ao kr ks kt ku am kv kw kx kp\"><svg aria-label=\"clap\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z\" fill-rule=\"evenodd\"></path></svg></div></div></div></a></span></div><div class=\"pw-multi-vote-count l ky kz la lb lc ld le\"><p class=\"be b du z dt\"><span class=\"lf\">--</span></p></div></div></span></div><div class=\"bp ab\"><div><div aria-hidden=\"false\" class=\"bl\"><button aria-label=\"responses\" class=\"ao kq lh li ab q fj lj lk\"><svg class=\"hx\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z\"></path></svg><p class=\"be b bf z dt\"><span class=\"pw-responses-count lg hx\">1</span></p></button></div></div></div></div><div class=\"ab q\"><div class=\"ou l ja\"><div><div aria-hidden=\"false\" class=\"bl\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"footerBookmarkButton\" href=\"/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7abfcb69da7f&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;source=--------------------------bookmark_footer-----------\" rel=\"noopener follow\"><svg aria-label=\"Add to list bookmark button\" class=\"dt lm\" fill=\"none\" height=\"25\" viewbox=\"0 0 25 25\" width=\"25\"><path d=\"M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z\" fill=\"currentColor\"></path></svg></a></span></div></div></div><div class=\"ou l ja\"><div aria-describedby=\"postFooterSocialMenu\" aria-hidden=\"false\" aria-labelledby=\"postFooterSocialMenu\" class=\"bl\"><div><div aria-hidden=\"false\" class=\"bl\"><button aria-controls=\"postFooterSocialMenu\" aria-expanded=\"false\" aria-label=\"Share Post\" class=\"af fj ah ai aj ak al lu an ao ap ew lv lw lk lx\" data-testid=\"footerSocialShareButton\"><svg fill=\"none\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path clip-rule=\"evenodd\" d=\"M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class=\"ov ow ox oy oz l bw\"><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"><div class=\"ck ab pa co\"><div class=\"ab ii\"><a href=\"/@thedatabeast?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><div class=\"l pb pc bx pd im\"><div class=\"l fi\"><img alt=\"The Data Beast\" class=\"l fc bx pe pf cw\" height=\"72\" loading=\"lazy\" src=\"https://miro.medium.com/v2/resize:fill:144:144/1*A7eSHxmpHV-LOcc4-DxVnw.png\" width=\"72\"/><div class=\"in bx l pe pf fr n io fs\"></div></div></div></a></div><div class=\"j i d\"><div class=\"ab\"><span><button class=\"be b bf z eo pg ep eq er es et eu ev ew ex ey ez ph fa fb fc bl fd fe\">Follow</button></span><div class=\"ds l\"><div><div><div aria-hidden=\"false\" class=\"bl\"><div class=\"l\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F920e325a463a&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;newsletterV3=f6bbc6865a96&amp;newsletterV3Id=920e325a463a&amp;user=The+Data+Beast&amp;userId=f6bbc6865a96&amp;source=-----7abfcb69da7f---------------------subscribe_user-----------\" rel=\"noopener follow\"><button aria-label=\"Subscribe\" class=\"be b bf z pl am pm pn po pp pq pr ps pt ev ew ex ey ez fa fb fc bl fd fe\"><svg class=\"pi pj pk\" fill=\"none\" height=\"38\" viewbox=\"0 0 38 38\" width=\"38\"><rect height=\"6.5\" rx=\"0.25\" width=\"0.5\" x=\"26.25\" y=\"9.25\"></rect><rect height=\"6.5\" rx=\"0.25\" transform=\"rotate(90 29.75 12.25)\" width=\"0.5\" x=\"29.75\" y=\"12.25\"></rect><path d=\"M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5\"></path><path d=\"M11.5 14.5L19 20l4-3\"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class=\"ab cm co\"><div class=\"l\"><div class=\"ab q\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at ab q\" href=\"/@thedatabeast?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><h2 class=\"pw-author-name be pu pv pw px bj\"><span class=\"gu\">Written by <!-- -->The Data Beast</span></h2></a></div><div class=\"py ab\"><div class=\"l ja\"><span class=\"pw-follower-count be b bf z bj\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar it\" href=\"/@thedatabeast/followers?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\">324 Followers</a></span></div></div><div class=\"pz l\"></div></div><div class=\"h k\"><div class=\"ab\"><span><button class=\"be b bf z eo pg ep eq er es et eu ev ew ex ey ez ph fa fb fc bl fd fe\">Follow</button></span><div class=\"ds l\"><div><div><div aria-hidden=\"false\" class=\"bl\"><div class=\"l\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F920e325a463a&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f&amp;newsletterV3=f6bbc6865a96&amp;newsletterV3Id=920e325a463a&amp;user=The+Data+Beast&amp;userId=f6bbc6865a96&amp;source=-----7abfcb69da7f---------------------subscribe_user-----------\" rel=\"noopener follow\"><button aria-label=\"Subscribe\" class=\"be b bf z pl am pm pn po pp pq pr ps pt ev ew ex ey ez fa fb fc bl fd fe\"><svg class=\"pi pj pk\" fill=\"none\" height=\"38\" viewbox=\"0 0 38 38\" width=\"38\"><rect height=\"6.5\" rx=\"0.25\" width=\"0.5\" x=\"26.25\" y=\"9.25\"></rect><rect height=\"6.5\" rx=\"0.25\" transform=\"rotate(90 29.75 12.25)\" width=\"0.5\" x=\"29.75\" y=\"12.25\"></rect><path d=\"M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5\"></path><path d=\"M11.5 14.5L19 20l4-3\"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class=\"qa bg qb gm gn go gp gq\"></div></div></div><div class=\"h k j\"><div class=\"qa bg qb qc\"></div><div class=\"ab ca\"><div class=\"ch bg fy fz ga gb\"><div class=\"qd ab km jd\"><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"https://help.medium.com/hc/en-us?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Help</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"https://medium.statuspage.io/?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Status</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"/about?autoplay=1&amp;source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">About</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Careers</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"https://blog.medium.com/?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Blog</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Privacy</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Terms</p></a></div><div class=\"qe qf l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"https://speechify.com/medium?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Text to speech</p></a></div><div class=\"qe l\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" href=\"/business?source=post_page-----7abfcb69da7f--------------------------------\" rel=\"noopener follow\"><p class=\"be b du z dt\">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__=\"main-20240308-234842-a5200d2619\"</script><script>window.__GRAPHQL_URI__ = \"https://medium.com/_/graphql\"</script><script>window.__PRELOADED_STATE__ = {\"algolia\":{\"queries\":{}},\"cache\":{\"experimentGroupSet\":true,\"reason\":\"\",\"group\":\"enabled\",\"tags\":[\"group-edgeCachePosts\",\"post-7abfcb69da7f\",\"user-f6bbc6865a96\"],\"serverVariantState\":\"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a\",\"middlewareEnabled\":true,\"cacheStatus\":\"DYNAMIC\",\"shouldUseCache\":true,\"vary\":[],\"loHomepageEnabled\":false,\"updatedPostPreviewsEnabled\":false},\"client\":{\"hydrated\":false,\"isUs\":false,\"isNativeMedium\":false,\"isSafariMobile\":false,\"isSafari\":false,\"isFirefox\":false,\"routingEntity\":{\"type\":\"DEFAULT\",\"explicit\":false},\"viewerIsBot\":false},\"debug\":{\"requestId\":\"c4b13701-ff22-426f-879b-4d4ee2a50edc\",\"hybridDevServices\":[],\"originalSpanCarrier\":{\"ot-tracer-spanid\":\"24b7a8a6756f5c74\",\"ot-tracer-traceid\":\"7851877c3d674a9c\",\"ot-tracer-sampled\":\"true\"}},\"multiVote\":{\"clapsPerPost\":{}},\"navigation\":{\"branch\":{\"show\":null,\"hasRendered\":null,\"blockedByCTA\":false},\"hideGoogleOneTap\":false,\"hasRenderedAlternateUserBanner\":null,\"currentLocation\":\"https:\\u002F\\u002Fmedium.com\\u002F@thedatabeast\\u002Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\",\"host\":\"medium.com\",\"hostname\":\"medium.com\",\"referrer\":\"\",\"hasSetReferrer\":false,\"susiModal\":{\"step\":null,\"operation\":\"register\"},\"postRead\":false,\"queryString\":\"\",\"currentHash\":\"\"},\"config\":{\"nodeEnv\":\"production\",\"version\":\"main-20240308-234842-a5200d2619\",\"target\":\"production\",\"productName\":\"Medium\",\"publicUrl\":\"https:\\u002F\\u002Fcdn-client.medium.com\\u002Flite\",\"authDomain\":\"medium.com\",\"authGoogleClientId\":\"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com\",\"favicon\":\"production\",\"glyphUrl\":\"https:\\u002F\\u002Fglyph.medium.com\",\"branchKey\":\"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm\",\"algolia\":{\"appId\":\"MQ57UUUQZ2\",\"apiKeySearch\":\"394474ced050e3911ae2249ecc774921\",\"indexPrefix\":\"medium_\",\"host\":\"-dsn.algolia.net\"},\"recaptchaKey\":\"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk\",\"recaptcha3Key\":\"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5\",\"recaptchaEnterpriseKeyId\":\"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp\",\"datadog\":{\"applicationId\":\"6702d87d-a7e0-42fe-bbcb-95b469547ea0\",\"clientToken\":\"pub853ea8d17ad6821d9f8f11861d23dfed\",\"rumToken\":\"pubf9cc52896502b9413b68ba36fc0c7162\",\"context\":{\"deployment\":{\"target\":\"production\",\"tag\":\"main-20240308-234842-a5200d2619\",\"commit\":\"a5200d2619b9422b2f8b826496ae3c4debb09146\"}},\"datacenter\":\"us\"},\"googleAnalyticsCode\":\"G-7JY7T788PK\",\"googlePay\":{\"apiVersion\":\"2\",\"apiVersionMinor\":\"0\",\"merchantId\":\"BCR2DN6TV7EMTGBM\",\"merchantName\":\"Medium\",\"instanceMerchantId\":\"13685562959212738550\"},\"applePay\":{\"version\":3},\"signInWallCustomDomainCollectionIds\":[\"3a8144eabfe3\",\"336d898217ee\",\"61061eb0c96b\",\"138adf9c44c\",\"819cc2aaeee0\"],\"mediumMastodonDomainName\":\"me.dm\",\"mediumOwnedAndOperatedCollectionIds\":[\"8a9336e5bb4\",\"b7e45b22fec3\",\"193b68bd4fba\",\"8d6b8a439e32\",\"54c98c43354d\",\"3f6ecf56618\",\"d944778ce714\",\"92d2092dc598\",\"ae2a65f35510\",\"1285ba81cada\",\"544c7006046e\",\"fc8964313712\",\"40187e704f1c\",\"88d9857e584e\",\"7b6769f2748b\",\"bcc38c8f6edf\",\"cef6983b292\",\"cb8577c9149e\",\"444d13b52878\",\"713d7dbc99b0\",\"ef8e90590e66\",\"191186aaafa0\",\"55760f21cdc5\",\"9dc80918cc93\",\"bdc4052bbdba\",\"8ccfed20cbb2\"],\"tierOneDomains\":[\"medium.com\",\"thebolditalic.com\",\"arcdigital.media\",\"towardsdatascience.com\",\"uxdesign.cc\",\"codeburst.io\",\"psiloveyou.xyz\",\"writingcooperative.com\",\"entrepreneurshandbook.co\",\"prototypr.io\",\"betterhumans.coach.me\",\"theascent.pub\"],\"topicsToFollow\":[\"d61cf867d93f\",\"8a146bc21b28\",\"1eca0103fff3\",\"4d562ee63426\",\"aef1078a3ef5\",\"e15e46793f8d\",\"6158eb913466\",\"55f1c20aba7a\",\"3d18b94f6858\",\"4861fee224fd\",\"63c6f1f93ee\",\"1d98b3a9a871\",\"decb52b64abf\",\"ae5d4995e225\",\"830cded25262\"],\"topicToTagMappings\":{\"accessibility\":\"accessibility\",\"addiction\":\"addiction\",\"android-development\":\"android-development\",\"art\":\"art\",\"artificial-intelligence\":\"artificial-intelligence\",\"astrology\":\"astrology\",\"basic-income\":\"basic-income\",\"beauty\":\"beauty\",\"biotech\":\"biotech\",\"blockchain\":\"blockchain\",\"books\":\"books\",\"business\":\"business\",\"cannabis\":\"cannabis\",\"cities\":\"cities\",\"climate-change\":\"climate-change\",\"comics\":\"comics\",\"coronavirus\":\"coronavirus\",\"creativity\":\"creativity\",\"cryptocurrency\":\"cryptocurrency\",\"culture\":\"culture\",\"cybersecurity\":\"cybersecurity\",\"data-science\":\"data-science\",\"design\":\"design\",\"digital-life\":\"digital-life\",\"disability\":\"disability\",\"economy\":\"economy\",\"education\":\"education\",\"equality\":\"equality\",\"family\":\"family\",\"feminism\":\"feminism\",\"fiction\":\"fiction\",\"film\":\"film\",\"fitness\":\"fitness\",\"food\":\"food\",\"freelancing\":\"freelancing\",\"future\":\"future\",\"gadgets\":\"gadgets\",\"gaming\":\"gaming\",\"gun-control\":\"gun-control\",\"health\":\"health\",\"history\":\"history\",\"humor\":\"humor\",\"immigration\":\"immigration\",\"ios-development\":\"ios-development\",\"javascript\":\"javascript\",\"justice\":\"justice\",\"language\":\"language\",\"leadership\":\"leadership\",\"lgbtqia\":\"lgbtqia\",\"lifestyle\":\"lifestyle\",\"machine-learning\":\"machine-learning\",\"makers\":\"makers\",\"marketing\":\"marketing\",\"math\":\"math\",\"media\":\"media\",\"mental-health\":\"mental-health\",\"mindfulness\":\"mindfulness\",\"money\":\"money\",\"music\":\"music\",\"neuroscience\":\"neuroscience\",\"nonfiction\":\"nonfiction\",\"outdoors\":\"outdoors\",\"parenting\":\"parenting\",\"pets\":\"pets\",\"philosophy\":\"philosophy\",\"photography\":\"photography\",\"podcasts\":\"podcast\",\"poetry\":\"poetry\",\"politics\":\"politics\",\"privacy\":\"privacy\",\"product-management\":\"product-management\",\"productivity\":\"productivity\",\"programming\":\"programming\",\"psychedelics\":\"psychedelics\",\"psychology\":\"psychology\",\"race\":\"race\",\"relationships\":\"relationships\",\"religion\":\"religion\",\"remote-work\":\"remote-work\",\"san-francisco\":\"san-francisco\",\"science\":\"science\",\"self\":\"self\",\"self-driving-cars\":\"self-driving-cars\",\"sexuality\":\"sexuality\",\"social-media\":\"social-media\",\"society\":\"society\",\"software-engineering\":\"software-engineering\",\"space\":\"space\",\"spirituality\":\"spirituality\",\"sports\":\"sports\",\"startups\":\"startup\",\"style\":\"style\",\"technology\":\"technology\",\"transportation\":\"transportation\",\"travel\":\"travel\",\"true-crime\":\"true-crime\",\"tv\":\"tv\",\"ux\":\"ux\",\"venture-capital\":\"venture-capital\",\"visual-design\":\"visual-design\",\"work\":\"work\",\"world\":\"world\",\"writing\":\"writing\"},\"defaultImages\":{\"avatar\":{\"imageId\":\"1*dmbNkD5D-u45r44go_cf0g.png\",\"height\":150,\"width\":150},\"orgLogo\":{\"imageId\":\"1*OMF3fSqH8t4xBJ9-6oZDZw.png\",\"height\":106,\"width\":545},\"postLogo\":{\"imageId\":\"1*kFrc4tBFM_tCis-2Ic87WA.png\",\"height\":810,\"width\":1440},\"postPreviewImage\":{\"imageId\":\"1*hn4v1tCaJy7cWMyb0bpNpQ.png\",\"height\":386,\"width\":579}},\"collectionStructuredData\":{\"8d6b8a439e32\":{\"name\":\"Elemental\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fcdn-images-1.medium.com\\u002Fmax\\u002F980\\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png\",\"width\":980,\"height\":159}}},\"3f6ecf56618\":{\"name\":\"Forge\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fcdn-images-1.medium.com\\u002Fmax\\u002F596\\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png\",\"width\":596,\"height\":183}}},\"ae2a65f35510\":{\"name\":\"GEN\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fmiro.medium.com\\u002Fmax\\u002F264\\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png\",\"width\":264,\"height\":140}}},\"88d9857e584e\":{\"name\":\"LEVEL\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fmiro.medium.com\\u002Fmax\\u002F540\\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png\",\"width\":540,\"height\":108}}},\"7b6769f2748b\":{\"name\":\"Marker\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fcdn-images-1.medium.com\\u002Fmax\\u002F383\\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png\",\"width\":383,\"height\":92}}},\"444d13b52878\":{\"name\":\"OneZero\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fmiro.medium.com\\u002Fmax\\u002F540\\u002F1*cw32fIqCbRWzwJaoQw6BUg.png\",\"width\":540,\"height\":123}}},\"8ccfed20cbb2\":{\"name\":\"Zora\",\"data\":{\"@type\":\"NewsMediaOrganization\",\"ethicsPolicy\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Farticles\\u002F360043290473\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\u002F\\u002Fmiro.medium.com\\u002Fmax\\u002F540\\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png\",\"width\":540,\"height\":106}}}},\"embeddedPostIds\":{\"coronavirus\":\"cd3010f9d81f\"},\"sharedCdcMessaging\":{\"COVID_APPLICABLE_TAG_SLUGS\":[],\"COVID_APPLICABLE_TOPIC_NAMES\":[],\"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE\":[],\"COVID_MESSAGES\":{\"tierA\":{\"text\":\"For more information on the novel coronavirus and Covid-19, visit cdc.gov.\",\"markups\":[{\"start\":66,\"end\":73,\"href\":\"https:\\u002F\\u002Fwww.cdc.gov\\u002Fcoronavirus\\u002F2019-nCoV\"}]},\"tierB\":{\"text\":\"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.\",\"markups\":[{\"start\":37,\"end\":45,\"href\":\"https:\\u002F\\u002Fhelp.medium.com\\u002Fhc\\u002Fen-us\\u002Fcategories\\u002F201931128-Policies-Safety\"},{\"start\":125,\"end\":132,\"href\":\"https:\\u002F\\u002Fwww.cdc.gov\\u002Fcoronavirus\\u002F2019-nCoV\"}]},\"paywall\":{\"text\":\"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.\",\"markups\":[{\"start\":56,\"end\":70,\"href\":\"https:\\u002F\\u002Fmedium.com\\u002Fmembership\"},{\"start\":138,\"end\":145,\"href\":\"https:\\u002F\\u002Fwww.cdc.gov\\u002Fcoronavirus\\u002F2019-nCoV\"}]},\"unbound\":{\"text\":\"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.\",\"markups\":[{\"start\":45,\"end\":59,\"href\":\"https:\\u002F\\u002Fmedium.com\\u002Fmembership\"},{\"start\":127,\"end\":134,\"href\":\"https:\\u002F\\u002Fwww.cdc.gov\\u002Fcoronavirus\\u002F2019-nCoV\"}]}},\"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST\":[\"3b31a67bff4a\"]},\"sharedVoteMessaging\":{\"TAGS\":[\"politics\",\"election-2020\",\"government\",\"us-politics\",\"election\",\"2020-presidential-race\",\"trump\",\"donald-trump\",\"democrats\",\"republicans\",\"congress\",\"republican-party\",\"democratic-party\",\"biden\",\"joe-biden\",\"maga\"],\"TOPICS\":[\"politics\",\"election\"],\"MESSAGE\":{\"text\":\"Find out more about the U.S. election results here.\",\"markups\":[{\"start\":46,\"end\":50,\"href\":\"https:\\u002F\\u002Fcookpolitical.com\\u002F2020-national-popular-vote-tracker\"}]},\"EXCLUDE_POSTS\":[\"397ef29e3ca5\"]},\"embedPostRules\":[],\"recircOptions\":{\"v1\":{\"limit\":3},\"v2\":{\"limit\":8}},\"braintreeClientKey\":\"production_zjkj96jm_m56f8fqpf7ngnrd4\",\"braintree\":{\"enabled\":true,\"merchantId\":\"m56f8fqpf7ngnrd4\",\"merchantAccountId\":{\"usd\":\"AMediumCorporation_instant\",\"eur\":\"amediumcorporation_EUR\",\"cad\":\"amediumcorporation_CAD\"},\"publicKey\":\"ds2nn34bg2z7j5gd\",\"braintreeEnvironment\":\"production\",\"dashboardUrl\":\"https:\\u002F\\u002Fwww.braintreegateway.com\\u002Fmerchants\",\"gracePeriodDurationInDays\":14,\"mediumMembershipPlanId\":{\"monthly\":\"ce105f8c57a3\",\"monthlyWithTrial\":\"d5ee3dbe3db8\",\"monthlyPremium\":\"fa741a9b47a2\",\"yearly\":\"a40ad4a43185\",\"yearlyStaff\":\"d74fb811198a\",\"yearlyWithTrial\":\"b3bc7350e5c7\",\"yearlyPremium\":\"e21bd2c12166\",\"monthlyCad\":\"p52orjkaceei\",\"yearlyCad\":\"h4q9g2up9ktt\"},\"braintreeDiscountId\":{\"oneMonthFree\":\"MONTHS_FREE_01\",\"threeMonthsFree\":\"MONTHS_FREE_03\",\"sixMonthsFree\":\"MONTHS_FREE_06\",\"fiftyPercentOffOneYear\":\"FIFTY_PERCENT_OFF_ONE_YEAR\"},\"3DSecureVersion\":\"2\",\"defaultCurrency\":\"usd\",\"providerPlanIdCurrency\":{\"4ycw\":\"usd\",\"rz3b\":\"usd\",\"3kqm\":\"usd\",\"jzw6\":\"usd\",\"c2q2\":\"usd\",\"nnsw\":\"usd\",\"q8qw\":\"usd\",\"d9y6\":\"usd\",\"fx7w\":\"cad\",\"nwf2\":\"cad\"}},\"paypalClientId\":\"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v\",\"paypal\":{\"host\":\"https:\\u002F\\u002Fapi.paypal.com:443\",\"clientMode\":\"production\",\"serverMode\":\"live\",\"webhookId\":\"4G466076A0294510S\",\"monthlyPlan\":{\"planId\":\"P-9WR0658853113943TMU5FDQA\",\"name\":\"Medium Membership (Monthly) with setup fee\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed monthly.\"},\"yearlyPlan\":{\"planId\":\"P-7N8963881P8875835MU5JOPQ\",\"name\":\"Medium Membership (Annual) with setup fee\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed annually.\"},\"oneYearGift\":{\"name\":\"Medium Membership (1 Year, Digital Gift Code)\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\\u002Fredeem.\",\"price\":\"50.00\",\"currency\":\"USD\",\"sku\":\"membership-gift-1-yr\"},\"oldMonthlyPlan\":{\"planId\":\"P-96U02458LM656772MJZUVH2Y\",\"name\":\"Medium Membership (Monthly)\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed monthly.\"},\"oldYearlyPlan\":{\"planId\":\"P-59P80963JF186412JJZU3SMI\",\"name\":\"Medium Membership (Annual)\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed annually.\"},\"monthlyPlanWithTrial\":{\"planId\":\"P-66C21969LR178604GJPVKUKY\",\"name\":\"Medium Membership (Monthly) with setup fee\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed monthly.\"},\"yearlyPlanWithTrial\":{\"planId\":\"P-6XW32684EX226940VKCT2MFA\",\"name\":\"Medium Membership (Annual) with setup fee\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed annually.\"},\"oldMonthlyPlanNoSetupFee\":{\"planId\":\"P-4N046520HR188054PCJC7LJI\",\"name\":\"Medium Membership (Monthly)\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed monthly.\"},\"oldYearlyPlanNoSetupFee\":{\"planId\":\"P-7A4913502Y5181304CJEJMXQ\",\"name\":\"Medium Membership (Annual)\",\"description\":\"Unlimited access to the best and brightest stories on Medium. Membership billed annually.\"},\"sdkUrl\":\"https:\\u002F\\u002Fwww.paypal.com\\u002Fsdk\\u002Fjs\"},\"stripePublishableKey\":\"pk_live_7FReX44VnNIInZwrIIx6ghjl\",\"log\":{\"json\":true,\"level\":\"info\"},\"imageUploadMaxSizeMb\":25,\"staffPicks\":{\"title\":\"Staff Picks\",\"catalogId\":\"c7bc6e1ee00f\"}},\"session\":{\"xsrf\":\"\"}}</script><script>window.__APOLLO_STATE__ = {\"ROOT_QUERY\":{\"__typename\":\"Query\",\"isLoggedIn\":false,\"viewer\":null,\"collectionByDomainOrSlug({\\\"domainOrSlug\\\":\\\"medium.com\\\"})\":null,\"postResult({\\\"id\\\":\\\"7abfcb69da7f\\\"})\":{\"__ref\":\"Post:7abfcb69da7f\"}},\"LinkedAccounts:f6bbc6865a96\":{\"__typename\":\"LinkedAccounts\",\"mastodon\":null,\"id\":\"f6bbc6865a96\"},\"UserViewerEdge:userId:f6bbc6865a96-viewerId:lo_4d12f5adefc3\":{\"__typename\":\"UserViewerEdge\",\"id\":\"userId:f6bbc6865a96-viewerId:lo_4d12f5adefc3\",\"isFollowing\":false,\"isUser\":false,\"isMuting\":false},\"NewsletterV3:920e325a463a\":{\"__typename\":\"NewsletterV3\",\"id\":\"920e325a463a\",\"type\":\"NEWSLETTER_TYPE_AUTHOR\",\"slug\":\"f6bbc6865a96\",\"name\":\"f6bbc6865a96\",\"collection\":null,\"user\":{\"__ref\":\"User:f6bbc6865a96\"}},\"User:f6bbc6865a96\":{\"__typename\":\"User\",\"id\":\"f6bbc6865a96\",\"name\":\"The Data Beast\",\"username\":\"thedatabeast\",\"newsletterV3\":{\"__ref\":\"NewsletterV3:920e325a463a\"},\"linkedAccounts\":{\"__ref\":\"LinkedAccounts:f6bbc6865a96\"},\"isSuspended\":false,\"imageId\":\"1*A7eSHxmpHV-LOcc4-DxVnw.png\",\"mediumMemberAt\":0,\"verifications\":{\"__typename\":\"VerifiedInfo\",\"isBookAuthor\":false},\"socialStats\":{\"__typename\":\"SocialStats\",\"followerCount\":324},\"customDomainState\":null,\"hasSubdomain\":false,\"bio\":\"\",\"isPartnerProgramEnrolled\":true,\"viewerEdge\":{\"__ref\":\"UserViewerEdge:userId:f6bbc6865a96-viewerId:lo_4d12f5adefc3\"},\"viewerIsUser\":false,\"postSubscribeMembershipUpsellShownAt\":0,\"allowNotes\":true,\"membership\":null,\"twitterScreenName\":\"the_data_beast\"},\"Paragraph:2cf054fdb682_0\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_0\",\"name\":\"1be4\",\"type\":\"H3\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"ImageMetadata:1*DJCRL6_IaSlWcebV_rDzjw.png\":{\"__typename\":\"ImageMetadata\",\"id\":\"1*DJCRL6_IaSlWcebV_rDzjw.png\",\"originalHeight\":1024,\"originalWidth\":1024,\"focusPercentX\":null,\"focusPercentY\":null,\"alt\":null},\"Paragraph:2cf054fdb682_1\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_1\",\"name\":\"bf56\",\"type\":\"IMG\",\"href\":null,\"layout\":\"INSET_CENTER\",\"metadata\":{\"__ref\":\"ImageMetadata:1*DJCRL6_IaSlWcebV_rDzjw.png\"},\"text\":\"\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_2\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_2\",\"name\":\"62b7\",\"type\":\"OLI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_3\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_3\",\"name\":\"b27d\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Link: BERT Paper\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[{\"__typename\":\"Markup\",\"type\":\"A\",\"start\":6,\"end\":16,\"href\":\"https:\\u002F\\u002Farxiv.org\\u002Fabs\\u002F1810.04805\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_4\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_4\",\"name\":\"6118\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Details: Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_5\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_5\",\"name\":\"d23e\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Practical Implementation: Used for state-of-the-art (SOTA) models in language inference and simple question-answer tasks​​.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_6\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_6\",\"name\":\"2349\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"2. BlenderBot 3: A deployed conversational agent that continually learns to responsibly engage\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_7\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_7\",\"name\":\"685c\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Link: BlenderBot 3 Paper\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[{\"__typename\":\"Markup\",\"type\":\"A\",\"start\":6,\"end\":24,\"href\":\"https:\\u002F\\u002Farxiv.org\\u002Fabs\\u002F2208.03188\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_8\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_8\",\"name\":\"d33f\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Details: From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_9\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_9\",\"name\":\"7127\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Practical Implementation: Continually learns from deployment data, enhancing engagement and response quality​​.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_10\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_10\",\"name\":\"3dc8\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"3. Improving alignment of dialogue agents via targeted human judgements\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_11\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_11\",\"name\":\"0d47\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Link: Sparrow Paper\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[{\"__typename\":\"Markup\",\"type\":\"A\",\"start\":6,\"end\":19,\"href\":\"https:\\u002F\\u002Farxiv.org\\u002Fabs\\u002F2209.14375\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_12\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_12\",\"name\":\"3ef2\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Details: DeepMind’s Sparrow employs the RLHF method for training, focusing on using human feedback for generative models.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_13\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_13\",\"name\":\"3e22\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Practical Implementation: Helps in building complex goals in chatbots by integrating human feedback effectively​​.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_14\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_14\",\"name\":\"2012\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"4. Improving Language Understanding by Generative Pre-Training\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_15\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_15\",\"name\":\"51bc\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Link: GPT Paper\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[{\"__typename\":\"Markup\",\"type\":\"A\",\"start\":6,\"end\":15,\"href\":\"https:\\u002F\\u002Fwww.semanticscholar.org\\u002Fpaper\\u002FImproving-Language-Understanding-by-Generative-Radford-Narasimhan\\u002Fcd18800a0fe0b668a1cc19f2ec95b5003d0a5035\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_16\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_16\",\"name\":\"1e7c\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Details: OpenAI’s paper on GPT, demonstrating the use of a decoder-style LLM for generative modeling.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_17\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_17\",\"name\":\"979b\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Practical Implementation: Pioneered NLP tasks by generative pre-training of a language model​​.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_18\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_18\",\"name\":\"5157\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"5. Scaling Laws for Neural Language Models\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_19\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_19\",\"name\":\"0dfe\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Link: Scaling Laws Paper\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[{\"__typename\":\"Markup\",\"type\":\"A\",\"start\":6,\"end\":24,\"href\":\"https:\\u002F\\u002Farxiv.org\\u002Fabs\\u002F2001.08361\",\"anchorType\":\"LINK\",\"userId\":null,\"linkMetadata\":null}],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_20\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_20\",\"name\":\"52b8\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Details: OpenAI’s theoretical investigation into the relationship between the size of a language model and its performance.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_21\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_21\",\"name\":\"292b\",\"type\":\"ULI\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"Practical Implementation: Provides empirical evidence for the scaling laws that govern model performance​​.\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Paragraph:2cf054fdb682_22\":{\"__typename\":\"Paragraph\",\"id\":\"2cf054fdb682_22\",\"name\":\"2f6f\",\"type\":\"P\",\"href\":null,\"layout\":null,\"metadata\":null,\"text\":\"6. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation…\",\"hasDropCap\":null,\"dropCapImage\":null,\"markups\":[],\"codeBlockMetadata\":null,\"iframe\":null,\"mixtapeMetadata\":null},\"Tag:llm\":{\"__typename\":\"Tag\",\"id\":\"llm\",\"displayTitle\":\"Llm\",\"normalizedTagSlug\":\"llm\"},\"Tag:ai\":{\"__typename\":\"Tag\",\"id\":\"ai\",\"displayTitle\":\"AI\",\"normalizedTagSlug\":\"ai\"},\"Tag:data-science\":{\"__typename\":\"Tag\",\"id\":\"data-science\",\"displayTitle\":\"Data Science\",\"normalizedTagSlug\":\"data-science\"},\"Tag:research\":{\"__typename\":\"Tag\",\"id\":\"research\",\"displayTitle\":\"Research\",\"normalizedTagSlug\":\"research\"},\"Tag:beginner\":{\"__typename\":\"Tag\",\"id\":\"beginner\",\"displayTitle\":\"Beginner\",\"normalizedTagSlug\":\"beginner\"},\"Post:7abfcb69da7f\":{\"__typename\":\"Post\",\"id\":\"7abfcb69da7f\",\"collection\":null,\"content({\\\"postMeteringOptions\\\":{}})\":{\"__typename\":\"PostContent\",\"isLockedPreviewOnly\":true,\"bodyModel\":{\"__typename\":\"RichText\",\"sections\":[{\"__typename\":\"Section\",\"name\":null,\"startIndex\":0,\"textLayout\":null,\"imageLayout\":null,\"backgroundImage\":null,\"videoLayout\":null,\"backgroundVideo\":null}],\"paragraphs\":[{\"__ref\":\"Paragraph:2cf054fdb682_0\"},{\"__ref\":\"Paragraph:2cf054fdb682_1\"},{\"__ref\":\"Paragraph:2cf054fdb682_2\"},{\"__ref\":\"Paragraph:2cf054fdb682_3\"},{\"__ref\":\"Paragraph:2cf054fdb682_4\"},{\"__ref\":\"Paragraph:2cf054fdb682_5\"},{\"__ref\":\"Paragraph:2cf054fdb682_6\"},{\"__ref\":\"Paragraph:2cf054fdb682_7\"},{\"__ref\":\"Paragraph:2cf054fdb682_8\"},{\"__ref\":\"Paragraph:2cf054fdb682_9\"},{\"__ref\":\"Paragraph:2cf054fdb682_10\"},{\"__ref\":\"Paragraph:2cf054fdb682_11\"},{\"__ref\":\"Paragraph:2cf054fdb682_12\"},{\"__ref\":\"Paragraph:2cf054fdb682_13\"},{\"__ref\":\"Paragraph:2cf054fdb682_14\"},{\"__ref\":\"Paragraph:2cf054fdb682_15\"},{\"__ref\":\"Paragraph:2cf054fdb682_16\"},{\"__ref\":\"Paragraph:2cf054fdb682_17\"},{\"__ref\":\"Paragraph:2cf054fdb682_18\"},{\"__ref\":\"Paragraph:2cf054fdb682_19\"},{\"__ref\":\"Paragraph:2cf054fdb682_20\"},{\"__ref\":\"Paragraph:2cf054fdb682_21\"},{\"__ref\":\"Paragraph:2cf054fdb682_22\"}]},\"validatedShareKey\":\"\",\"shareKeyCreator\":null},\"creator\":{\"__ref\":\"User:f6bbc6865a96\"},\"inResponseToEntityType\":null,\"isLocked\":true,\"isMarkedPaywallOnly\":false,\"lockedSource\":\"LOCKED_POST_SOURCE_UGC\",\"mediumUrl\":\"https:\\u002F\\u002Fmedium.com\\u002F@thedatabeast\\u002Ftop-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\",\"primaryTopic\":null,\"topics\":[{\"__typename\":\"Topic\",\"slug\":\"machine-learning\"}],\"isPublished\":true,\"latestPublishedVersion\":\"2cf054fdb682\",\"visibility\":\"LOCKED\",\"postResponses\":{\"__typename\":\"PostResponses\",\"count\":1},\"createdAt\":1699866174818,\"firstPublishedAt\":1699866559152,\"latestPublishedAt\":1699866559152,\"clapCount\":53,\"allowResponses\":true,\"isLimitedState\":false,\"title\":\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering…\",\"isSeries\":false,\"sequence\":null,\"uniqueSlug\":\"top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\",\"socialTitle\":\"\",\"socialDek\":\"\",\"noIndex\":null,\"canonicalUrl\":\"\",\"metaDescription\":\"\",\"readingTime\":1.9622641509433962,\"previewContent\":{\"__typename\":\"PreviewContent\",\"subtitle\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"},\"previewImage\":{\"__ref\":\"ImageMetadata:1*DJCRL6_IaSlWcebV_rDzjw.png\"},\"isShortform\":false,\"seoTitle\":\"\",\"updatedAt\":1699939894681,\"shortformType\":\"SHORTFORM_TYPE_LINK\",\"seoDescription\":\"\",\"isSuspended\":false,\"license\":\"ALL_RIGHTS_RESERVED\",\"tags\":[{\"__ref\":\"Tag:llm\"},{\"__ref\":\"Tag:ai\"},{\"__ref\":\"Tag:data-science\"},{\"__ref\":\"Tag:research\"},{\"__ref\":\"Tag:beginner\"}],\"pendingCollection\":null,\"statusForCollection\":null,\"detectedLanguage\":\"en\",\"wordCount\":467,\"layerCake\":0}}</script><script>window.__MIDDLEWARE_STATE__={\"session\":{\"xsrf\":\"\"},\"cache\":{\"cacheStatus\":\"HIT\"}}</script><script src=\"https://cdn-client.medium.com/lite/static/js/manifest.749d8bab.js\"></script><script src=\"https://cdn-client.medium.com/lite/static/js/3057.5e22bbb0.js\"></script><script src=\"https://cdn-client.medium.com/lite/static/js/main.24597a77.js\"></script><script src=\"https://cdn-client.medium.com/lite/static/js/instrumentation.7c58a71f.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/reporting.2021fe63.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/4398.db4d4378.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/7883.0e445e04.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/6733.1d85727b.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/4711.043615ac.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/8695.9065ba3d.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/4341.e697d2a1.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/5971.2c86ab13.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/5203.e7a22052.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/5465.248bcf72.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/6487.eef0a2d8.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/5459.80a6ee18.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/6804.2cda7ee2.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/1711.b70f1a35.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/7652.f5b06845.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/7966.0942fdc8.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/9174.24f568ee.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/1128.fce43c64.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/4129.ee8ae2c8.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/8580.feeb2549.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/8883.c8b03d13.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/4078.da7800a7.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/9408.3df4db57.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/9150.42fafb2e.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/5005.b5d4a37c.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/6605.224598fd.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/2393.aaa1ee6d.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/2211.706ab0f5.chunk.js\"></script>\n<script src=\"https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.d6090a33.chunk.js\"></script><script>window.main();</script><script crossorigin=\"anonymous\" data-cf-beacon='{\"rayId\":\"861dfa02bfb60614\",\"b\":1,\"version\":\"2024.2.4\",\"token\":\"0b5f665943484354a59c39c6833f7078\"}' defer=\"\" integrity=\"sha512-euoFGowhlaLqXsPWQ48qSkBSCFs3DPRyiwVu3FjR96cMPx+Fr+gpWRhIafcHwqwCqWS42RZhIudOvEI+Ckf6MA==\" src=\"https://static.cloudflareinsights.com/beacon.min.js/v84a3a4012de94ce1a686ba8c167c359c1696973893317\"></script>\n</body></html>\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/fe4aec12-287a-46af-8fd0-648af4cf9430"},{"cell_type":"markdown","metadata":{"id":"TR-IFH1YcDke","deepnote_app_block_visible":true,"cell_id":"6969273f02bb420281a927da879f8112","deepnote_cell_type":"markdown"},"source":"### Convert resulting html into markdown","block_group":"325824d38afb4e399934590f1fbda7be"},{"cell_type":"code","metadata":{"id":"SCfo_vCVcDke","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb377d00-e08a-472e-e765-dac66e5f4cec","source_hash":"4374083","execution_start":1709953214067,"execution_millis":306,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"38a6fd08b43c49af8acb319e7aa72510","deepnote_cell_type":"code"},"source":"import html2text\n# Function to convert HTML to Markdown\ndef html_to_markdown(html_content):\n    # Create a converter object\n    converter = html2text.HTML2Text()\n    converter.ignore_links = False  # Set to True if you want to ignore converting links\n    \n    # Convert the HTML content to Markdown\n    markdown = converter.handle(html_content)\n\n    return markdown\n\nmarkdown = html_to_markdown(str(response['soup']))\nprint(markdown)","block_group":"8cc94267aef54334ba4fa598f67235c4","execution_count":43,"outputs":[{"name":"stdout","text":"[Open in\napp](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7abfcb69da7f&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=---two_column_layout_nav----------------------------------)\n\nSign up\n\n[Sign\nin](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&source=post_page---two_column_layout_nav\n-----------------------global_nav-----------)\n\n[](/?source=---two_column_layout_nav----------------------------------)\n\n[Write](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-\nstory&source=---two_column_layout_nav-----------------------\nnew_post_topnav-----------)\n\n[](/search?source=---two_column_layout_nav----------------------------------)\n\nSign up\n\n[Sign\nin](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&source=post_page---two_column_layout_nav\n-----------------------global_nav-----------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\nMember-only story\n\n# Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023:\nPioneering Developments and Practical Applications\n\n[![The Data Beast](https://miro.medium.com/v2/resize:fill:88:88/1*A7eSHxmpHV-\nLOcc4-DxVnw.png)](/@thedatabeast?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[The Data Beast](/@thedatabeast?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n·\n\n[Follow](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff6bbc6865a96&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&user=The+Data+Beast&userId=f6bbc6865a96&source=post_page-f6bbc6865a96\n----7abfcb69da7f---------------------post_header-----------)\n\n2 min read\n\n·\n\nNov 13, 2023\n\n[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7abfcb69da7f&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&user=The+Data+Beast&userId=f6bbc6865a96&source=-----7abfcb69da7f\n---------------------clap_footer-----------)\n\n\\--\n\n1\n\n[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7abfcb69da7f&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&source=-----7abfcb69da7f---------------------\nbookmark_footer-----------)\n\nShare\n\n  1. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n\n  * Link: [BERT Paper](https://arxiv.org/abs/1810.04805)\n  * Details: Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.\n  * Practical Implementation: Used for state-of-the-art (SOTA) models in language inference and simple question-answer tasks​​.\n\n2\\. BlenderBot 3: A deployed conversational agent that continually learns to\nresponsibly engage\n\n  * Link: [BlenderBot 3 Paper](https://arxiv.org/abs/2208.03188)\n  * Details: From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.\n  * Practical Implementation: Continually learns from deployment data, enhancing engagement and response quality​​.\n\n3\\. Improving alignment of dialogue agents via targeted human judgements\n\n  * Link: [Sparrow Paper](https://arxiv.org/abs/2209.14375)\n  * Details: DeepMind’s Sparrow employs the RLHF method for training, focusing on using human feedback for generative models.\n  * Practical Implementation: Helps in building complex goals in chatbots by integrating human feedback effectively​​.\n\n4\\. Improving Language Understanding by Generative Pre-Training\n\n  * Link: [GPT Paper](https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035)\n  * Details: OpenAI’s paper on GPT, demonstrating the use of a decoder-style LLM for generative modeling.\n  * Practical Implementation: Pioneered NLP tasks by generative pre-training of a language model​​.\n\n5\\. Scaling Laws for Neural Language Models\n\n  * Link: [Scaling Laws Paper](https://arxiv.org/abs/2001.08361)\n  * Details: OpenAI’s theoretical investigation into the relationship between the size of a language model and its performance.\n  * Practical Implementation: Provides empirical evidence for the scaling laws that govern model performance​​.\n\n6\\. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language\nGeneration…\n\n[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7abfcb69da7f&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&user=The+Data+Beast&userId=f6bbc6865a96&source=-----7abfcb69da7f\n---------------------clap_footer-----------)\n\n\\--\n\n[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F7abfcb69da7f&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&user=The+Data+Beast&userId=f6bbc6865a96&source=-----7abfcb69da7f\n---------------------clap_footer-----------)\n\n\\--\n\n1\n\n[](/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7abfcb69da7f&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&source=--------------------------bookmark_footer-----------)\n\n[![The Data\nBeast](https://miro.medium.com/v2/resize:fill:144:144/1*A7eSHxmpHV-\nLOcc4-DxVnw.png)](/@thedatabeast?source=post_page-----\n7abfcb69da7f--------------------------------)\n\nFollow\n\n[](/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F920e325a463a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&newsletterV3=f6bbc6865a96&newsletterV3Id=920e325a463a&user=The+Data+Beast&userId=f6bbc6865a96&source=-----7abfcb69da7f\n---------------------subscribe_user-----------)\n\n## [Written by The Data Beast](/@thedatabeast?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[323 Followers](/@thedatabeast/followers?source=post_page-----\n7abfcb69da7f--------------------------------)\n\nFollow\n\n[](/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F920e325a463a&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40thedatabeast%2Ftop-10-breakthrough-\nresearch-papers-on-large-language-models-llms-\nin-2023-pioneering-7abfcb69da7f&newsletterV3=f6bbc6865a96&newsletterV3Id=920e325a463a&user=The+Data+Beast&userId=f6bbc6865a96&source=-----7abfcb69da7f\n---------------------subscribe_user-----------)\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Status](https://medium.statuspage.io/?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[About](/about?autoplay=1&source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Careers](/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Blog](https://blog.medium.com/?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-\npolicy-f03bf92035c9?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-\nservice-9db0094a1e0f?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n[Teams](/business?source=post_page-----\n7abfcb69da7f--------------------------------)\n\n\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/4c02794d-8864-46b3-b5a6-c88979ce6e07"},{"cell_type":"markdown","metadata":{"id":"wlDwyEyvcDke","deepnote_app_block_visible":true,"cell_id":"5da578362ba7423a9a797927fcfc504f","deepnote_cell_type":"markdown"},"source":"### Convert markdown into a structured JSON format using function calling","block_group":"c264d0bf9f694ac2b4706ca00f463cb2"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"3da761f3e9e541b58f50f314a487b1c3","deepnote_cell_type":"text-cell-p"},"source":"we'll structure the JSON to include the page title, page summary, and details for each paragraph (title, content, and links)","block_group":"0082319406244e5c8b7fd49fa6fe28e5"},{"cell_type":"code","metadata":{"id":"8x0Cm5xycDke","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f79ef568-15f1-4c02-911b-8df9f3998327","source_hash":"1e42b023","execution_start":1709953214081,"execution_millis":8164,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"8830ea8a1c9948198cf2654fc5ccad79","deepnote_cell_type":"code"},"source":"from pydantic import BaseModel, HttpUrl\nfrom typing import List\nfrom llama_index.program.openai import OpenAIPydanticProgram\nfrom llama_index.llms.openai import OpenAI\nimport tiktoken\nfrom llama_index.core.callbacks import CallbackManager, TokenCountingHandler\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.core import Settings\n\n# Define your Pydantic models\nclass Link(BaseModel):\n    url: HttpUrl\n\nclass Paper(BaseModel):\n    paper_title: str\n    content: str\n    links: List[Link] = []\n\nclass Page(BaseModel):\n    title: str\n    summary: str\n    paragraphs: List[Paper]\n\n# Define the OpenAI Pydantic program\ndef process_markdown(markdown: str, query: str):\n    max_length: int = 16000  # Updated max length for token count\n\n    # Check token length before splitting\n    token_count = count_tokens(markdown)  # Implement this function\n    if token_count > max_length:\n        markdown_parts = split_into_parts(markdown, max_length)\n    else:\n        markdown_parts = [markdown]  # No need to split\n\n    results = []\n    for part in markdown_parts:\n        print(\"Current part length (tokens):\", count_tokens(part))\n\n        # Define the OpenAI Pydantic program\n        prompt_template_str = \"\"\"\n        Given the following markdown_content, extract only structured information about academic papers including paper title, content, and links. The papers should reflect answers to the user query {user_query}:\n        {markdown_content}\n        \"\"\"\n        program = OpenAIPydanticProgram.from_defaults(\n            output_cls=Page,\n            llm=OpenAI(model=\"gpt-3.5-turbo-1106\"),\n            prompt_template_str=prompt_template_str,\n            allow_multiple=False,\n            verbose=True,\n        )\n\n        # Run the program to get structured output\n        description_str = f\"Structured json of search results based on a user {query}\"\n        try:\n            output = program(markdown_content=part, user_query=query, description=description_str)\n            results.append(output)\n        except Exception as e:\n            # Catch all exceptions\n            if hasattr(e, 'error') and 'message' in e.error:\n                print(f\"Error: {e.error['message']}\")\n            elif hasattr(e, 'args') and e.args:\n                print(f\"Error: {e.args[0]}\")\n            else:\n                print(f\"An unexpected error occurred: {e}\")\n            continue\n\n    # Combine results from all parts or handle as needed\n    combined_result = combine_page_results(results)\n    return combined_result\n\n# Function to count tokens (replace with your implementation)\ndef count_tokens(text: str) -> int:\n    # Use your preferred tokenizer (e.g., tiktoken)\n    tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\").encode\n    return len(tokenizer(text))\n\n# Assuming 'results' is a list of Page objects or similar structured data\ndef combine_page_results(results: List[Page]) -> Page:\n    if not results:\n        return None  # Or some default value\n    \n    # Start with the title and summary from the first result\n    combined_title = results[0].title\n    combined_summary = results[0].summary\n    combined_paragraphs = []\n\n    # Iterate through all results and combine the paragraphs\n    for result in results:\n        combined_paragraphs.extend(result.paragraphs)  # Assuming 'paragraphs' is a list of 'Paper' objects\n    \n    # Create a new combined Page object\n    combined_page = Page(\n        title=combined_title,\n        summary=combined_summary,\n        paragraphs=combined_paragraphs\n    )\n    return combined_page\n\ndef split_into_parts(text: str, max_length: int) -> List[str]:\n    paragraphs = text.split('\\n\\n')\n    parts = []\n    current_part = \"\"\n\n    for paragraph in paragraphs:\n        if count_tokens(current_part) + count_tokens(paragraph) + 2 > max_length:  # +2 for the two newlines\n            parts.append(current_part)\n            current_part = paragraph  # Start new part with the current paragraph\n        else:\n            # Add paragraph to current part, include two newlines if it's not the first paragraph\n            current_part += ('\\n\\n' + paragraph) if current_part else paragraph\n\n    if current_part:  # Add the last part if not empty\n        parts.append(current_part)\n    \n    return parts\n\n\nresult = process_markdown(markdown, query)\nprint(result)","block_group":"f4717fadcdb9479e882bccadb360185f","execution_count":44,"outputs":[{"name":"stdout","text":"Current part length (tokens): 2513\nFunction call: Page with args: {\"title\":\"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications\",\"summary\":\"The top 10 breakthrough research papers on large language models (LLMs) in 2023, including practical applications and pioneering developments.\",\"paragraphs\":[{\"paper_title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"content\":\"Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.\",\"links\":[{\"url\":\"https://arxiv.org/abs/1810.04805\"}]},{\"paper_title\":\"BlenderBot 3: A deployed conversational agent that continually learns to responsibly engage\",\"content\":\"From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.\",\"links\":[{\"url\":\"https://arxiv.org/abs/2208.03188\"}]},{\"paper_title\":\"Improving alignment of dialogue agents via targeted human judgements\",\"content\":\"DeepMind’s Sparrow employs the RLHF method for training, focusing on using human feedback for generative models.\",\"links\":[{\"url\":\"https://arxiv.org/abs/2209.14375\"}]},{\"paper_title\":\"Improving Language Understanding by Generative Pre-Training\",\"content\":\"OpenAI’s paper on GPT, demonstrating the use of a decoder-style LLM for generative modeling.\",\"links\":[{\"url\":\"https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035\"}]},{\"paper_title\":\"Scaling Laws for Neural Language Models\",\"content\":\"OpenAI’s theoretical investigation into the relationship between the size of a language model and its performance.\",\"links\":[{\"url\":\"https://arxiv.org/abs/2001.08361\"}]}]}\ntitle='Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications' summary='The top 10 breakthrough research papers on large language models (LLMs) in 2023, including practical applications and pioneering developments.' paragraphs=[Paper(paper_title='BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', content='Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.', links=[Link(url=HttpUrl('https://arxiv.org/abs/1810.04805', ))]), Paper(paper_title='BlenderBot 3: A deployed conversational agent that continually learns to responsibly engage', content='From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.', links=[Link(url=HttpUrl('https://arxiv.org/abs/2208.03188', ))]), Paper(paper_title='Improving alignment of dialogue agents via targeted human judgements', content='DeepMind’s Sparrow employs the RLHF method for training, focusing on using human feedback for generative models.', links=[Link(url=HttpUrl('https://arxiv.org/abs/2209.14375', ))]), Paper(paper_title='Improving Language Understanding by Generative Pre-Training', content='OpenAI’s paper on GPT, demonstrating the use of a decoder-style LLM for generative modeling.', links=[Link(url=HttpUrl('https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035', ))]), Paper(paper_title='Scaling Laws for Neural Language Models', content='OpenAI’s theoretical investigation into the relationship between the size of a language model and its performance.', links=[Link(url=HttpUrl('https://arxiv.org/abs/2001.08361', ))])]\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/a0118da8-f961-476c-b227-79988dd92117"},{"cell_type":"code","metadata":{"id":"DZb-IZjXcDke","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89704bdc-dd84-4a75-a5cc-337437b66aaf","source_hash":"6aa8e4bb","execution_start":1709953222247,"execution_millis":317,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"0b6506fb99b44058bff8c039d8dae400","deepnote_cell_type":"code"},"source":"import json\n\n# Assuming `output` is your object and it has a method `.dict()` to convert it to a dictionary.\n# If `output` is already a dictionary, you can skip the `.dict()` conversion.\noutput_dict = result.dict() if hasattr(result, 'dict') else result\n\n# Convert to JSON string with indentation for readability\npretty_output = json.dumps(output_dict, indent=4, default=str)\n\n# Print with added line breaks\nprint(pretty_output)","block_group":"acb1e3543ff849019a00c96527b04748","execution_count":45,"outputs":[{"name":"stdout","text":"{\n    \"title\": \"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications\",\n    \"summary\": \"The top 10 breakthrough research papers on large language models (LLMs) in 2023, including practical applications and pioneering developments.\",\n    \"paragraphs\": [\n        {\n            \"paper_title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n            \"content\": \"Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.\",\n            \"links\": [\n                {\n                    \"url\": \"https://arxiv.org/abs/1810.04805\"\n                }\n            ]\n        },\n        {\n            \"paper_title\": \"BlenderBot 3: A deployed conversational agent that continually learns to responsibly engage\",\n            \"content\": \"From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.\",\n            \"links\": [\n                {\n                    \"url\": \"https://arxiv.org/abs/2208.03188\"\n                }\n            ]\n        },\n        {\n            \"paper_title\": \"Improving alignment of dialogue agents via targeted human judgements\",\n            \"content\": \"DeepMind\\u2019s Sparrow employs the RLHF method for training, focusing on using human feedback for generative models.\",\n            \"links\": [\n                {\n                    \"url\": \"https://arxiv.org/abs/2209.14375\"\n                }\n            ]\n        },\n        {\n            \"paper_title\": \"Improving Language Understanding by Generative Pre-Training\",\n            \"content\": \"OpenAI\\u2019s paper on GPT, demonstrating the use of a decoder-style LLM for generative modeling.\",\n            \"links\": [\n                {\n                    \"url\": \"https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035\"\n                }\n            ]\n        },\n        {\n            \"paper_title\": \"Scaling Laws for Neural Language Models\",\n            \"content\": \"OpenAI\\u2019s theoretical investigation into the relationship between the size of a language model and its performance.\",\n            \"links\": [\n                {\n                    \"url\": \"https://arxiv.org/abs/2001.08361\"\n                }\n            ]\n        }\n    ]\n}\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/f042ae04-38eb-47b1-9e1c-db3c78874e55"},{"cell_type":"markdown","metadata":{"id":"f5hOKcVZGXDC","deepnote_app_block_visible":true,"cell_id":"edd872556d404844a30c5cd6893483a4","deepnote_cell_type":"markdown"},"source":"### Put data into a local database","block_group":"5cb36415784b4a82b85ac5ad8e784e5a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"3581664c78784171bb50391685060a4d","deepnote_cell_type":"text-cell-p"},"source":"establish db connection","block_group":"bbce0bed79c448a8a74c0b1b48b453b6"},{"cell_type":"code","metadata":{"source_hash":"3ae08e6d","execution_start":1710035502505,"execution_millis":574,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"9bc33b69c73a45e19ec264a0048ab348","deepnote_cell_type":"code"},"source":"import psycopg2\nimport os\n\ndef connection():\n    \"\"\"Creates and returns a new database connection.\"\"\"\n    try:\n        conn = psycopg2.connect(\n            user=os.environ[\"MY_INTEGRATION_USER\"],\n            password=os.environ[\"MY_INTEGRATION_PASSWORD\"],\n            host=os.environ[\"MY_INTEGRATION_HOST\"],\n            port=os.environ[\"MY_INTEGRATION_PORT\"],\n            database=os.environ[\"MY_INTEGRATION_DATABASE\"]\n        )\n        \n        # Test the connection\n        with conn.cursor() as cursor:\n            cursor.execute(\"SELECT version();\")\n            record = cursor.fetchone()\n            print(\"You are connected to - \", record)\n        \n        return conn  # Return the connection object if successful\n\n    except (Exception, psycopg2.Error) as error:\n        print(\"Error while connecting to database\", error)\n        return None  # Return None if connection was not successful\n\nconn = connection()","block_group":"7e1738211d2d488c96250a71c0085ae8","execution_count":129,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"7c0492a5","execution_start":1709953222764,"execution_millis":815,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"70492ce7597342ed9c27db0807c987d0","deepnote_cell_type":"code"},"source":"import psycopg2\nimport os\n\n# Function to create tables in the database\ndef create_tables():\n    # Define your SQL statements for creating tables\n    sql_commands = [\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS google_search_results (\n            url TEXT PRIMARY KEY,\n            html TEXT,\n            scraping_status TEXT,\n            processed_markdown TEXT,\n            query TEXT\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS Papers (\n            id SERIAL PRIMARY KEY,\n            paper_title TEXT,\n            source_content TEXT,\n            links TEXT,\n            arxiv_link TEXT UNIQUE,\n            arxiv_title TEXT,\n            arxiv_abstract TEXT,\n            arxiv_metadata TEXT,\n            arxiv_filename TEXT,\n            arxiv_paper_markdown TEXT,\n            citations INTEGER,\n            versions INTEGER\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS Query_Papers (\n            id SERIAL PRIMARY KEY,\n            query TEXT,\n            arxiv_link TEXT,\n            relevance_score REAL,\n            final_rank INTEGER,\n            relevant_answer TEXT,\n            paper_stats TEXT,\n            paper_metadata_filtered TEXT,\n            download_link TEXT,\n            CONSTRAINT unique_query_arxiv_link UNIQUE (query, arxiv_link)\n        );\n        \"\"\",\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS jobs (\n            job_id SERIAL PRIMARY KEY,\n            query TEXT,\n            job_status TEXT,\n            printed_ranks INTEGER DEFAULT 0\n        );\n        \"\"\"\n    ]\n    try:\n        with conn.cursor() as cursor:\n            # Execute each SQL command separately\n            for sql_command in sql_commands:\n                cursor.execute(sql_command)\n            conn.commit()  # Commit the transaction\n            print(\"All tables are created successfully.\")\n\n    except (Exception, psycopg2.Error) as error:\n        print(\"Failed to create tables\", error)\n        conn.rollback()  # Rollback the transaction on error\n\n    finally:\n        if conn:\n            conn.close()\n            print(\"Database connection is closed.\")\n# Main script execution\ntry:\n    connection()\n    create_tables()\n\nexcept (Exception, psycopg2.Error) as error:\n    print(\"Error while connecting to database\", error)\n","block_group":"bfd069d9767d431abab154ac1cdd1f1b","execution_count":48,"outputs":[{"name":"stdout","text":"You are connected to -  ('PostgreSQL 15.1 (Ubuntu 15.1-1.pgdg20.04+1) on aarch64-unknown-linux-gnu, compiled by gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0, 64-bit',)\nAll tables are created successfully.\nDatabase connection is closed.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/818fedc8-bc64-4ecd-af9d-562c59a55cb9"},{"cell_type":"code","metadata":{"source_hash":"2194fa32","execution_start":1710021659355,"execution_millis":828,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"3f342ab2cfc84051bf55a1eca6442e18","deepnote_cell_type":"code"},"source":"def insert_arxiv_links_into_db(html_content, user_query):\n    # Parse the HTML content\n    soup = BeautifulSoup(html_content, 'html.parser')\n    \n    # Find all hyperlinks within the HTML content\n    links = soup.find_all('a', href=True)\n    \n    # Filter for links containing 'arxiv.org'\n    arxiv_links = [link['href'] for link in links if 'arxiv.org' in link['href']]\n    print(f\"arxiv_links[{len(arxiv_links)}]: {arxiv_links}\")\n\n    if arxiv_links:\n        try:\n            conn = connection()\n            c = conn.cursor()\n            # Assuming auto-commit is enabled by default; otherwise, manage transactions explicitly if needed\n            # If transactions need to be managed manually, ensure this is done outside of a transaction block\n\n            # Insert arxiv links into Papers table in bulk if there are any\n            arxiv_links_data = [(link,) for link in arxiv_links]  # Prepare data for bulk insert\n            psycopg2.extras.execute_batch(\n                c, \n                \"INSERT INTO Papers (arxiv_link) VALUES (%s) ON CONFLICT (arxiv_link) DO NOTHING\",\n                arxiv_links_data\n            )\n            \n            # Insert records associated with user query in Query_Papers table in bulk\n            query_papers_data = [(user_query, link) for link in arxiv_links]  # Prepare data\n            psycopg2.extras.execute_batch(\n                c, \n                \"INSERT INTO Query_Papers (query, arxiv_link) VALUES (%s, %s) ON CONFLICT (query, arxiv_link) DO NOTHING\",\n                query_papers_data\n            )\n\n            # Commit the transaction\n            conn.commit()\n            # print(f\"Successfully inserted records associated with the query '{user_query}' into the database.\")\n\n        except Exception as e:\n            # Rollback any changes if an error occurs\n            conn.rollback()\n            print(f\"Transaction rolled back. Error occurred: {e}\")\n        if conn:\n            conn.close()\n# Connect to the database\n\n# Example user query\nuser_query = \"Example Query for Testing\"\n# Example HTML content\nhtml_content = \"\"\"\n<html>\n    <body>\n        <p>Here are some arXiv papers that might interest you:</p>\n        <a href=\"https://arxiv.org/abs/12457457234623434.56789\">Paper 1</a>\n        <a href=\"https://arxiv.org/abs/98724723463246234623466.54321\">Paper 2</a>\n        <a href=\"http://example.com\">Non-arXiv link</a>\n        <a href=\"https://arxiv.org/abs/11223472347234722.3344\">Paper 3</a>\n    </body>\n</html>\n\"\"\"\ninsert_arxiv_links_into_db(html_content, user_query)","block_group":"1b61ac5205dc4d72a902767398261840","execution_count":117,"outputs":[{"name":"stdout","text":"arxiv_links[3]: ['https://arxiv.org/abs/12457457234623434.56789', 'https://arxiv.org/abs/98724723463246234623466.54321', 'https://arxiv.org/abs/11223472347234722.3344']\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/22abae79-91c4-4082-9f47-732589a98f82"},{"cell_type":"code","metadata":{"id":"M70X-8aepAuW","colab":{"height":297,"base_uri":"https://localhost:8080/"},"outputId":"11e1c1ba-2216-4163-f33d-6387a72c171d","source_hash":"cb7f2bbc","execution_start":1709953224606,"execution_millis":892,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"8b6c49cdea1748af9d89532fc84022d9","deepnote_cell_type":"code"},"source":"def insert_papers_into_db(result, query):\n    arxiv_links = []\n    if result is None:\n        print(\"No data to insert into Papers table.\")\n        return\n    # Parse JSON data\n    output_dict = result.dict() if hasattr(result, 'dict') else result\n    pretty_output = json.dumps(output_dict, indent=4, default=str)\n    data = json.loads(pretty_output)\n    if data is None or 'paragraphs' not in data:\n        print(\"Invalid or empty data.\")\n        print('Parsed website stuctured data=', data)\n        return\n\n    # Connect to SQLite database\n    conn = connection()\n    c = conn.cursor()\n\n    try:\n        # Start transaction\n        c.execute(\"BEGIN;\")\n        # Insert data into Papers table\n        for paragraph in data['paragraphs']:\n            paper_title = paragraph['paper_title']\n            source_content = paragraph['content']\n            links = json.dumps(paragraph['links'])  # Convert list of links to JSON string\n            # Initialize an empty arXiv link\n            arxiv_link = None\n            # Search for the arXiv link among the links\n            for link in paragraph['links']:\n                if 'arxiv.org' in link['url']:\n                    temp_link = link['url'].replace('.pdf', '')  # Remove .pdf if present\n                    # Remove any trailing file identifiers after the arXiv ID\n                    temp_link = temp_link.split('/abs/')[1] if '/abs/' in temp_link else temp_link.split('/')[-1]\n                    arxiv_link = 'https://arxiv.org/abs/' + temp_link  # Construct the cleaned arXiv link\n                    # Add the arXiv link to the list\n                    if arxiv_link not in arxiv_links:\n                        arxiv_links.append(arxiv_link)\n                    break  # Stop searching once the arXiv link is found\n            # Check if the arxiv_link already exists in the database\n            c.execute('SELECT COUNT(*) FROM Papers WHERE arxiv_link = %s', (arxiv_link,))\n            if c.fetchone()[0] == 0:  # If the count is 0, then the link does not exist\n                # SQL statement for inserting data\n                insert_sql = '''\n                INSERT INTO Papers (paper_title, source_content, links, arxiv_link) VALUES (%s, %s, %s, %s)\n                '''\n                c.execute(insert_sql, (paper_title, source_content, links, arxiv_link))\n            else:\n                print(f'Skipping insert: arXiv link already exists in the database: {arxiv_link}')\n\n        for link in arxiv_links:\n            # Insert new row into Query_Papers if it does not exist\n            c.execute(\"INSERT INTO Query_Papers (query, arxiv_link) SELECT %s, %s WHERE NOT EXISTS (SELECT 1 FROM Query_Papers WHERE query = %s AND arxiv_link = %s)\", (query, link, query, link))\n\n        # Commit the transaction\n        conn.commit()\n        print(f\"Processed and inserted links associated with the query '{query}' into the database.\")\n\n    except Exception as e:\n        # Rollback the transaction on error\n        conn.rollback()\n        print(f\"An error occurred: {e}. Transaction was rolled back.\")\n\n    finally:\n        if conn:\n            conn.close()\n        pass\n\n# Example data\nquery = \"Example Query for Testing\"\nresult_data = {\n    \"title\": \"Top 10 Breakthrough Research Papers on Large Language Models (LLMs) in 2023: Pioneering Developments and Practical Applications\",\n    \"summary\": \"The following are the top 10 breakthrough research papers on large language models (LLMs) in 2023, along with their practical applications and details.\",\n    \"paragraphs\": [\n        {\"paper_title\": \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\", \"content\": \"Released by Google AI Language team, BERT introduced a deep bidirectional architecture, which enhanced transfer learning demonstrated by unsupervised pre-training.\", \"links\": [{\"url\": \"https://arxiv.org/abs/1810.04805\"}]},\n        {\"paper_title\": \"BlenderBot 3: A deployed conversational agent that continually learns to responsibly engage\", \"content\": \"From Meta AI, BlenderBot 3, with its 175 billion parameters, can scour the internet, setting it apart from other conversational bots.\", \"links\": [{\"url\": \"https://arxiv.org/abs/2208.03188\"}]},\n        # Add more papers as needed...\n    ]\n}\n# result_string = json.dumps(result_data)\ninsert_papers_into_db(result_data, query)","block_group":"03b49bf5028a4bc396f92e67ac2011e8","execution_count":50,"outputs":[{"name":"stdout","text":"You are connected to -  ('PostgreSQL 15.1 (Ubuntu 15.1-1.pgdg20.04+1) on aarch64-unknown-linux-gnu, compiled by gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0, 64-bit',)\nSkipping insert: arXiv link already exists in the database: https://arxiv.org/abs/1810.04805\nSkipping insert: arXiv link already exists in the database: https://arxiv.org/abs/2208.03188\nProcessed and inserted links associated with the query 'Example Query for Testing' into the database.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b8b3b5f4-4f8f-46df-8093-3095f424823b"},{"cell_type":"code","metadata":{"id":"OWn2sNiIp8uf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2fa2724f-ea6c-4fe1-e2db-3821a368efeb","allow_embed":false,"source_hash":"26ec98cd","execution_start":1709953225503,"execution_millis":1134,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"50f9b9b63f9e4b70968896648923a5d6","deepnote_cell_type":"code"},"source":"def print_papers_table():\n    conn = connection()\n    c = conn.cursor()\n\n    try:\n        # Start transaction (mainly useful if there are preceding data manipulations)\n        c.execute(\"BEGIN;\")\n\n        # Query all records from Papers table\n        query_sql = 'SELECT * FROM Papers'  # Add any condition if necessary\n        c.execute(query_sql)\n\n        # Fetch all rows from the query\n        all_rows = c.fetchall()\n\n        # Get the column names\n        field_names = [description[0] for description in c.description]\n\n        # Check if the table is not empty\n        if all_rows:\n            print(\"Preview of Papers Table:\")\n            for row_counter, row in enumerate(all_rows, start=1):\n                print(f\"Row {row_counter}:\")\n                row_with_field_names = {\n                    field_name: (content[:60] + '...' if isinstance(content, str) and len(content) > 60 else content) \n                    for field_name, content in zip(field_names, row)\n                }\n                for field, content in row_with_field_names.items():\n                    print(f\"{field}: {content}\")\n                print(\"-------------\")  # Separator for readability\n        else:\n            print(\"The Papers table is currently empty.\")\n\n        # Commit if there were preceding changes; otherwise, this is optional for read-only operations\n        conn.commit()\n\n    except Exception as e:\n        # Rollback any changes if an exception occurs\n        conn.rollback()\n        print(f\"An error occurred: {e}\")\n\n    finally:\n        if conn:\n            conn.close()\n        pass\n\n# Call the function\nprint_papers_table()","block_group":"6ab16ec9c7a64d16b69f5328f45ed294","execution_count":51,"outputs":[{"name":"stdout","text":"arxiv_filename: FlashAttention_Fast_and_Memory-Efficient_Exact_Attention_wit...\narxiv_paper_markdown: None\ncitations: 599\nversions: 9\nid: 20\n-------------\nRow 140:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2303.15647\narxiv_title: Scaling Down to Scale Up: A Guide to Parameter-Efficient Fin...\narxiv_abstract: This paper presents a systematic overview and comparison of\n...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Scaling_Down_to_Scale_Up_A_Guide_to_Parameter-Efficient_Fine...\narxiv_paper_markdown: None\ncitations: 61\nversions: 2\nid: 25\n-------------\nRow 141:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2203.02155\narxiv_title: Training language models to follow instructions with human f...\narxiv_abstract: Making language models bigger does not inherently make them ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Training_language_models_to_follow_instructions_with_human_f...\narxiv_paper_markdown: None\ncitations: 5319\nversions: 17\nid: 27\n-------------\nRow 142:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2303.17564\narxiv_title: BloombergGPT: A Large Language Model for Finance\narxiv_abstract: The use of NLP in the realm of financial technology is broad...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: BloombergGPT_A_Large_Language_Model_for_Finance.pdf\narxiv_paper_markdown: None\ncitations: 332\nversions: 8\nid: 31\n-------------\nRow 143:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.16944\narxiv_title: Zephyr: Direct Distillation of LM Alignment\narxiv_abstract: We aim to produce a smaller language model that is aligned t...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Zephyr_Direct_Distillation_of_LM_Alignment.pdf\narxiv_paper_markdown: None\ncitations: 93\nversions: 2\nid: 41\n-------------\nRow 144:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2304.03442\narxiv_title: Generative Agents: Interactive Simulacra of Human Behavior\narxiv_abstract: Believable proxies of human behavior can empower interactive...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Generative_Agents_Interactive_Simulacra_of_Human_Behavior.pd...\narxiv_paper_markdown: None\ncitations: 566\nversions: 5\nid: 36\n-------------\nRow 145:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.03047\narxiv_title: Principle-Driven Self-Alignment of Language Models from Scra...\narxiv_abstract: Recent AI-assistant agents, such as ChatGPT, predominantly r...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Principle-Driven_Self-Alignment_of_Language_Models_from_Scra...\narxiv_paper_markdown: None\ncitations: 115\nversions: 7\nid: 39\n-------------\nRow 146:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2206.14858\narxiv_title: Solving Quantitative Reasoning Problems with Language Models\narxiv_abstract: Language models have achieved remarkable performance on a wi...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Solving_Quantitative_Reasoning_Problems_with_Language_Models...\narxiv_paper_markdown: None\ncitations: 365\nversions: 7\nid: 42\n-------------\nRow 147:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2306.05685\narxiv_title: Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\narxiv_abstract: Evaluating large language model (LLM) based chat assistants ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Judging_LLM-as-a-Judge_with_MT-Bench_and_Chatbot_Arena.pdf\narxiv_paper_markdown: None\ncitations: 537\nversions: 4\nid: 43\n-------------\nRow 148:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2308.07922\narxiv_title: RAVEN: In-Context Learning with Retrieval Augmented Encoder-...\narxiv_abstract: In this paper, we investigate the in-context learning abilit...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: RAVEN_In-Context_Learning_with_Retrieval_Augmented_Encoder-D...\narxiv_paper_markdown: None\ncitations: 11\nversions: 2\nid: 790\n-------------\nRow 149:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2205.05131v1\narxiv_title: Unifying Language Learning Paradigms\narxiv_abstract: Existing pre-trained models are generally geared towards a p...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Unifying_Language_Learning_Paradigms.pdf\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 49\n-------------\nRow 150:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2211.05100.pdf\narxiv_title: BLOOM: A 176B-Parameter Open-Access Multilingual Language Mo...\narxiv_abstract: Large language models (LLMs) have been shown to be able to p...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: BLOOM_A_176B-Parameter_Open-Access_Multilingual_Language_Mod...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 60\n-------------\nRow 151:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.04091\narxiv_title: Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thoug...\narxiv_abstract: Large language models (LLMs) have recently been shown to del...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Plan-and-Solve_Prompting_Improving_Zero-Shot_Chain-of-Though...\narxiv_paper_markdown: None\ncitations: 36\nversions: 6\nid: 62\n-------------\nRow 152:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2212.12017\narxiv_title: OPT-IML: Scaling Language Model Instruction Meta Learning th...\narxiv_abstract: Recent work has shown that fine-tuning large pre-trained lan...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: OPT-IML_Scaling_Language_Model_Instruction_Meta_Learning_thr...\narxiv_paper_markdown: None\ncitations: 55\nversions: 2\nid: 65\n-------------\nRow 153:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2210.00720\narxiv_title: Complexity-Based Prompting for Multi-Step Reasoning\narxiv_abstract: We study the task of prompting large-scale language models t...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Complexity-Based_Prompting_for_Multi-Step_Reasoning.pdf\narxiv_paper_markdown: None\ncitations: 171\nversions: 3\nid: 67\n-------------\nRow 154:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.05176\narxiv_title: FrugalGPT: How to Use Large Language Models While Reducing C...\narxiv_abstract: There is a rapidly growing number of large language models (...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: FrugalGPT_How_to_Use_Large_Language_Models_While_Reducing_Co...\narxiv_paper_markdown: None\ncitations: 67\nversions: 3\nid: 71\n-------------\nRow 155:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2311.11045\narxiv_title: Orca 2: Teaching Small Language Models How to Reason\narxiv_abstract: Orca 1 learns from rich signals, such as explanation traces,...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Orca_2_Teaching_Small_Language_Models_How_to_Reason.pdf\narxiv_paper_markdown: None\ncitations: 23\nversions: 3\nid: 72\n-------------\nRow 156:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2210.03629\narxiv_title: ReAct: Synergizing Reasoning and Acting in Language Models\narxiv_abstract: While large language models (LLMs) have demonstrated impress...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: ReAct_Synergizing_Reasoning_and_Acting_in_Language_Models.pd...\narxiv_paper_markdown: None\ncitations: 706\nversions: 6\nid: 74\n-------------\nRow 157:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.11206\narxiv_title: LIMA: Less Is More for Alignment\narxiv_abstract: Large language models are trained in two stages: (1) unsuper...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: LIMA_Less_Is_More_for_Alignment.pdf\narxiv_paper_markdown: None\ncitations: 331\nversions: 4\nid: 75\n-------------\nRow 158:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2205.11822\narxiv_title: Maieutic Prompting: Logically Consistent Reasoning with Recu...\narxiv_abstract: Despite their impressive capabilities, large pre-trained lan...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Maieutic_Prompting_Logically_Consistent_Reasoning_with_Recur...\narxiv_paper_markdown: None\ncitations: 28\nversions: 4\nid: 79\n-------------\nRow 159:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.18654\narxiv_title: Faith and Fate: Limits of Transformers on Compositionality\narxiv_abstract: Transformer large language models (LLMs) have sparked admira...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Faith_and_Fate_Limits_of_Transformers_on_Compositionality.pd...\narxiv_paper_markdown: None\ncitations: 110\nversions: 5\nid: 84\n-------------\nRow 160:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2212.14034.pdf\narxiv_title: Cramming: Training a Language Model on a Single GPU in One D...\narxiv_abstract: Recent trends in language modeling have focused on increasin...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Cramming_Training_a_Language_Model_on_a_Single_GPU_in_One_Da...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 101\n-------------\nRow 161:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2005.14165\narxiv_title: Language Models are Few-Shot Learners\narxiv_abstract: Recent work has demonstrated substantial gains on many NLP t...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Language_Models_are_Few-Shot_Learners.pdf\narxiv_paper_markdown: None\ncitations: 22215\nversions: 33\nid: 96\n-------------\nRow 162:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2301.12652\narxiv_title: REPLUG: Retrieval-Augmented Black-Box Language Models\narxiv_abstract: We introduce REPLUG, a retrieval-augmented language modeling...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: REPLUG_Retrieval-Augmented_Black-Box_Language_Models.pdf\narxiv_paper_markdown: None\ncitations: 33\nversions: 2\nid: 751\n-------------\nRow 163:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.01352\narxiv_title: RA-DIT: Retrieval-Augmented Dual Instruction Tuning\narxiv_abstract: Retrieval-augmented language models (RALMs) improve performa...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: RA-DIT_Retrieval-Augmented_Dual_Instruction_Tuning.pdf\narxiv_paper_markdown: None\ncitations: 16\nversions: 3\nid: 692\n-------------\nRow 164:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/1910.13461.pdf\narxiv_title: BART: Denoising Sequence-to-Sequence Pre-training for Natura...\narxiv_abstract: We present BART, a denoising autoencoder for pretraining seq...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: BART_Denoising_Sequence-to-Sequence_Pre-training_for_Natural...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 99\n-------------\nRow 165:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/html/2312.10997v4\narxiv_title: Retrieval-Augmented Generation for Large Language Models: A ...\narxiv_abstract: Large Language Models (LLMs) demonstrate significant capabil...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Retrieval-Augmented_Generation_for_Large_Language_Models_A_S...\narxiv_paper_markdown: None\ncitations: 63\nversions: 5\nid: 713\n-------------\nRow 166:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2303.08518\narxiv_title: UPRISE: Universal Prompt Retrieval for Improving Zero-Shot E...\narxiv_abstract: Large Language Models (LLMs) are popular for their impressiv...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: UPRISE_Universal_Prompt_Retrieval_for_Improving_Zero-Shot_Ev...\narxiv_paper_markdown: None\ncitations: 19\nversions: 4\nid: 752\n-------------\nRow 167:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/1703.06870v3\narxiv_title: Mask R-CNN\narxiv_abstract: We present a conceptually simple, flexible, and general fram...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Mask_R-CNN.pdf\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 82\n-------------\nRow 168:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2308.11761\narxiv_title: KnowledGPT: Enhancing Large Language Models with Retrieval a...\narxiv_abstract: Large language models (LLMs) have demonstrated impressive im...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: KnowledGPT_Enhancing_Large_Language_Models_with_Retrieval_an...\narxiv_paper_markdown: None\ncitations: 10\nversions: 2\nid: 789\n-------------\nRow 169:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2307.03172\narxiv_title: Lost in the Middle: How Language Models Use Long Contexts\narxiv_abstract: While recent language models have the ability to take long c...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Lost_in_the_Middle_How_Language_Models_Use_Long_Contexts.pdf\narxiv_paper_markdown: None\ncitations: 240\nversions: 8\nid: 792\n-------------\nRow 170:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2211.08411.pdf\narxiv_title: Large Language Models Struggle to Learn Long-Tail Knowledge\narxiv_abstract: The Internet contains a wealth of knowledge -- from the birt...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Large_Language_Models_Struggle_to_Learn_Long-Tail_Knowledge....\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 733\n-------------\nRow 171:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2212.10511.pdf\narxiv_title: When Not to Trust Language Models: Investigating Effectivene...\narxiv_abstract: Despite their impressive performance on diverse tasks, large...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: When_Not_to_Trust_Language_Models_Investigating_Effectivenes...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 735\n-------------\nRow 172:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2204.04991.pdf\narxiv_title: TRUE: Re-evaluating Factual Consistency Evaluation\narxiv_abstract: Grounded text generation systems often generate text that co...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: TRUE_Re-evaluating_Factual_Consistency_Evaluation.pdf\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 739\n-------------\nRow 173:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.15294\narxiv_title: Enhancing Retrieval-Augmented Large Language Models with Ite...\narxiv_abstract: Large language models are powerful text processors and reaso...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Enhancing_Retrieval-Augmented_Large_Language_Models_with_Ite...\narxiv_paper_markdown: None\ncitations: 26\nversions: 4\nid: 749\n-------------\nRow 174:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.17331\narxiv_title: Augmentation-Adapted Retriever Improves Generalization of La...\narxiv_abstract: Retrieval augmentation can aid language models (LMs) in know...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Augmentation-Adapted_Retriever_Improves_Generalization_of_La...\narxiv_paper_markdown: None\ncitations: 14\nversions: 4\nid: 750\n-------------\nRow 175:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2201.12431\narxiv_title: Neuro-Symbolic Language Modeling with Automaton-augmented Re...\narxiv_abstract: Retrieval-based language models (R-LM) model the probability...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Neuro-Symbolic_Language_Modeling_with_Automaton-augmented_Re...\narxiv_paper_markdown: None\ncitations: 38\nversions: 5\nid: 814\n-------------\nRow 176:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2112.04426\narxiv_title: Improving language models by retrieving from trillions of to...\narxiv_abstract: We enhance auto-regressive language models by conditioning o...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Improving_language_models_by_retrieving_from_trillions_of_to...\narxiv_paper_markdown: None\ncitations: 594\nversions: 5\nid: 755\n-------------\nRow 177:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.20158\narxiv_title: GAR-meets-RAG Paradigm for Zero-Shot Information Retrieval\narxiv_abstract: Given a query and a document corpus, the information retriev...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: GAR-meets-RAG_Paradigm_for_Zero-Shot_Information_Retrieval.p...\narxiv_paper_markdown: None\ncitations: 1\nversions: 2\nid: 757\n-------------\nRow 178:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.14696\narxiv_title: Tree of Clarifications: Answering Ambiguous Questions with\n ...\narxiv_abstract: Questions in open-domain question answering are often ambigu...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Tree_of_Clarifications_Answering_Ambiguous_Questions_with\n__...\narxiv_paper_markdown: None\ncitations: 4\nversions: 4\nid: 759\n-------------\nRow 179:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.19912\narxiv_title: Structure-Aware Language Model Pretraining Improves Dense Re...\narxiv_abstract: This paper presents Structure Aware Dense Retrieval (SANTA) ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Structure-Aware_Language_Model_Pretraining_Improves_Dense_Re...\narxiv_paper_markdown: None\ncitations: 1\nversions: 5\nid: 796\n-------------\nRow 180:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.11511\narxiv_title: Self-RAG: Learning to Retrieve, Generate, and Critique throu...\narxiv_abstract: Despite their remarkable capabilities, large language models...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Self-RAG_Learning_to_Retrieve,_Generate,_and_Critique_throug...\narxiv_paper_markdown: None\ncitations: 43\nversions: 4\nid: 761\n-------------\nRow 181:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2309.01431\narxiv_title: Benchmarking Large Language Models in Retrieval-Augmented Ge...\narxiv_abstract: Retrieval-Augmented Generation (RAG) is a promising approach...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Benchmarking_Large_Language_Models_in_Retrieval-Augmented_Ge...\narxiv_paper_markdown: None\ncitations: 23\nversions: 2\nid: 763\n-------------\nRow 182:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2311.08147\narxiv_title: RECALL: A Benchmark for LLMs Robustness against External Cou...\narxiv_abstract: LLMs and AI chatbots have improved people's efficiency in va...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: RECALL_A_Benchmark_for_LLMs_Robustness_against_External_Coun...\narxiv_paper_markdown: None\ncitations: 1\nversions: 2\nid: 764\n-------------\nRow 183:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2401.18059\narxiv_title: RAPTOR: Recursive Abstractive Processing for Tree-Organized ...\narxiv_abstract: Retrieval-augmented language models can better adapt to chan...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: RAPTOR_Recursive_Abstractive_Processing_for_Tree-Organized_R...\narxiv_paper_markdown: None\ncitations: None\nversions: 4\nid: 770\n-------------\nRow 184:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2401.12178\narxiv_title: In-Context Learning for Extreme Multi-Label Classification\narxiv_abstract: Multi-label classification problems with thousands of classe...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: In-Context_Learning_for_Extreme_Multi-Label_Classification.p...\narxiv_paper_markdown: None\ncitations: None\nversions: 3\nid: 771\n-------------\nRow 185:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2311.06595\narxiv_title: From Classification to Generation: Insights into Crosslingua...\narxiv_abstract: The remarkable ability of Large Language Models (LLMs) to un...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: From_Classification_to_Generation_Insights_into_Crosslingual...\narxiv_paper_markdown: None\ncitations: 1\nversions: 3\nid: 772\n-------------\nRow 186:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.17653\narxiv_title: Prompt-Guided Retrieval Augmentation for Non-Knowledge-Inten...\narxiv_abstract: Retrieval-augmented methods have received increasing attenti...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Prompt-Guided_Retrieval_Augmentation_for_Non-Knowledge-Inten...\narxiv_paper_markdown: None\ncitations: 6\nversions: 6\nid: 803\n-------------\nRow 187:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.13682\narxiv_title: Optimizing Retrieval-augmented Reader Models via Token Elimi...\narxiv_abstract: Fusion-in-Decoder (FiD) is an effective retrieval-augmented ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Optimizing_Retrieval-augmented_Reader_Models_via_Token_Elimi...\narxiv_paper_markdown: None\ncitations: 3\nversions: 4\nid: 774\n-------------\nRow 188:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2310.07713\narxiv_title: InstructRetro: Instruction Tuning post Retrieval-Augmented P...\narxiv_abstract: Pretraining auto-regressive large language models (LLMs) wit...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: InstructRetro_Instruction_Tuning_post_Retrieval-Augmented_Pr...\narxiv_paper_markdown: None\ncitations: 7\nversions: 4\nid: 779\n-------------\nRow 189:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.18846\narxiv_title: Knowledge Graph-Augmented Language Models for Knowledge-Grou...\narxiv_abstract: Language models have achieved impressive performances on dia...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Knowledge_Graph-Augmented_Language_Models_for_Knowledge-Grou...\narxiv_paper_markdown: None\ncitations: 10\nversions: 2\nid: 798\n-------------\nRow 190:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.02437\narxiv_title: Lift Yourself Up: Retrieval-augmented Text Generation with S...\narxiv_abstract: With direct access to human-written reference as memory, ret...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Lift_Yourself_Up_Retrieval-augmented_Text_Generation_with_Se...\narxiv_paper_markdown: None\ncitations: 11\nversions: 4\nid: 800\n-------------\nRow 191:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2305.14322\narxiv_title: RET-LLM: Towards a General Read-Write Memory for Large Langu...\narxiv_abstract: Large language models (LLMs) have significantly advanced the...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: RET-LLM_Towards_a_General_Read-Write_Memory_for_Large_Langua...\narxiv_paper_markdown: None\ncitations: 13\nversions: 2\nid: 802\n-------------\nRow 192:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2212.14024\narxiv_title: Demonstrate-Search-Predict: Composing retrieval and language...\narxiv_abstract: Retrieval-augmented in-context learning has emerged as a pow...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Demonstrate-Search-Predict_Composing_retrieval_and_language_...\narxiv_paper_markdown: None\ncitations: 95\nversions: 4\nid: 807\n-------------\nRow 193:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2210.01296\narxiv_title: Recitation-Augmented Language Models\narxiv_abstract: We propose a new paradigm to help Large Language Models (LLM...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Recitation-Augmented_Language_Models.pdf\narxiv_paper_markdown: None\ncitations: 58\nversions: 5\nid: 810\n-------------\nRow 194:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2209.11755\narxiv_title: Promptagator: Few-shot Dense Retrieval From 8 Examples\narxiv_abstract: Much recent research on information retrieval has focused on...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Promptagator_Few-shot_Dense_Retrieval_From_8_Examples.pdf\narxiv_paper_markdown: None\ncitations: 101\nversions: 5\nid: 811\n-------------\nRow 195:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2203.08773\narxiv_title: Training Data is More Valuable than You Think: A Simple and ...\narxiv_abstract: Retrieval-based methods have been shown to be effective in N...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Training_Data_is_More_Valuable_than_You_Think_A_Simple_and_E...\narxiv_paper_markdown: None\ncitations: 79\nversions: 5\nid: 813\n-------------\nRow 196:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2108.13934\narxiv_title: Robust Retrieval Augmented Generation for Zero-shot Slot Fil...\narxiv_abstract: Automatically inducing high quality knowledge graphs from a ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Robust_Retrieval_Augmented_Generation_for_Zero-shot_Slot_Fil...\narxiv_paper_markdown: None\ncitations: 24\nversions: 8\nid: 816\n-------------\nRow 197:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2211.12561\narxiv_title: Retrieval-Augmented Multimodal Language Modeling\narxiv_abstract: Recent multimodal models such as DALL-E and CM3 have achieve...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Retrieval-Augmented_Multimodal_Language_Modeling.pdf\narxiv_paper_markdown: None\ncitations: 40\nversions: 6\nid: 821\n-------------\nRow 198:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2305.18290.pdf\narxiv_title: Direct Preference Optimization: Your Language Model is Secre...\narxiv_abstract: While large-scale unsupervised language models (LMs) learn b...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Direct_Preference_Optimization_Your_Language_Model_is_Secret...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 88\n-------------\nRow 199:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2201.11903.pdf\narxiv_title: Chain-of-Thought Prompting Elicits Reasoning in Large Langua...\narxiv_abstract: We explore how generating a chain of thought -- a series of ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Chain-of-Thought_Prompting_Elicits_Reasoning_in_Large_Langua...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 38\n-------------\nRow 200:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2107.03374.pdf\narxiv_title: Evaluating Large Language Models Trained on Code\narxiv_abstract: We introduce Codex, a GPT language model fine-tuned on publi...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Evaluating_Large_Language_Models_Trained_on_Code.pdf\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 24\n-------------\nRow 201:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2312.10997.pdf\narxiv_title: Retrieval-Augmented Generation for Large Language Models: A ...\narxiv_abstract: Large Language Models (LLMs) demonstrate significant capabil...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Retrieval-Augmented_Generation_for_Large_Language_Models_A_S...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 824\n-------------\nRow 202:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/pdf/2203.02155.pdf\narxiv_title: Training language models to follow instructions with human f...\narxiv_abstract: Making language models bigger does not inherently make them ...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Training_language_models_to_follow_instructions_with_human_f...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 45\n-------------\nRow 203:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2005.11401v4\narxiv_title: Retrieval-Augmented Generation for Knowledge-Intensive NLP T...\narxiv_abstract: Large pre-trained language models have been shown to store f...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Retrieval-Augmented_Generation_for_Knowledge-Intensive_NLP_T...\narxiv_paper_markdown: None\ncitations: None\nversions: None\nid: 688\n-------------\nRow 204:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2005.11401\narxiv_title: Retrieval-Augmented Generation for Knowledge-Intensive NLP T...\narxiv_abstract: Large pre-trained language models have been shown to store f...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: Retrieval-Augmented_Generation_for_Knowledge-Intensive_NLP_T...\narxiv_paper_markdown: None\ncitations: 1639\nversions: 13\nid: 690\n-------------\nRow 205:\npaper_title: None\nsource_content: None\nlinks: None\narxiv_link: https://arxiv.org/abs/2311.05232\narxiv_title: A Survey on Hallucination in Large Language Models: Principl...\narxiv_abstract: The emergence of large language models (LLMs) has marked a s...\narxiv_metadata: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://w...\narxiv_filename: A_Survey_on_Hallucination_in_Large_Language_Models_Principle...\narxiv_paper_markdown: None\ncitations: 79\nversions: 2\nid: 819\n-------------\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/2b469552-2f2d-480b-9438-2ae59071f53c"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":true,"cell_id":"527df4672114483c8e3b15334d550cc0","deepnote_cell_type":"markdown"},"source":"Define database function to insert scraping results","block_group":"4636c78c977f43b7b48896a49fc9bb5f"},{"cell_type":"code","metadata":{"id":"WT_D0XfPXrYR","source_hash":"57cbd1ff","execution_start":1710017967952,"execution_millis":717,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"3f7ccc20e42e42229ce39af07759da6b","deepnote_cell_type":"code"},"source":"def insert_scraping_results(url, html, status, query):    \n    conn = connection()\n    c = conn.cursor()\n    try:\n        # Check if the URL already exists in the table\n        c.execute('SELECT COUNT(*) FROM google_search_results WHERE url = %s', (url,))\n        count = c.fetchone()[0]\n\n        if count == 0:\n            # URL does not exist, insert new row\n            c.execute('''\n                INSERT INTO google_search_results (url, html, scraping_status, query)\n                VALUES (%s, %s, %s, %s)\n            ''', (url, html, status, query))\n        else:\n            # URL exists, skip inserting\n            print(\"URL already exists in google_search_results. Skipping insert.\")\n\n        # Commit the transaction\n        conn.commit()\n\n    except Exception as e:\n        # Rollback the transaction if an error occurs\n        conn.rollback()\n        print(f\"An error occurred: {e}. Transaction was rolled back.\")\n    if conn:\n        conn.close()\n\n# Example\ninsert_scraping_results('https://www.topbots.com/top-llm-research-papers-2023/', '<html lang=\"en-US\"><head>..</html>', 200, 'example query')","block_group":"c4c4624363304a04932801a192ba3f05","execution_count":108,"outputs":[{"name":"stdout","text":"URL already exists in google_search_results. Skipping insert.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/17c8d1fd-90ca-4ed0-9416-bb53c3dc42f8"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"eaaf737f5c4048258a60100fe87dde31","deepnote_cell_type":"text-cell-p"},"source":"define a database function to check for processed markdown","block_group":"5c894e5199a94f29a3984861b3de9b24"},{"cell_type":"code","metadata":{"source_hash":"1bb61aa3","execution_start":1709953227326,"execution_millis":567,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"8488807ff1454b9ab7065334b52b645d","deepnote_cell_type":"code"},"source":"def check_processed_markdown(url: str) -> bool:\n    conn = connection()\n    \"\"\"Check if the markdown for a given URL has already been processed.\"\"\"\n    c = conn.cursor()\n    c.execute(\"SELECT processed_markdown FROM google_search_results WHERE url = %s\", (url,))\n    result = c.fetchone()\n    if result and result[0]:\n        # If there's processed markdown, return True\n        return True\n    return False\n    if conn:\n        conn.close()\n\n# Example usage:\nurl = 'https://www.topbots.com/top-llm-research-papers-2023/'\ncheck_processed_markdown(url) ","block_group":"615a3e57d9ff43e6b6bcf28399282cac","execution_count":53,"outputs":[{"name":"stdout","text":"You are connected to -  ('PostgreSQL 15.1 (Ubuntu 15.1-1.pgdg20.04+1) on aarch64-unknown-linux-gnu, compiled by gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0, 64-bit',)\n","output_type":"stream"},{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"False"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/1290e21f-fba5-4971-a537-39f57c9eb3ac"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"c50c7d0f062044749a10a0ce12f60140","deepnote_cell_type":"text-cell-p"},"source":"define a database function to insert processed markdown","block_group":"97d4ceb2ae3f431199e3f7c3c91da9f3"},{"cell_type":"code","metadata":{"source_hash":"1ef6728b","execution_start":1709953227900,"execution_millis":603,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"8004aacb12f74d1cac30c562d5857c0b","deepnote_cell_type":"code"},"source":"def insert_processed_markdown(url: str, processed_markdown: dict):  # processed_markdown should be a dict based on usage\n    try:\n        conn = connection()\n        c = conn.cursor()\n        \n        # First, check if the URL exists in the database\n        c.execute('SELECT COUNT(*) FROM google_search_results WHERE url = %s', (url,))\n        url_exists = c.fetchone()[0]\n        \n        if url_exists:\n            # Convert processed_markdown to a JSON string\n            processed_markdown_str = json.dumps(processed_markdown, indent=4)  # Assuming processed_markdown is always a dict based on your usage\n            \n            # Update the row where the URL matches, setting the processed_markdown column\n            c.execute('''\n                UPDATE google_search_results \n                SET processed_markdown = %s \n                WHERE url = %s;\n            ''', (processed_markdown_str, url))\n            conn.commit()\n            print(f\"Processed markdown inserted successfully for URL: {url}\")\n        else:\n            print(f\"No entry found in the database for URL: {url}. Update skipped.\")\n        \n    except Exception as e:\n        print(f\"An error occurred while inserting processed markdown: {e}\")\n    finally:\n        if conn:\n            conn.close()\n            \nurl = 'https://test.url'\nprocessed_markdown = {\n    \"Function call\": \"Page\",\n    \"args\": {\n        \"title\": \"Top academic papers on LLMs\",\n        \"summary\": \"A list of academic papers and resources related to Large Language Models (LLMs) and their applications.\",\n        \"paragraphs\": [\n            {\n                \"paper_title\": \"Awesome-LLM-hallucination\",\n                \"content\": \"LLM hallucination paper list.\",\n                \"links\": [\n                    {\"url\": \"https://github.com/LuckyyySTA/Awesome-LLM-hallucination\"}\n                ]\n            },\n            {\n                \"paper_title\": \"awesome-hallucination-detection\",\n                \"content\": \"List of papers on hallucination detection in LLMs.\",\n                \"links\": [\n                    {\"url\": \"https://github.com/EdinburghNLP/awesome-hallucination-detection\"}\n                ]\n            },\n            {\n                \"paper_title\": \"LLMsPracticalGuide\",\n                \"content\": \"A curated (still actively updated) list of practical guide resources of LLMs\",\n                \"links\": [\n                    {\"url\": \"https://github.com/Mooler0410/LLMsPracticalGuide\"}\n                ]\n            },\n            # Add other papers here in the same format\n        ]\n    }\n}\n\ninsert_processed_markdown(url, processed_markdown)","block_group":"65dc6a72009e4a5c94b853fdac5b0d0d","execution_count":54,"outputs":[{"name":"stdout","text":"You are connected to -  ('PostgreSQL 15.1 (Ubuntu 15.1-1.pgdg20.04+1) on aarch64-unknown-linux-gnu, compiled by gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0, 64-bit',)\nNo entry found in the database for URL: https://test.url. Update skipped.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/0ac9c14f-37dd-4ee8-82e2-6444f3c5bc67"},{"cell_type":"markdown","metadata":{"id":"91Izl-tUsvYs","deepnote_app_block_visible":true,"cell_id":"289b7bd7049649fbad72fcaf3408d521","deepnote_cell_type":"markdown"},"source":"### Get metadata from arxiv for the paper","block_group":"a4e1182f717243be889675cfa4369496"},{"cell_type":"code","metadata":{"id":"QShBS-KWqTqD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"127f03ce-502d-4912-c123-b7b1129df144","source_hash":"356c3982","execution_start":1709953228504,"execution_millis":217,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"65fab026a41b438180be639a7ce83dee","deepnote_cell_type":"code"},"source":"import xml.etree.ElementTree as ET\n\ndef fetch_arxiv_paper_from_url(arxiv_url):\n    # Extract the arXiv ID from the provided URL\n    arxiv_id = arxiv_url.split('/')[-1]\n    # Ensure that .pdf is not part of the arXiv ID\n    arxiv_id = arxiv_id.replace('.pdf', '')  # Remove '.pdf' if it's part of the ID\n\n    print(\"Fetching information for arXiv ID:\", arxiv_id)\n\n    # Define the base URL for the arXiv API\n    base_url = 'http://export.arxiv.org/api/query?'\n    query_params = 'id_list={}&max_results=1'.format(arxiv_id)\n    final_url = base_url + query_params  # Construct the final URL\n    print(\"Final API Request URL:\", final_url)  # Debug: print the URL to be requested\n\n    # Make the request\n    response = requests.get(final_url)\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        print(\"Raw XML response received\")\n        xml_data = response.text\n        root = ET.fromstring(xml_data)\n        ns = {'atom': 'http://www.w3.org/2005/Atom'}  # Namespace for parsing\n\n        # Extract paper details\n        link_element = root.find('.//atom:entry/atom:link[@rel=\"related\"]', ns)\n        if link_element is not None:\n            pdf_url = link_element.attrib['href']\n        else:\n            pdf_url = None\n        title = root.find('.//atom:entry/atom:title', ns).text.strip()\n        abstract = root.find('.//atom:entry/atom:summary', ns).text.strip()\n        published_date = root.find('.//atom:entry/atom:published', ns).text.strip()\n\n        # Extract authors\n        authors = [author.find('atom:name', ns).text for author in root.findall('.//atom:entry/atom:author', ns)]\n\n        # Generate a sanitized file name from the title\n        file_name = title.replace(':', '').replace(' ', '_') + '.pdf'\n\n        # Print extracted information for debugging\n        print(f\"PDF URL: {pdf_url}\")\n        print(f\"Title: {title}\")\n        print(f\"File Name: {file_name}\")\n        print(f\"Abstract: {abstract[:100]}...\" if len(abstract) > 100 else abstract)\n        print(f\"Published Date: {published_date}\")\n        print(f\"Authors: {', '.join(authors)}\")\n\n        # Return the collected information\n        return xml_data, pdf_url, title, file_name, abstract, published_date, authors\n    else:\n        print(\"Failed to fetch data from arXiv API. Status code:\", response.status_code)\n        return None, None, None, None, None, None, None\n\n# Example usage\narxiv_url = 'https://arxiv.org/abs/2302.13971'\nfetch_arxiv_paper_from_url(arxiv_url)","block_group":"3c4bf3e6017046bca5920f5fb49096e9","execution_count":55,"outputs":[{"name":"stdout","text":"Fetching information for arXiv ID: 2302.13971\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2302.13971&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2302.13971v1\nTitle: LLaMA: Open and Efficient Foundation Language Models\nFile Name: LLaMA_Open_and_Efficient_Foundation_Language_Models.pdf\nAbstract: We introduce LLaMA, a collection of foundation language models ranging from\n7B to 65B parameters. We...\nPublished Date: 2023-02-27T17:11:15Z\nAuthors: Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample\n","output_type":"stream"},{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3D2302.13971%26start%3D0%26max_results%3D1\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=2302.13971&amp;start=0&amp;max_results=1</title>\\n  <id>http://arxiv.org/api/qJuhZNxbRqWajNrNkNtkRSmyBuQ</id>\\n  <updated>2024-03-08T00:00:00-05:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/2302.13971v1</id>\\n    <updated>2023-02-27T17:11:15Z</updated>\\n    <published>2023-02-27T17:11:15Z</published>\\n    <title>LLaMA: Open and Efficient Foundation Language Models</title>\\n    <summary>  We introduce LLaMA, a collection of foundation language models ranging from\\n7B to 65B parameters. We train our models on trillions of tokens, and show that\\nit is possible to train state-of-the-art models using publicly available\\ndatasets exclusively, without resorting to proprietary and inaccessible\\ndatasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks,\\nand LLaMA-65B is competitive with the best models, Chinchilla-70B and\\nPaLM-540B. We release all our models to the research community.\\n</summary>\\n    <author>\\n      <name>Hugo Touvron</name>\\n    </author>\\n    <author>\\n      <name>Thibaut Lavril</name>\\n    </author>\\n    <author>\\n      <name>Gautier Izacard</name>\\n    </author>\\n    <author>\\n      <name>Xavier Martinet</name>\\n    </author>\\n    <author>\\n      <name>Marie-Anne Lachaux</name>\\n    </author>\\n    <author>\\n      <name>Timothée Lacroix</name>\\n    </author>\\n    <author>\\n      <name>Baptiste Rozière</name>\\n    </author>\\n    <author>\\n      <name>Naman Goyal</name>\\n    </author>\\n    <author>\\n      <name>Eric Hambro</name>\\n    </author>\\n    <author>\\n      <name>Faisal Azhar</name>\\n    </author>\\n    <author>\\n      <name>Aurelien Rodriguez</name>\\n    </author>\\n    <author>\\n      <name>Armand Joulin</name>\\n    </author>\\n    <author>\\n      <name>Edouard Grave</name>\\n    </author>\\n    <author>\\n      <name>Guillaume Lample</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2302.13971v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2302.13971v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n',\n 'http://arxiv.org/pdf/2302.13971v1',\n 'LLaMA: Open and Efficient Foundation Language Models',\n 'LLaMA_Open_and_Efficient_Foundation_Language_Models.pdf',\n 'We introduce LLaMA, a collection of foundation language models ranging from\\n7B to 65B parameters. We train our models on trillions of tokens, and show that\\nit is possible to train state-of-the-art models using publicly available\\ndatasets exclusively, without resorting to proprietary and inaccessible\\ndatasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks,\\nand LLaMA-65B is competitive with the best models, Chinchilla-70B and\\nPaLM-540B. We release all our models to the research community.',\n '2023-02-27T17:11:15Z',\n ['Hugo Touvron',\n  'Thibaut Lavril',\n  'Gautier Izacard',\n  'Xavier Martinet',\n  'Marie-Anne Lachaux',\n  'Timothée Lacroix',\n  'Baptiste Rozière',\n  'Naman Goyal',\n  'Eric Hambro',\n  'Faisal Azhar',\n  'Aurelien Rodriguez',\n  'Armand Joulin',\n  'Edouard Grave',\n  'Guillaume Lample'])"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/a3742893-aed4-405f-b131-ab7bef7410e9"},{"cell_type":"markdown","metadata":{"id":"i9A5UfGBstA0","deepnote_app_block_visible":true,"cell_id":"82738a7559f34ccdad8b031ba05fd7d5","deepnote_cell_type":"markdown"},"source":"### Download pdf of the paper","block_group":"9329080b7fb34539a821e604c0875e0c"},{"cell_type":"code","metadata":{"id":"fZwslypIsf-4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"01af4fd0-2b43-4886-e0ef-eac8ed71e1cf","source_hash":"de2044b4","execution_start":1709953228724,"execution_millis":229,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"2f493d40fd38496d90c90a57c8064805","deepnote_cell_type":"code"},"source":"def download_pdf(pdf_url, file_name):\n    # Create the \"papers\" directory if it doesn't exist\n    papers_dir = \"papers\"\n    if not os.path.exists(papers_dir):\n        os.makedirs(papers_dir)\n\n    # Construct the full file path\n    file_path = os.path.join(papers_dir, file_name)\n\n    # Check if the file already exists\n    if os.path.exists(file_path):\n        print(\"The paper already exists.\")\n        return file_path  # Return the file path\n\n    # Send a GET request to download the PDF\n    response = requests.get(pdf_url)\n\n    # Check if the request was successful\n    if response.status_code == 200:\n        # Write the PDF content to the file\n        with open(file_path, 'wb') as f:\n            f.write(response.content)\n        print(\"The paper has been downloaded successfully.\")\n        return file_path  # Return the file path\n    else:\n        # Return a status error message\n        error_message = f\"Failed to download the paper. Status code: {response.status_code}\"\n        return error_message\n\n# Example usage\ndownload_pdf('http://arxiv.org/pdf/2302.13971v1', 'LLaMA_Open_and_Efficient_Foundation_Language_Models.pdf')\n\n","block_group":"221abd5c1c544a869145d9f714468673","execution_count":56,"outputs":[{"name":"stdout","text":"The paper already exists.\n","output_type":"stream"},{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"'papers/LLaMA_Open_and_Efficient_Foundation_Language_Models.pdf'"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/7086a77a-3cf0-4432-9ddc-5d28f54a2a4b"},{"cell_type":"markdown","metadata":{"id":"NlHg6Z20sqKH","deepnote_app_block_visible":true,"cell_id":"b7a1786b345c43c99f2b71a25a97c965","deepnote_cell_type":"markdown"},"source":"### Convert pdf into markdown","block_group":"a23ae86f5c844865af4511949a641b93"},{"cell_type":"code","metadata":{"id":"PCakTs60tTH1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba2f97f5-42ce-4182-ea5e-4ebb15f13246","source_hash":"55b486db","execution_start":1709953228959,"execution_millis":2623,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"f53abd56a6894ade81db76791227ce9f","deepnote_cell_type":"code"},"source":"import nest_asyncio\nfrom llama_parse import LlamaParse\n\n# This function will convert a given PDF file to Markdown format using LlamaParse\ndef convert_pdf_to_markdown(file_name):\n    # Necessary for running async code in notebooks or scripts\n    nest_asyncio.apply()\n\n    # Initialize the LlamaParse parser\n    parser = LlamaParse(\n        api_key=llamaindex_api_key,\n        result_type=\"markdown\",  # Choose \"markdown\" as the output format\n        verbose=True,  # Enable verbose output to see detailed logs\n    )\n    \n    # Define the path to your PDF file\n    pdf_file_path = os.path.join(\"./papers/\", file_name)\n    print(pdf_file_path, \"type:\", type(pdf_file_path))\n    # Convert the PDF to Markdown\n    # This is a synchronous call, you can also use asynchronous calls as shown in the documentation\n    documents = parser.load_data(pdf_file_path)\n\n    # Return the converted documents\n    return documents\n\n# Define the path to your PDF file\nfile_name = \"Retrieval-Augmented_Generation_for_Knowledge-Intensive_NLP_Tasks.pdf\"\ndocuments = convert_pdf_to_markdown(file_name)","block_group":"aa9b48dc38d0416486e6dd513632f311","execution_count":57,"outputs":[{"name":"stdout","text":"./papers/Retrieval-Augmented_Generation_for_Knowledge-Intensive_NLP_Tasks.pdf type: <class 'str'>\nStarted parsing the file under job_id 6a8f5721-ae50-4ddc-90a3-6bb2dbddeb07\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/5f28d8a0-75fc-4aa2-9e0f-ba72b4bdad9f"},{"cell_type":"code","metadata":{"id":"nTLmIr8AwpmG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af063990-1cfb-4b52-c74a-9294984976fd","source_hash":"8d5f8090","execution_start":1709953231585,"execution_millis":293,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"c0e822e8b52e437c941781cb6af4050d","deepnote_cell_type":"code"},"source":"markdown_content = None\nif documents:\n    # Assuming the first document contains the content\n    # Use the get_text() method to retrieve the Markdown content\n    markdown_content = documents[0].get_text()\n    print(markdown_content)\n\n    # Optionally, write the markdown content to a file\n    with open('converted_markdown.md', 'w', encoding='utf-8') as markdown_file:\n        markdown_file.write(markdown_content)","block_group":"3d6ca6c2ca164b4c92462bdbaaded69e","execution_count":58,"outputs":[{"name":"stdout","text":"## Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n\nPatrick Lewis†‡, Ethan Perez⋆, Aleksandra Piktus†, Fabio Petroni†, Vladimir Karpukhin†, Naman Goyal†, Heinrich Küttler†\n\narXiv:2005.11401v4 [cs.CL] 12 Apr 2021\n\nMike Lewis†, Wen-tau Yih†, Tim Rocktäschel†‡, Sebastian Riedel†‡, Douwe Kiela†\n\n†Facebook AI Research; ‡University College London; ⋆New York University;\n\nplewis@fb.com\n\n### Abstract\n\nLarge pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\n\n### Introduction\n\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowledge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have downsides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations” [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results.\n---\n## Define \"middle ear\"(x)\n\nThe middle ear includes the tympanic cavity and the three ossicles.\n\n## Question Answering:\n\n|Question Query|Query|Retriever p|η|Document|Generator p|θ|\n|---|---|---|---|---|---|---|\n|Barack Obama was born in Hawaii.(x)|Encoder|(Non-Parametric)|Index|(Parametric)|Answer Generation|supports (y)|\n\n## Fact Verification: Fact Query\n\nThe Divine Comedy (x)\n\n## Jeopardy Question Generation:\n\nAnswer Query\n\nFigure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents. but have only explored open-domain extractive question answering. Here, we bring hybrid parametric and non-parametric memory to the “workhorse of NLP,” i.e. sequence-to-sequence (seq2seq) models. We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose fine-tuning approach which we refer to as retrieval-augmented generation (RAG). We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The retriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART [32]) then conditions on these latent documents together with the input to generate the output. We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG can be fine-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned. There has been extensive previous work proposing architectures to enrich systems with non-parametric memory which are trained from scratch for specific tasks, e.g. memory networks [64, 55], stack-augmented networks [25] and memory layers [30]. In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge. Crucially, by using pre-trained access mechanisms, the ability to access knowledge is present without additional training. Our results highlight the benefits of combining parametric and non-parametric memory with generation for knowledge-intensive tasks—tasks that humans could not reasonably be expected to perform without access to an external knowledge source. Our RAG models achieve state-of-the-art results on open Natural Questions [29], WebQuestions [3] and CuratedTrec [2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [24]. Despite these being extractive tasks, we find that unconstrained generation outperforms previous extractive approaches. For knowledge-intensive generation, we experiment with MS-MARCO [1] and Jeopardy question generation, and we find that our models generate responses that are more factual, specific, and diverse than a BART baseline. For FEVER [56] fact verification, we achieve results within 4.3% of state-of-the-art pipeline models which use strong retrieval supervision. Finally, we demonstrate that the non-parametric memory can be replaced to update the models’ knowledge as the world changes.\n\n## Methods\n\nWe explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y. As shown in Figure 1, our models leverage two components: (i) a retriever pη(z|x) with parameters η that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator pθ(yi|x, z, y1:i−1) parametrized\n\n1 Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transformers Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/\n---\n## by θ that generates a current token based on a context of the previous i − 1 tokens y1:i−1, the original input x and a retrieved passage z.\n\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable. We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. The second approach, RAG-Token, can predict each target token based on a different document. In the following, we formally introduce both models and then describe the pη and pθ components, as well as the training and decoding procedure.\n\n### Models\n\n|RAG-Sequence Model|The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized,|\n|---|---|\n| |pRAG-Sequence(y|x) ≈ pη(z|x)pθ(y|x, z) = pη(z|x) Σ pθ(yi|x, z, y1:i−1) z∈top-k(p(·|x)) z∈top-k(p(·|x)) i|\n|RAG-Token Model|In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we define:|\n| |pRAG-Token(y|x) ≈ Σ z∈top-k(p(·|x)) pη(z|x)pθ(yi|x, z, y1:i−1)|\n\nFinally, we note that RAG can be used for sequence classification tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\n\n### Retriever: DPR\n\nThe retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture: pη(z|x) ∝ exp d(z)⊤q(x) d(z) = BERTd(z), q(x) = BERTq(x) where d(z) is a dense representation of a document produced by a BERTBASE document encoder [8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(pη(·|x)), the list of k documents z with highest prior probability pη(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and Natural Questions [29]. We refer to the document index as the non-parametric memory.\n\n### Generator: BART\n\nThe generator component pθ(yi|x, z, y1:i−1) could be modelled using any encoder-decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them. BART was pre-trained using a denoising objective and a variety of different noising functions. It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32]. We refer to the BART generator parameters θ as the parametric memory henceforth.\n\n### Training\n\nWe jointly train the retriever and generator components without any direct supervision on what document should be retrieved. Given a fine-tuning training corpus of input/output pairs (xj, yj), we\n---\n## Decoding\n\nAt test time, RAG-Sequence and RAG-Token require different ways to approximate arg max y p(y|x).\n\n|RAG-Token| |\n|---|---|\n|The RAG-Token model can be seen as a standard, autoregressive seq2seq generator with transition probability: p'θ(yi|x, y1:i-1) = Σz∈top-k(p(·|x)) pη(zi|x)pθ(yi|x, zi, y1:i-1) To decode, we can plug p'θ(yi|x, y1:i-1) into a standard beam decoder.| |\n\n|RAG-Sequence| |\n|---|---|\n|For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per-token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using pθ(yi|x, z, y1:i-1). This yields a set of hypotheses Y, some of which may not have appeared in the beams of all documents. To estimate the probability of a hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with pη(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as “Thorough Decoding.” For longer output sequences, |Y| can become large, requiring many forward passes. For more efficient decoding, we can make a further approximation that pθ(y|x, zi) ≈ 0 where y was not generated during beam search from x, zi. This avoids the need to run additional forward passes once the candidate set Y has been generated. We refer to this decoding procedure as “Fast Decoding.”| |\n\n## Experiments\n\nWe experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. [31] and Karpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents. We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37]. During training, we retrieve the top k documents for each query. We consider k ∈ {5, 10} for training and set k for test time using dev data. We now discuss experimental details for each task.\n\n## Open-domain Question Answering\n\nOpen-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20]. We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers. We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge. We also compare to “Closed-Book QA” approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge. We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24]. WebQuestions (WQ) [3] and CuratedTrec (CT) [2]. As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.\n\n## Abstractive Question Answering\n\nRAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG’s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat\n---\nMSMARCO as an open-domain abstractive QA task. MSMARCO has some questions that cannot be answered in a way that matches the reference answer without access to the gold passages, such as \"What is the weather in Volcano, CA?\" so performance will be lower without using gold passages. We also note that some MSMARCO questions cannot be answered using Wikipedia alone. Here, RAG can rely on parametric knowledge to generate reasonable responses.\n\nJeopardy Question Generation\n\nTo evaluate RAG’s generation abilities in a non-QA setting, we study open-domain question generation. Rather than use questions from standard open-domain QA tasks, which typically consist of short, simple questions, we propose the more demanding task of generating Jeopardy questions. Jeopardy is an unusual format that consists of trying to guess an entity from a fact about that entity. For example, \"The World Cup\" is the answer to the question \"In 1986 Mexico scored as the first country to host this international sports competition twice.\" As Jeopardy questions are precise, factual statements, generating Jeopardy questions conditioned on their answer entities constitutes a challenging knowledge-intensive generation task.\n\nWe use the splits from SearchQA [10], with 100K train, 14K dev, and 27K test examples. As this is a new task, we train a BART model for comparison. Following [67], we evaluate using the SQuAD-tuned Q-BLEU-1 metric [42]. Q-BLEU is a variant of BLEU with a higher weight for matching entities and has higher correlation with human judgment for question generation than standard metrics. We also perform two human evaluations, one to assess generation factuality, and one for specificity. We define factuality as whether a statement can be corroborated by trusted external sources, and specificity as high mutual dependence between the input and output [33]. We follow best practice and use pairwise comparative evaluation [34]. Evaluators are shown an answer and two generated questions, one from BART and one from RAG. They are then asked to pick one of four options—question A is better, question B is better, both are good, or neither is good.\n\nFact Verification\n\nFEVER [56] requires classifying whether a natural language claim is supported or refuted by Wikipedia, or whether there is not enough information to decide. The task requires retrieving evidence from Wikipedia relating to the claim and then reasoning over this evidence to classify whether the claim is true, false, or unverifiable from Wikipedia alone. FEVER is a retrieval problem coupled with a challenging entailment reasoning task. It also provides an appropriate testbed for exploring the RAG models’ ability to handle classification rather than generation. We map FEVER class labels (supports, refutes, or not enough info) to single output tokens and directly train with claim-class pairs. Crucially, unlike most other approaches to FEVER, we do not use supervision on retrieved evidence. In many real-world applications, retrieval supervision signals aren’t available, and models that do not require such supervision will be applicable to a wider range of tasks. We explore two variants: the standard 3-way classification task (supports/refutes/not enough info) and the 2-way (supports/refutes) task studied in Thorne and Vlachos [57]. In both cases we report label accuracy.\n\nResults\n\nOpen-domain Question Answering\n\n|Task|RAG|State-of-the-art Models|\n|---|---|---|\n|All four open-domain QA tasks|RAG sets a new state of the art|Only on the T5-comparable split for TQA|\n|RAG combines the generation flexibility of the \"closed-book\" (parametric only) approaches and the performance of \"open-book\" retrieval-based approaches| | |\n|Unlike REALM and T5+SSM, RAG enjoys strong results without expensive, specialized \"salient span masking\" pre-training [20]| | |\n|RAG's retriever is initialized using DPR's retriever, which uses retrieval supervision on Natural Questions and TriviaQA| | |\n|RAG compares favorably to the DPR QA system, which uses a BERT-based \"cross-encoder\" to re-rank documents, along with an extractive reader| | |\n|RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art performance| | |\n\nThere are several advantages to generating answers even when it is possible to extract them. Documents with clues about the answer but do not contain the answer verbatim can still contribute towards a correct answer being generated, which is not possible with standard extractive approaches, leading\n---\n## Table 1: Open-Domain QA Test Scores\n\n|Model|NQ|TQA|WQ|CT|\n|---|---|---|---|---|\n|Closed Book T5-11B [52]|34.5|- /50.1|37.4|-|\n|Book T5-11B+SSM[52]|36.6|- /60.5|44.7|-|\n|Open Book REALM [20]|40.4|- / -|40.7|46.8|\n|Book DPR [26]|41.5|57.9/ -|41.1|50.6|\n|RAG-Token|44.1|55.2/66.1|45.5|50.0|\n|RAG-Seq.|44.5|56.8/68.0|45.2|52.2|\n\n## Table 2: Generation and classification Test Scores\n\n|Model|Jeopardy|MSMARCO|FVR3|FVR2|\n|---|---|---|---|---|\n|B-1|QB-1|R-L|B-1|Label Acc.|\n|BART|15.1|19.7|38.2|41.6|\n|RAG-Tok.|17.3|22.2|40.1|41.5|\n|RAG-Seq.|14.7|21.4|40.8|44.2|\n\n4.2 Abstractive Question Answering\n\nAs shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with specific information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we find that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see §4.5).\n\n4.3 Jeopardy Question Generation\n\nTable 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model. Evaluators also find RAG generations to be more specific by a large margin. Table 3 shows typical generations from each model.\n\nJeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating “Sun”, the posterior is high for document 2 which mentions “The Sun Also Rises”. Similarly, document 1 dominates the posterior when “A Farewell to Arms” is generated. Intriguingly, after the first token of each book is generated, the document posterior flattens. This observation suggests that the generator can complete the titles without depending on specific documents. In other words, the model’s parametric knowledge is sufficient to complete the titles. We find evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \"The Sun. BART completes the generation \"The Sun Also Rises\" is a novel by this author of \"The Sun Also Rises\" indicating the title \"The Sun Also Rises\" is stored in BART’s parameters. Similarly, BART will complete the partial decoding \"The Sun Also Rises\" is a novel by this author of \"A with \"The Sun Also Rises\" is a novel by this author of \"A Farewell to Arms\". This example shows how parametric and non-parametric memories work together—the non-parametric component helps to guide the generation, drawing out specific knowledge stored in the parametric memory.\n\n4.4 Fact Verification\n\nTable 2 shows our results on FEVER. For 3-way classification, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-specific architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require.\n---\n## Document 1\n\nHis works are considered classics of American literature ... His wartime experiences formed the basis for his novel \"A Farewell to Arms\" (1929) ...\n\n## Document 2\n\n... artists of the 1920s \"Lost Generation\" expatriate community. His debut novel, \"The Sun Also Rises\", was published in 1926.\n\nFigure 2: RAG-Token document posterior p(zi|x, yi, y−i) for each generated token for input “Hemingway\" for Jeopardy generation with 5 retrieved documents. The posterior for document 1 is high when generating “A Farewell to Arms\" and for document 2 when generating “The Sun Also Rises\".\n\n|Task|Input|Model|Generation|\n|---|---|---|---|\n|define middle ear|BART|?|The middle ear is the part of the ear between the middle ear and the nose.|\n| |RAG-T| |The middle ear is the portion of the ear internal to the eardrum.|\n|MS-MARCO|what currency needed in Scotland|BART|The currency needed in Scotland is Pound sterling.|\n| |RAG-T| |Pound is the currency needed in Scotland.|\n| |RAG-S| |The currency needed in Scotland is the pound sterling.|\n| |BART|?|This state has the largest number of counties in the U.S.|\n|Jeopardy Question Generation|Washington|RAG-T|It’s the only U.S. state named for a U.S. president|\n| |RAG-S| |It’s the state where you’ll find Mount Rainier National Park|\n| |BART|*|This epic poem by Dante is divided into 3 parts: the Inferno, the Purgatorio & the Purgatorio|\n|The Divine Comedy|RAG-T| |Dante’s \"Inferno\" is the first part of this epic poem|\n| |RAG-S| |This 14th century work is divided into 3 sections: \"Inferno\", \"Purgatorio\" & \"Paradiso\"|\n\nFor 2-way classification, we compare against Thorne and Vlachos [57], who train RoBERTa [35] to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy within 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence. We also analyze whether documents retrieved by RAG correspond to documents annotated as gold evidence in FEVER. We calculate the overlap in article titles between the top k documents retrieved by RAG and gold evidence annotations. We find that the top retrieved document is from a gold article in 71% of cases, and a gold article is present in the top 10 retrieved articles in 90% of cases.\n\n## Additional Results\n\nGeneration Diversity: Section 4.3 shows that RAG models are more factual and specific than BART for Jeopardy question generation. Following recent work on diversity-promoting decoding, we also investigate generation diversity by calculating the ratio of distinct ngrams to total ngrams generated by different models. Table 5 shows that RAG-Sequence’s generations are more diverse than RAG-Token’s, and both are significantly more diverse than BART without needing any diversity-promoting decoding.\n\nRetrieval Ablations: A key feature of RAG is learning to retrieve relevant information for the task. To assess the effectiveness of the retrieval mechanism, we run ablations where we freeze the retriever during training. As shown in Table 6, learned retrieval improves results for all tasks.\n\nWe compare RAG’s dense retriever to a word overlap-based BM25 retriever. Here, we replace RAG’s retriever with a fixed BM25 system, and use BM25 retrieval scores as logits when calculating p(z|x). Table 6 shows the results. For FEVER, BM25 performs best, perhaps since FEVER claims are heavily entity-centric and thus well-suited for word overlap-based retrieval. Differentiable retrieval improves results on all other tasks, especially for Open-Domain QA, where it is crucial.\n\nIndex hot-swapping: An advantage of non-parametric memory models like RAG is that knowledge can be easily updated at test time. Parametric-only models like T5 or BART need further training to update their behavior as the world changes. To demonstrate, we build an index using the DrQA Wikipedia dump from December 2016 and compare outputs from RAG using this index to the newer index from our main results (December 2018). We prepare a list of 82 world leaders who had changed\n---\n## Table 4: Human assessments for the Jeopardy Question Generation Task\n\n| |Factuality|Specificity|\n|---|---|---|\n|BART better|7.1%|16.8%|\n|RAG better|42.7%|37.4%|\n|Both good|11.7%|11.8%|\n|Both poor|17.7%|6.9%|\n|No majority|20.8%|20.1%|\n\n## Table 5: Ratio of distinct to total tri-grams for generation tasks\n\n| |MSMARCO|Jeopardy QGen|\n|---|---|---|\n|Gold|89.6%|90.0%|\n|BART|70.7%|32.4%|\n|RAG-Token|77.8%|46.8%|\n|RAG-Seq.|83.5%|53.8%|\n\n## Table 6: Ablations on the dev set\n\n|Model|NQ|TQA|WQ|CT|Jeopardy-QGen|MSMarco|FVR-3|FVR-2|\n|---|---|---|---|---|---|---|---|---|\n|RAG-Token-BM25|29.7|41.5|32.1|33.1|17.5|22.3|55.5|48.4|75.1|91.6|\n|RAG-Sequence-BM25|31.8|44.1|36.6|33.8|11.1|19.5|56.5|46.9|\n|RAG-Token-Frozen|37.8|50.1|37.1|51.1|16.7|21.7|55.9|49.4|72.9|89.4|\n|RAG-Sequence-Frozen|41.2|52.1|41.8|52.6|11.8|19.6|56.7|47.3|\n|RAG-Token|43.5|54.8|46.5|51.9|17.9|22.6|56.2|49.4|74.5|90.6|\n|RAG-Sequence|44.0|55.8|44.9|53.4|15.3|21.5|57.2|47.5|\n\nBetween these dates and use a template “Who is {position}?” (e.g. “Who is the President of Peru?”) to query our NQ RAG model with each index. RAG answers 70% correctly using the 2016 index for 2016 world leaders and 68% using the 2018 index for 2018 world leaders. Accuracy with mismatched indices is low (12% with the 2018 index and 2016 leaders, 4% with the 2016 index and 2018 leaders). This shows we can update RAG’s world knowledge by simply replacing its non-parametric memory.\n\nEffect of Retrieving more documents: Models are trained with either 5 or 10 retrieved latent documents, and we do not observe significant differences in performance between them. We have the flexibility to adjust the number of retrieved documents at test time, which can affect performance and runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.\n\n| |44|80|Bleu-1 / Rouge-L score|\n|---|---|---|---|\n| | |NQ Answer Recall @ K|56|\n|NQ Exact Match| |54| |\n| | | |RAG-Tok R-L| |\n| | | |RAG-Tok B-1| |\n| | | |RAG-Seq R-L| |\n| | | |RAG-Seq B-1| |\n\nFigure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall performance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.\n\n## Related Work\n\nSingle-Task Retrieval: Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering, fact checking, fact completion, long-form question answering, Wikipedia article generation, dialogue, translation, and language modeling. Our work unifies previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.\n---\n## General-Purpose Architectures for NLP\n\nPrior work on general-purpose architectures for NLP tasks has shown great success without the use of retrieval. A single, pre-trained language model has been shown to achieve strong performance on various classification tasks in the GLUE benchmarks [60, 61] after fine-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right, pre-trained language model could achieve strong performance across both discriminative and generative tasks. For further improvement, BART [32] and T5 [51, 52] propose a single, pre-trained encoder-decoder model that leverages bi-directional attention to achieve stronger performance on discriminative and generative tasks. Our work aims to expand the space of possible tasks with a single, unified architecture, by learning a retrieval module to augment pre-trained, generative language models.\n\n## Learned Retrieval\n\nThere is significant work on learning to retrieve documents in information retrieval, more recently with pre-trained, neural language models [44, 26] similar to ours. Some work optimizes the retrieval module to aid in a specific, downstream task such as question answering, using search [46], reinforcement learning [6, 63, 62], or a latent variable approach [31, 20] as in our work. These successes leverage different retrieval-based architectures and optimization techniques to achieve strong performance on a single task, while we show that a single retrieval-based architecture can be fine-tuned for strong performance on a variety of tasks.\n\n## Memory-based Architectures\n\nOur document index can be seen as a large external memory for neural networks to attend to, analogous to memory networks [64, 55]. Concurrent work [14] learns to retrieve a trained embedding for each entity in the input, rather than to retrieve raw text as in our work. Other work improves the ability of dialog models to generate factual text by attending over fact embeddings [15, 13]. A key feature of our memory is that it is comprised of raw text rather distributed representations, which makes the memory both (i) human-readable, lending a form of interpretability to our model, and (ii) human-writable, enabling us to dynamically update the model’s memory by editing the document index. This approach has also been used in knowledge-intensive dialog, where generators have been conditioned on retrieved text directly, albeit obtained via TF-IDF rather than end-to-end learnt retrieval [9].\n\n## Retrieve-and-Edit approaches\n\nOur method shares some similarities with retrieve-and-edit style approaches, where a similar training input-output pair is retrieved for a given input, and then edited to provide a final output. These approaches have proved successful in a number of domains including Machine Translation [18, 22] and Semantic Parsing [21]. Our approach does have several differences, including less of emphasis on lightly editing a retrieved item, but on aggregating content from several pieces of retrieved content, as well as learning latent retrieval, and retrieving evidence documents rather than related training pairs. This said, RAG techniques may work well in these settings, and could represent promising future work.\n\n## Discussion\n\nIn this work, we presented hybrid generation models with access to parametric and non-parametric memory. We showed that our RAG models obtain state of the art results on open-domain QA. We found that people prefer RAG’s generation over purely parametric BART, finding RAG more factual and specific. We conducted an thorough investigation of the learned retrieval component, validating its effectiveness, and we illustrated how the retrieval index can be hot-swapped to update the model without requiring any retraining. In future work, it may be fruitful to investigate if the two components can be jointly pre-trained from scratch, either with a denoising objective similar to BART or some another objective. Our work opens up new research directions on how parametric and non-parametric memories interact and how to most effectively combine them, showing promise in being applied to a wide variety of NLP tasks.\n---\n## Broader Impact\n\nThis work offers several positive societal benefits over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct benefit to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs.\n\nWith these advantages also come potential downsides: Wikipedia, or any potential external knowledge source, will probably never be entirely factual and completely devoid of bias. Since RAG can be employed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably to a lesser extent, including that it might be used to generate abuse, faked or misleading content in the news or on social media; to impersonate others; or to automate the production of spam/phishing content [54]. Advanced language models may also lead to the automation of various jobs in the coming decades [16]. In order to mitigate these risks, AI systems could be employed to fight against misleading content and automated spam/phishing.\n\n## Acknowledgments\n\nThe authors would like to thank the reviewers for their thoughtful and constructive feedback on this paper, as well as HuggingFace for their help in open-sourcing code to run RAG models. The authors would also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. EP thanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR PhD program.\n\n## References\n\n[1] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. arXiv:1611.09268 [cs], November 2016. URL http://arxiv.org/abs/1611.09268. arXiv: 1611.09268.\n[2] Petr Baudiš and Jan Šediv` y. Modeling of pe question answering task in pe yodaqa system. In International Conference of pe Cross-Language Evaluation Forum for European Languages, pages 222–228. Springer, 2015. URL https://link.springer.com/chapter/10.1007% 2F978-3-319-24027-5_20.\n[3] Jonapan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic Parsing on Freebase from Question-Answer Pairs. In Proceedings of pe 2013 Conference on Empirical Mepods in Natural Language Processing, pages 1533–1544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL http://www.aclweb.org/anpology/ D13-1160.\n[4] Bin Bi, Chenliang Li, Chen Wu, Ming Yan, and Wei Wang. Palm: Pre-training an autoencod- ing&autoregressive language model for context-conditioned generation. ArXiv, abs/2004.07159, 2020. URL https://arxiv.org/abs/2004.07159.\n[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer Open-Domain Questions. In Proceedings of pe 55p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 1870–1879, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://www.aclweb.org/anpology/P17-1171.\n[6] Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and Jonapan Berant. Coarse-to-fine question answering for long documents. In Proceedings of pe 55p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 209–220, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1020. URL https://www.aclweb.org/anpology/P17-1020.\n---\nChristopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Comprehension. arXiv:1710.10723 [cs], October 2017. URL http://arxiv.org/abs/1710.10723. arXiv: 1710.10723.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of pe 2019 Conference of pe Norp American Chapter of pe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://www.aclweb.org/anpology/N19-1423.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wizard of wikipedia: Knowledge-powered conversational agents. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=r1l73iRqKm.\nMatpew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. SearchQA: A New Q&A Dataset Augmented wip Context from a Search Engine. arXiv:1704.05179 [cs], April 2017. URL http://arxiv.org/abs/1704.05179. arXiv: 1704.05179.\nAngela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceedings of pe 56p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 889–898, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1082. URL https://www.aclweb.org/anpology/P18-1082.\nAngela Fan, Yacine Jernite, Epan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: Long form question answering. In Proceedings of pe 57p Annual Meeting of pe Association for Computational Linguistics, pages 3558–3567, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1346. URL https://www.aclweb.org/anpology/P19-1346.\nAngela Fan, Claire Gardent, Chloe Braud, and Antoine Bordes. Augmenting transformers wip KNN-based composite memory, 2020. URL https://openreview.net/forum?id=H1gx1CNKPH.\nThibault Févry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, and Tom Kwiatkowski. Entities as experts: Sparse memory access wip entity supervision. ArXiv, abs/2004.07202, 2020. URL https://arxiv.org/abs/2004.07202.\nMarjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wentau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16710.\nKatja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. When will AI exceed human performance? evidence from AI experts. CoRR, abs/1705.08807, 2017. URL http://arxiv.org/abs/1705.08807.\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282.\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, pages 5133–5140. AAAI press, 2018. 32nd AAAI Conference on Artificial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.\nKelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by editing prototypes. Transactions of pe Association for Computational Linguistics, 6:437–450, 2018. doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anpology/Q18-1031.\n---\n## References\n\n|[20]|Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. REALM: Retrieval-augmented language model pre-training. ArXiv, abs/2002.08909, 2020. URL https://arxiv.org/abs/2002.08909.|\n|---|---|\n|[21]|Tatsunori B Hashimoto, Kelvin Guu, Yonatan Oren, and Percy S Liang. A retrieve-and-edit framework for predicting structured outputs. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 10052–10062. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/8209-a-retrieve-and-edit-framework-for-predicting-structured-outputs.pdf.|\n|[22]|Nabil Hossain, Marjan Ghazvininejad, and Luke Zettlemoyer. Simple and effective retrieve-edit-rerank text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2532–2538, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.228. URL https://www.aclweb.org/anthology/2020.acl-main.228.|\n|[23]|Jeff Johnson, Matthijs Douze, and Hervé Jégou. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.08734, 2017. URL https://arxiv.org/abs/1702.08734.|\n|[24]|Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601–1611, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1147. URL https://www.aclweb.org/anthology/P17-1147.|\n|[25]|Armand Joulin and Tomas Mikolov. Inferring algorithmic patterns with stack-augmented recurrent nets. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1, NIPS’15, page 190–198, Cambridge, MA, USA, 2015. MIT Press. URL https://papers.nips.cc/paper/5857-inferring-algorithmic-patterns-with-stack-augmented-recurrent-nets.|\n|[26]|Vladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906, 2020. URL https://arxiv.org/abs/2004.04906.|\n|[27]|Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.|\n|[28]|Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412.6980.|\n|[29]|Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural Questions: a Benchmark for Question Answering Research. Transactions of the Association of Computational Linguistics, 2019. URL https://tomkwiat.users.x20web.corp.google.com/papers/natural-questions/main-1455-kwiatkowski.pdf.|\n|[30]|Guillaume Lample, Alexandre Sablayrolles, Marc’ Aurelio Ranzato, Ludovic Denoyer, and Herve Jegou. Large memory layers with product keys. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’ Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8548–8559. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf.|\n|[31]|Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association|\n---\n|Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.|BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461.|\n|---|---|\n|Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan.|A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110–119, San Diego, California, June 2016. Association for Computational Linguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/N16-1014.|\n|Margaret Li, Jason Weston, and Stephen Roller.|Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL https://arxiv.org/abs/1909.03087.|\n|Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He.|Robust neural machine translation with joint textual and phonetic embedding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3044–3049, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL https://www.aclweb.org/anthology/P19-1291.|\n|Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer.|Generating wikipedia by summarizing long sequences. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=Hyg0vbWC-.|\n|Yury A. Malkov and D. A. Yashunin.|Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:824–836, 2016. URL https://arxiv.org/abs/1603.09320.|\n|Gary Marcus.|The next decade in ai: four steps towards robust artificial intelligence. arXiv preprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177.|\n|Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rocktäschel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel.|How decoding strategies affect the verifiability of generated text. arXiv preprint arXiv:1911.03587, 2019. URL https://arxiv.org/abs/1911.03587.|\n|Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu.|Mixed precision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ.|\n|Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra.|Towards exploiting background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2322–2332, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255.|\n|Preksha Nema and Mitesh M. Khapra.|Towards a better metric for evaluating question generation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3950–3959, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/anthology/D18-1429.|\n|Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.|MS MARCO: A human generated machine reading comprehension dataset. In Tarek Richard Besold, Antoine Bordes, Artur S. d’Avila Garcez, and Greg Wayne, editors, Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic.|\n---\napproaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016, volume 1773 of CEUR Workshop Proceedings. CEUR-WS.org, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf.\n\n[44] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. arXiv preprint arXiv:1901.04085, 2019. URL https://arxiv.org/abs/1901.04085.\n\n[45] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-4009. URL https://www.aclweb.org/anthology/N19-4009.\n\n[46] Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe Kiela, and Kyunghyun Cho. Finding generalizable evidence by learning to convince q&a models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2402–2411, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.\n\n[47] Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463–2473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://www.aclweb.org/anthology/D19-1250.\n\n[48] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H. Miller, and Sebastian Riedel. How context affects language models’ factual predictions. In Automated Knowledge Base Construction, 2020. URL https://openreview.net/forum?id=025X0zPfn.\n\n[49] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving Language Understanding by Generative Pre-Training, 2018. URL https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf.\n\n[50] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners, 2019. URL https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.\n\n[51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv e-prints, 2019. URL https://arxiv.org/abs/1910.10683.\n\n[52] Adam Roberts, Colin Raffel, and Noam Shazeer. How much knowledge can you pack into the parameters of a language model? arXiv e-prints, 2020. URL https://arxiv.org/abs/2002.08910.\n\n[53] Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr., 3(4):333–389, April 2009. ISSN 1554-0669. doi: 10.1561/1500000019. URL https://doi.org/10.1561/1500000019.\n\n[54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, and Jian-Bing Wang. Release strategies and the social impacts of language models. ArXiv, abs/1908.09203, 2019.\n\n[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf.\n---\n# References\n\n[56] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In Proceedings of pe 2018 Conference of pe Norp American Chapter of pe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809–819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL https://www.aclweb.org/anpology/N18-1074.\n[57] James H. Thorne and Andreas Vlachos. Avoiding catastrophic forgetting in mitigating model biases in sentence-pair classification wip elastic weight consolidation. ArXiv, abs/2004.14366, 2020. URL https://arxiv.org/abs/2004.14366.\n[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanapan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5998–6008. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf.\n[59] Ashwin Vijayakumar, Michael Cogswell, Ramprasaap Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes. AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17329.\n[60] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of pe 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353–355, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5446. URL https://www.aclweb.org/anpology/W18-5446.\n[61] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3261–3275. Curran Associates, Inc., 2019. URL https://arxiv.org/abs/1905.00537.\n[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain question answering. In Sheila A. McIlraip and Kilian Q. Weinberger, editors, Proceedings of pe Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), pe 30p innovative Applications of Artificial Intelligence (IAAI-18), and pe 8p AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 5981–5988. AAAI Press, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16712.\n[63] Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, and Murray Campbell. Evidence aggregation for answer re-ranking in open-domain question answering. In ICLR, 2018. URL https://openreview.net/forum?id=rJl3yM-Ab.\n[64] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1410.3916.\n[65] Jason Weston, Emily Dinan, and Alexander Miller. Retrieve and refine: Improved sequence generation models for dialogue. In Proceedings of pe 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI, pages 87–92, Brussels, Belgium, October 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5713. URL https://www.aclweb.org/anpology/W18-5713.\n---\n## References\n\n[66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anpony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Huggingface’s transformers: State-of-pe-art natural language processing. ArXiv, abs/1910.03771, 2019.\n[67] Shiyue Zhang and Mohit Bansal. Addressing semantic drift in question generation for semi-supervised question answering. In Proceedings of pe 2019 Conference on Empirical Mepods in Natural Language Processing and pe 9p International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2495–2509, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1253. URL https://www.aclweb.org/anpology/D19-1253.\n[68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019. URL https://arxiv.org/abs/1909.03745.\n---\n## Appendices for Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n\n### Implementation Details\n\nFor Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models. For RAG-Sequence models, we report test results using 50 retrieved documents, and we use the Thorough Decoding approach since answers are generally short. We use greedy decoding for QA as we did not find beam search improved results. For Open-MSMarco and Jeopardy question generation, we report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence, and we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast Decoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.\n\n### Human Evaluation\n\n|Which sentence is more factually true?|Select option|\n|---|---|\n|Noje: Scna Guesucn?|snterzt \"The8r Nuso Rists S7lerce|\n|IncicateFich Farcncllic AM; on Im Iclbwng sentarces Is Mca luclualy Injb[ealecllo ZLbko Uaino cnoc urdoco| |\n\nFigure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions and a worked example appear when clicking \"view tool guide\".\n\nFigure 4 shows the user interface for human evaluation. To avoid any biases for screen position, which model corresponded to sentence A and sentence B was randomly selected for each example. Annotators were encouraged to research the topic using the internet, and were given detailed instructions and worked examples in a full instructions tab. We included some gold sentences in order to assess the accuracy of the annotators. Two annotators did not perform well on these examples and their annotations were removed from the results.\n\n### Training Setup Details\n\nWe train all RAG models and BART baselines using Fairseq [45]. We train with mixed precision floating point arithmetic, distributing training across 8, 32GB NVIDIA V100 GPUs, though training and inference can be run on one GPU. We find that doing Maximum Inner Product Search with FAISS is sufficiently fast on CPU, so we store document index vectors on CPU, requiring ∼ 100 GB of CPU memory for all of Wikipedia. After submission, We have ported our code to HuggingFace Transformers, which achieves equivalent performance to the previous version but is a cleaner and easier to use implementation. This version is also open-sourced. We also compress the document index using FAISS’s compression tools, reducing the CPU memory requirement to 36GB. Scripts to run experiments with RAG can be found at https://github.com/huggingface/transformers/blob/master/examples/rag/README.md and an interactive demo of a RAG model can be found at https://huggingface.co/rag/\n\n2. https://github.com/pytorch/fairseq\n\n3. https://github.com/huggingface/transformers\n---\n## Further Details on Open-Domain QA\n\nFor open-domain QA, multiple answer annotations are often available for a given question. These answer annotations are exploited by extractive models during training as typically all the answer annotations are used to find matches within documents when preparing training data. For RAG, we also make use of multiple annotation examples for Natural Questions and WebQuestions by training the model with each (q, a) pair separately, leading to a small increase in accuracy. For TriviaQA, there are often many valid answers to a given question, some of which are not suitable training targets, such as emoji or spelling variants. For TriviaQA, we filter out answer candidates if they do not occur in top 1000 documents for the query.\n\n## CuratedTrec preprocessing\n\nThe answers for CuratedTrec are given in the form of regular expressions, which has been suggested as a reason why it is unsuitable for answer-generation models [20]. To overcome this, we use a pre-processing step where we first retrieve the top 1000 documents for each query, and use the answer that most frequently matches the regex pattern as the supervision target. If no matches are found, we resort to a simple heuristic: generate all possible permutations for each regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\n\n## TriviaQA Evaluation setups\n\nThe open-domain QA community customarily uses public development datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading comprehension purposes. We report our results using the datasets splits used in DPR [26], which are consistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public TriviaQA Web Development split. Roberts et al. [52] used the TriviaQA official Wikipedia test set instead. Févry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See appendix of [14]). We report results on both test sets to enable fair comparison to both approaches. We find that our performance is much higher using the official Wiki test set, rather than the more conventional open-domain test set, which we attribute to the official Wiki test set questions being simpler to answer from Wikipedia.\n\n## Further Details on FEVER\n\nFor FEVER classification, we follow the practice from [32], and first re-generate the claim, and then classify using the representation of the final hidden state, before finally marginalizing across documents to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The first is to classify the claim as either \"Supported\", \"Refuted\" or \"Not Enough Info\", which is the task we explore in the main paper. FEVER’s other sub-task involves extracting sentences from Wikipedia as evidence supporting the classification prediction. As FEVER uses a different Wikipedia dump to us, directly tackling this task is not straightforward. We hope to address this in future work.\n\n## Null Document Probabilities\n\nWe experimented with adding \"Null document\" mechanism to RAG, similar to REALM [20] in order to model cases where no useful information could be retrieved for a given input. Here, if k documents were retrieved, we would additionally \"retrieve\" an empty document and predict a logit for the null document, before marginalizing over k + 1 predictions. We explored modelling this null document logit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or (iii) a neural network to predict the logit. We did not find that these improved performance, so in the interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents cannot always be retrieved, we observe that the model learns to always retrieve a particular set of documents for questions that are less likely to benefit from retrieval, suggesting that null document mechanisms may not be necessary for RAG.\n\n## Parameters\n\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of DPR, with 110M parameters each (although we do not train the document encoder ourselves) and 406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable.\n---\n|Task|Train|Development|Test|\n|---|---|---|---|\n|Natural Questions|79169|8758|3611|\n|TriviaQA|78786|8838|11314|\n|WebQuestions|3418|362|2033|\n|CuratedTrec|635|134|635|\n|Jeopardy Question Generation|97392|13714|26849|\n|MS-MARCO|153726|12468|101093*|\n|FEVER-3-way|145450|10000|10000|\n|FEVER-2-way|96966|6666|6666|\n\nparameters. The best performing \"closed-book\" (parametric only) open-domain QA model is T5-11B\nwith 11 Billion trainable parameters. The T5 model with the closest number of parameters to our\nmodels is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions [52],\nsubstantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/non-\nparametric models require far fewer trainable parameters for strong open-domain QA performance.\nThe non-parametric memory index does not consist of trainable parameters, but does consists of 21M\n728 dimensional vectors, consisting of 15.3B values. These can be easily be stored at 8-bit floating\npoint precision to manage memory and disk footprints.\n\n## Retrieval Collapse\n\nIn preliminary experiments, we observed that for some tasks such as story generation [11], the\nretrieval component would “collapse” and learn to retrieve the same documents regardless of the\ninput. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents,\nand the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit\nrequirement for factual knowledge in some tasks, or the longer target sequences, which could result\nin less informative gradients for the retriever. Perez et al. [46] also found spurious retrieval results\nwhen optimizing a retrieval component in order to improve performance on downstream tasks.\n\n## Number of instances per dataset\n\nThe number of training, development and test datapoints in each of our datasets is shown in Table 7.\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/0b4ab8e9-ea3f-4471-bca1-9dff2cb6124a"},{"cell_type":"markdown","metadata":{"id":"3tM61elq3hrj","deepnote_app_block_visible":true,"cell_id":"17ffcf9815084e5fa2002a2270ba5de0","deepnote_cell_type":"markdown"},"source":"### Get citations and number of versions from Google Scholar","block_group":"b8e3e9beee96482c8a18da4d133a0393"},{"cell_type":"code","metadata":{"id":"mwuv2gRw3mv-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdfaf190-a448-4bc6-9bd7-5ae42a5e41dd","source_hash":"6bb279e6","execution_start":1709953231875,"execution_millis":1272,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"3cbeef9dc096403499243ad238f9194e","deepnote_cell_type":"code"},"source":"from serpapi import GoogleSearch\n\ndef get_scholar_citations_versions(query_url):\n    params = {\n        \"api_key\": serp_api_key,  # Ensure serp_api_key is defined elsewhere\n        \"engine\": \"google_scholar\",\n        \"q\": query_url,\n        \"hl\": \"en\"\n    }\n\n    search = GoogleSearch(params)\n    results = search.get_dict()\n\n    # Initialize the return values\n    number_of_citations = None\n    number_of_versions = None\n\n    # Extracting number of citations and versions\n    if 'organic_results' in results:\n        if 'inline_links' in results['organic_results'][0]:\n            if 'cited_by' in results['organic_results'][0]['inline_links']:\n                number_of_citations = results[\"organic_results\"][0][\"inline_links\"][\"cited_by\"][\"total\"]\n\n            if 'versions' in results['organic_results'][0]['inline_links']:\n                number_of_versions = results[\"organic_results\"][0][\"inline_links\"][\"versions\"][\"total\"]\n\n    return number_of_citations, number_of_versions\n\nquery_url = 'https://arxiv.org/abs/2302.13971'\ncitations, versions = get_scholar_citations_versions(query_url)\nprint(\"Number of citations:\", citations)\nprint(\"Number of versions:\", versions)","block_group":"64707be5b9684185b05d52d700f0ecc3","execution_count":59,"outputs":[{"name":"stdout","text":"Number of citations: 4397\nNumber of versions: 13\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/bd042a61-7009-401f-9cdb-ab15bc70313a"},{"cell_type":"markdown","metadata":{"id":"u9eHATZLi5ZV","deepnote_app_block_visible":true,"cell_id":"7db90d63c5ee477fadc3fcaefa116c5e","deepnote_cell_type":"markdown"},"source":"### Gemini summary and relevance score","block_group":"303d9cd81b044716802ee7b71c614f28"},{"cell_type":"markdown","metadata":{"id":"-gQldNXOVd68","deepnote_app_block_visible":true,"cell_id":"8bd63746631d4fd888104de5728f7af1","deepnote_cell_type":"markdown"},"source":"Gemini Set up","block_group":"faa953eb4647427db8a2f9cea784cc67"},{"cell_type":"code","metadata":{"id":"GWLjB54KVgGb","colab":{"height":332,"base_uri":"https://localhost:8080/"},"outputId":"8b5b4290-7941-4489-9bab-6149fac379e6","source_hash":"c3b85edd","execution_start":1709953233150,"execution_millis":249,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"40c54655224746b7a4fd57cdcbaaa818","deepnote_cell_type":"code"},"source":"import google.generativeai as genai\ngenai.configure(api_key=gemini_api_key)\nmodel = genai.GenerativeModel('gemini-1.0-pro')","block_group":"8b3b32ec98e14047b104f2506295ba54","execution_count":60,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"d991cab6","execution_start":1709953233153,"execution_millis":246,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"4241ee38055245fab054980baf5462bc","deepnote_cell_type":"code"},"source":"model","block_group":"4a0d5e23b54a431a82ccbb0d4aca39b9","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"genai.GenerativeModel(\n    model_name='models/gemini-1.0-pro',\n    generation_config={},\n    safety_settings={},\n    tools=None,\n)"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/dcc71bfb-7ca9-49e9-8713-397b623ba6c4"},{"cell_type":"markdown","metadata":{"id":"nvyJkedJU2Pv","deepnote_app_block_visible":true,"cell_id":"e94a45f53692417d941389ae227e4b3e","deepnote_cell_type":"markdown"},"source":"Given `arxiv` structure, summarize and evaluate against user prompt. Give a heuritic score.","block_group":"fa2a223bf8034417a6d1fa9e5f8c8f52"},{"cell_type":"code","metadata":{"id":"SoqeHjBAihAD","source_hash":"389c1e7","execution_start":1709953233163,"execution_millis":237,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"bbdda948ae7447d59b2ab4dcbda5affb","deepnote_cell_type":"code"},"source":"import re\nimport json\n\ndef process_arxiv(mkdn, metdata, query):\n  # 1 - `arxiv` dict\n  def extract_markdown(markdown_text, pattern):\n    # Use re.findall to find all matches of the pattern in the markdown text\n    matches = re.findall(pattern, markdown_text, re.MULTILINE)\n\n    # Return the first match (if any)\n    if matches:\n        return matches[0]\n    else:\n        return None\n\n  paper_title = extract_markdown(mkdn, r'^##\\s+(.*)$')\n  if paper_title is None:\n    print(\"extract_markdown for paper_title isn't working\")\n\n  abstract = extract_markdown(mkdn, r'^Abstract(.*)#')\n  if abstract is None:\n    print(\"extract_markdown for abstract isn't working...hardcoding the abstract instead\")\n    abstract = '''We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.'''\n\n  arxiv = {'paper_title': paper_title, 'abstract': abstract, 'metadata': metadata, 'paper': mkdn}\n\n  # 2 - Summarizer\n  prompt = '''Please summarize the following paper in one sentence given the user query \"{query}\". The paper is provided in a structured format {paper_format} \\n\\nDocument: {document}'''.format(query=query, document=arxiv, paper_format={key: \"\" for key in arxiv.keys()})\n  print(prompt, \"\\nGenerating summarization............\")\n\n  if model.count_tokens(prompt).total_tokens > 28_000:\n    print(\"The prompt is too long, visiting https://aistudio.google.com/app/prompts/new_freeform to manually use Gemini 1.5 pro instead with the prompt above.\")\n  relevant_answer = model.generate_content(prompt).text\n\n  print(relevant_answer)\n\n  # 3 - Relevance scorer\n  prompt = '''From a scale of 1 to 5, rate how relevant the following paper is with the user query \"{query}\". The paper is provided in a structured format {paper_format}. Please provide the score in the format of a json object with one key, 'score'. Example: {{\"score\": 5}}. Also please provide reasoning why it doesn't have a higher or lower relevance score. \\n\\nDocument: {document}'''.format(query=query, document=arxiv, paper_format={key: \"\" for key in arxiv.keys()})\n  print(prompt, \"\\nGenerating............\")\n\n  if model.count_tokens(prompt).total_tokens > 28_000:\n    print(\"The prompt is too long, visiting https://aistudio.google.com/app/prompts/new_freeform to manually use Gemini 1.5 pro instead with the prompt above.\")\n\n  model_response = model.generate_content(prompt).text\n\n  re_match = re.search(r'\"score\": (\\d+)', model_response)\n  relevance_score = re_match.group(1)\n\n  print(\"relevance score: \" + relevance_score)\n\n  return {\n      'relevance_score': relevance_score,\n      'relevant_answer': relevant_answer\n  }\n\n  query\n\n  #@title `mkdn` and `metadata`\nmetadata = markdown_content #right now it's just the entire paper pdf\n\n#@title Extractors to process `mkdn` and `metadata` into `arxiv` dict\n\nimport re\n\ndef extract_markdown(markdown_text, pattern):\n  # Use re.findall to find all matches of the pattern in the markdown text\n  matches = re.findall(pattern, markdown_text, re.MULTILINE)\n\n  # Return the first match (if any)\n  if matches:\n      return matches[0]\n  else:\n      return None\n\npaper_title = extract_markdown(metadata, r'^##\\s+(.*)$')\nif paper_title is None:\n  print(\"extract_markdown for paper_title isn't working\")\n\nabstract = extract_markdown(metadata, r'^Abstract(.*)#')\nif abstract is None:\n  print(\"extract_markdown for abstract isn't working...hardcoding the abstract instead\")\n  abstract = '''We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.'''\n\narxiv = {'paper_title': paper_title, 'abstract': abstract, 'metadata': metadata, 'paper': metadata}\n\n\n\nimport json\n\n# Convert to JSON string with indentation for readability\npretty_arxiv_output = json.dumps(arxiv, indent=4, default=str)\n\n# Print with added line breaks\nprint(\"\\narxiv=\",)\nprint(pretty_arxiv_output)","block_group":"e3a2b46fdc674e5aa372ece84f9f2082","execution_count":62,"outputs":[{"name":"stdout","text":"extract_markdown for abstract isn't working...hardcoding the abstract instead\n\narxiv=\n{\n    \"paper_title\": \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\",\n    \"abstract\": \"We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.\",\n    \"metadata\": \"## Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\n\\nPatrick Lewis\\u2020\\u2021, Ethan Perez\\u22c6, Aleksandra Piktus\\u2020, Fabio Petroni\\u2020, Vladimir Karpukhin\\u2020, Naman Goyal\\u2020, Heinrich K\\u00fcttler\\u2020\\n\\narXiv:2005.11401v4 [cs.CL] 12 Apr 2021\\n\\nMike Lewis\\u2020, Wen-tau Yih\\u2020, Tim Rockt\\u00e4schel\\u2020\\u2021, Sebastian Riedel\\u2020\\u2021, Douwe Kiela\\u2020\\n\\n\\u2020Facebook AI Research; \\u2021University College London; \\u22c6New York University;\\n\\nplewis@fb.com\\n\\n### Abstract\\n\\nLarge pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) \\u2014 models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\\n\\n### Introduction\\n\\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowledge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have downsides: They cannot easily expand or revise their memory, can\\u2019t straightforwardly provide insight into their predictions, and may produce \\u201challucinations\\u201d [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results.\\n---\\n## Define \\\"middle ear\\\"(x)\\n\\nThe middle ear includes the tympanic cavity and the three ossicles.\\n\\n## Question Answering:\\n\\n|Question Query|Query|Retriever p|\\u03b7|Document|Generator p|\\u03b8|\\n|---|---|---|---|---|---|---|\\n|Barack Obama was born in Hawaii.(x)|Encoder|(Non-Parametric)|Index|(Parametric)|Answer Generation|supports (y)|\\n\\n## Fact Verification: Fact Query\\n\\nThe Divine Comedy (x)\\n\\n## Jeopardy Question Generation:\\n\\nAnswer Query\\n\\nFigure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents. but have only explored open-domain extractive question answering. Here, we bring hybrid parametric and non-parametric memory to the \\u201cworkhorse of NLP,\\u201d i.e. sequence-to-sequence (seq2seq) models. We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose fine-tuning approach which we refer to as retrieval-augmented generation (RAG). We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The retriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART [32]) then conditions on these latent documents together with the input to generate the output. We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG can be fine-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned. There has been extensive previous work proposing architectures to enrich systems with non-parametric memory which are trained from scratch for specific tasks, e.g. memory networks [64, 55], stack-augmented networks [25] and memory layers [30]. In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge. Crucially, by using pre-trained access mechanisms, the ability to access knowledge is present without additional training. Our results highlight the benefits of combining parametric and non-parametric memory with generation for knowledge-intensive tasks\\u2014tasks that humans could not reasonably be expected to perform without access to an external knowledge source. Our RAG models achieve state-of-the-art results on open Natural Questions [29], WebQuestions [3] and CuratedTrec [2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [24]. Despite these being extractive tasks, we find that unconstrained generation outperforms previous extractive approaches. For knowledge-intensive generation, we experiment with MS-MARCO [1] and Jeopardy question generation, and we find that our models generate responses that are more factual, specific, and diverse than a BART baseline. For FEVER [56] fact verification, we achieve results within 4.3% of state-of-the-art pipeline models which use strong retrieval supervision. Finally, we demonstrate that the non-parametric memory can be replaced to update the models\\u2019 knowledge as the world changes.\\n\\n## Methods\\n\\nWe explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y. As shown in Figure 1, our models leverage two components: (i) a retriever p\\u03b7(z|x) with parameters \\u03b7 that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator p\\u03b8(yi|x, z, y1:i\\u22121) parametrized\\n\\n1 Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transformers Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/\\n---\\n## by \\u03b8 that generates a current token based on a context of the previous i \\u2212 1 tokens y1:i\\u22121, the original input x and a retrieved passage z.\\n\\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable. We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. The second approach, RAG-Token, can predict each target token based on a different document. In the following, we formally introduce both models and then describe the p\\u03b7 and p\\u03b8 components, as well as the training and decoding procedure.\\n\\n### Models\\n\\n|RAG-Sequence Model|The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized,|\\n|---|---|\\n| |pRAG-Sequence(y|x) \\u2248 p\\u03b7(z|x)p\\u03b8(y|x, z) = p\\u03b7(z|x) \\u03a3 p\\u03b8(yi|x, z, y1:i\\u22121) z\\u2208top-k(p(\\u00b7|x)) z\\u2208top-k(p(\\u00b7|x)) i|\\n|RAG-Token Model|In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we define:|\\n| |pRAG-Token(y|x) \\u2248 \\u03a3 z\\u2208top-k(p(\\u00b7|x)) p\\u03b7(z|x)p\\u03b8(yi|x, z, y1:i\\u22121)|\\n\\nFinally, we note that RAG can be used for sequence classification tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\\n\\n### Retriever: DPR\\n\\nThe retrieval component p\\u03b7(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture: p\\u03b7(z|x) \\u221d exp d(z)\\u22a4q(x) d(z) = BERTd(z), q(x) = BERTq(x) where d(z) is a dense representation of a document produced by a BERTBASE document encoder [8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(p\\u03b7(\\u00b7|x)), the list of k documents z with highest prior probability p\\u03b7(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and Natural Questions [29]. We refer to the document index as the non-parametric memory.\\n\\n### Generator: BART\\n\\nThe generator component p\\u03b8(yi|x, z, y1:i\\u22121) could be modelled using any encoder-decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them. BART was pre-trained using a denoising objective and a variety of different noising functions. It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32]. We refer to the BART generator parameters \\u03b8 as the parametric memory henceforth.\\n\\n### Training\\n\\nWe jointly train the retriever and generator components without any direct supervision on what document should be retrieved. Given a fine-tuning training corpus of input/output pairs (xj, yj), we\\n---\\n## Decoding\\n\\nAt test time, RAG-Sequence and RAG-Token require different ways to approximate arg max y p(y|x).\\n\\n|RAG-Token| |\\n|---|---|\\n|The RAG-Token model can be seen as a standard, autoregressive seq2seq generator with transition probability: p'\\u03b8(yi|x, y1:i-1) = \\u03a3z\\u2208top-k(p(\\u00b7|x)) p\\u03b7(zi|x)p\\u03b8(yi|x, zi, y1:i-1) To decode, we can plug p'\\u03b8(yi|x, y1:i-1) into a standard beam decoder.| |\\n\\n|RAG-Sequence| |\\n|---|---|\\n|For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per-token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using p\\u03b8(yi|x, z, y1:i-1). This yields a set of hypotheses Y, some of which may not have appeared in the beams of all documents. To estimate the probability of a hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p\\u03b7(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as \\u201cThorough Decoding.\\u201d For longer output sequences, |Y| can become large, requiring many forward passes. For more efficient decoding, we can make a further approximation that p\\u03b8(y|x, zi) \\u2248 0 where y was not generated during beam search from x, zi. This avoids the need to run additional forward passes once the candidate set Y has been generated. We refer to this decoding procedure as \\u201cFast Decoding.\\u201d| |\\n\\n## Experiments\\n\\nWe experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. [31] and Karpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents. We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37]. During training, we retrieve the top k documents for each query. We consider k \\u2208 {5, 10} for training and set k for test time using dev data. We now discuss experimental details for each task.\\n\\n## Open-domain Question Answering\\n\\nOpen-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20]. We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers. We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge. We also compare to \\u201cClosed-Book QA\\u201d approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge. We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24]. WebQuestions (WQ) [3] and CuratedTrec (CT) [2]. As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.\\n\\n## Abstractive Question Answering\\n\\nRAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG\\u2019s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat\\n---\\nMSMARCO as an open-domain abstractive QA task. MSMARCO has some questions that cannot be answered in a way that matches the reference answer without access to the gold passages, such as \\\"What is the weather in Volcano, CA?\\\" so performance will be lower without using gold passages. We also note that some MSMARCO questions cannot be answered using Wikipedia alone. Here, RAG can rely on parametric knowledge to generate reasonable responses.\\n\\nJeopardy Question Generation\\n\\nTo evaluate RAG\\u2019s generation abilities in a non-QA setting, we study open-domain question generation. Rather than use questions from standard open-domain QA tasks, which typically consist of short, simple questions, we propose the more demanding task of generating Jeopardy questions. Jeopardy is an unusual format that consists of trying to guess an entity from a fact about that entity. For example, \\\"The World Cup\\\" is the answer to the question \\\"In 1986 Mexico scored as the first country to host this international sports competition twice.\\\" As Jeopardy questions are precise, factual statements, generating Jeopardy questions conditioned on their answer entities constitutes a challenging knowledge-intensive generation task.\\n\\nWe use the splits from SearchQA [10], with 100K train, 14K dev, and 27K test examples. As this is a new task, we train a BART model for comparison. Following [67], we evaluate using the SQuAD-tuned Q-BLEU-1 metric [42]. Q-BLEU is a variant of BLEU with a higher weight for matching entities and has higher correlation with human judgment for question generation than standard metrics. We also perform two human evaluations, one to assess generation factuality, and one for specificity. We define factuality as whether a statement can be corroborated by trusted external sources, and specificity as high mutual dependence between the input and output [33]. We follow best practice and use pairwise comparative evaluation [34]. Evaluators are shown an answer and two generated questions, one from BART and one from RAG. They are then asked to pick one of four options\\u2014question A is better, question B is better, both are good, or neither is good.\\n\\nFact Verification\\n\\nFEVER [56] requires classifying whether a natural language claim is supported or refuted by Wikipedia, or whether there is not enough information to decide. The task requires retrieving evidence from Wikipedia relating to the claim and then reasoning over this evidence to classify whether the claim is true, false, or unverifiable from Wikipedia alone. FEVER is a retrieval problem coupled with a challenging entailment reasoning task. It also provides an appropriate testbed for exploring the RAG models\\u2019 ability to handle classification rather than generation. We map FEVER class labels (supports, refutes, or not enough info) to single output tokens and directly train with claim-class pairs. Crucially, unlike most other approaches to FEVER, we do not use supervision on retrieved evidence. In many real-world applications, retrieval supervision signals aren\\u2019t available, and models that do not require such supervision will be applicable to a wider range of tasks. We explore two variants: the standard 3-way classification task (supports/refutes/not enough info) and the 2-way (supports/refutes) task studied in Thorne and Vlachos [57]. In both cases we report label accuracy.\\n\\nResults\\n\\nOpen-domain Question Answering\\n\\n|Task|RAG|State-of-the-art Models|\\n|---|---|---|\\n|All four open-domain QA tasks|RAG sets a new state of the art|Only on the T5-comparable split for TQA|\\n|RAG combines the generation flexibility of the \\\"closed-book\\\" (parametric only) approaches and the performance of \\\"open-book\\\" retrieval-based approaches| | |\\n|Unlike REALM and T5+SSM, RAG enjoys strong results without expensive, specialized \\\"salient span masking\\\" pre-training [20]| | |\\n|RAG's retriever is initialized using DPR's retriever, which uses retrieval supervision on Natural Questions and TriviaQA| | |\\n|RAG compares favorably to the DPR QA system, which uses a BERT-based \\\"cross-encoder\\\" to re-rank documents, along with an extractive reader| | |\\n|RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art performance| | |\\n\\nThere are several advantages to generating answers even when it is possible to extract them. Documents with clues about the answer but do not contain the answer verbatim can still contribute towards a correct answer being generated, which is not possible with standard extractive approaches, leading\\n---\\n## Table 1: Open-Domain QA Test Scores\\n\\n|Model|NQ|TQA|WQ|CT|\\n|---|---|---|---|---|\\n|Closed Book T5-11B [52]|34.5|- /50.1|37.4|-|\\n|Book T5-11B+SSM[52]|36.6|- /60.5|44.7|-|\\n|Open Book REALM [20]|40.4|- / -|40.7|46.8|\\n|Book DPR [26]|41.5|57.9/ -|41.1|50.6|\\n|RAG-Token|44.1|55.2/66.1|45.5|50.0|\\n|RAG-Seq.|44.5|56.8/68.0|45.2|52.2|\\n\\n## Table 2: Generation and classification Test Scores\\n\\n|Model|Jeopardy|MSMARCO|FVR3|FVR2|\\n|---|---|---|---|---|\\n|B-1|QB-1|R-L|B-1|Label Acc.|\\n|BART|15.1|19.7|38.2|41.6|\\n|RAG-Tok.|17.3|22.2|40.1|41.5|\\n|RAG-Seq.|14.7|21.4|40.8|44.2|\\n\\n4.2 Abstractive Question Answering\\n\\nAs shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with specific information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we find that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see \\u00a74.5).\\n\\n4.3 Jeopardy Question Generation\\n\\nTable 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model. Evaluators also find RAG generations to be more specific by a large margin. Table 3 shows typical generations from each model.\\n\\nJeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating \\u201cSun\\u201d, the posterior is high for document 2 which mentions \\u201cThe Sun Also Rises\\u201d. Similarly, document 1 dominates the posterior when \\u201cA Farewell to Arms\\u201d is generated. Intriguingly, after the first token of each book is generated, the document posterior flattens. This observation suggests that the generator can complete the titles without depending on specific documents. In other words, the model\\u2019s parametric knowledge is sufficient to complete the titles. We find evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \\\"The Sun. BART completes the generation \\\"The Sun Also Rises\\\" is a novel by this author of \\\"The Sun Also Rises\\\" indicating the title \\\"The Sun Also Rises\\\" is stored in BART\\u2019s parameters. Similarly, BART will complete the partial decoding \\\"The Sun Also Rises\\\" is a novel by this author of \\\"A with \\\"The Sun Also Rises\\\" is a novel by this author of \\\"A Farewell to Arms\\\". This example shows how parametric and non-parametric memories work together\\u2014the non-parametric component helps to guide the generation, drawing out specific knowledge stored in the parametric memory.\\n\\n4.4 Fact Verification\\n\\nTable 2 shows our results on FEVER. For 3-way classification, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-specific architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require.\\n---\\n## Document 1\\n\\nHis works are considered classics of American literature ... His wartime experiences formed the basis for his novel \\\"A Farewell to Arms\\\" (1929) ...\\n\\n## Document 2\\n\\n... artists of the 1920s \\\"Lost Generation\\\" expatriate community. His debut novel, \\\"The Sun Also Rises\\\", was published in 1926.\\n\\nFigure 2: RAG-Token document posterior p(zi|x, yi, y\\u2212i) for each generated token for input \\u201cHemingway\\\" for Jeopardy generation with 5 retrieved documents. The posterior for document 1 is high when generating \\u201cA Farewell to Arms\\\" and for document 2 when generating \\u201cThe Sun Also Rises\\\".\\n\\n|Task|Input|Model|Generation|\\n|---|---|---|---|\\n|define middle ear|BART|?|The middle ear is the part of the ear between the middle ear and the nose.|\\n| |RAG-T| |The middle ear is the portion of the ear internal to the eardrum.|\\n|MS-MARCO|what currency needed in Scotland|BART|The currency needed in Scotland is Pound sterling.|\\n| |RAG-T| |Pound is the currency needed in Scotland.|\\n| |RAG-S| |The currency needed in Scotland is the pound sterling.|\\n| |BART|?|This state has the largest number of counties in the U.S.|\\n|Jeopardy Question Generation|Washington|RAG-T|It\\u2019s the only U.S. state named for a U.S. president|\\n| |RAG-S| |It\\u2019s the state where you\\u2019ll find Mount Rainier National Park|\\n| |BART|*|This epic poem by Dante is divided into 3 parts: the Inferno, the Purgatorio & the Purgatorio|\\n|The Divine Comedy|RAG-T| |Dante\\u2019s \\\"Inferno\\\" is the first part of this epic poem|\\n| |RAG-S| |This 14th century work is divided into 3 sections: \\\"Inferno\\\", \\\"Purgatorio\\\" & \\\"Paradiso\\\"|\\n\\nFor 2-way classification, we compare against Thorne and Vlachos [57], who train RoBERTa [35] to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy within 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence. We also analyze whether documents retrieved by RAG correspond to documents annotated as gold evidence in FEVER. We calculate the overlap in article titles between the top k documents retrieved by RAG and gold evidence annotations. We find that the top retrieved document is from a gold article in 71% of cases, and a gold article is present in the top 10 retrieved articles in 90% of cases.\\n\\n## Additional Results\\n\\nGeneration Diversity: Section 4.3 shows that RAG models are more factual and specific than BART for Jeopardy question generation. Following recent work on diversity-promoting decoding, we also investigate generation diversity by calculating the ratio of distinct ngrams to total ngrams generated by different models. Table 5 shows that RAG-Sequence\\u2019s generations are more diverse than RAG-Token\\u2019s, and both are significantly more diverse than BART without needing any diversity-promoting decoding.\\n\\nRetrieval Ablations: A key feature of RAG is learning to retrieve relevant information for the task. To assess the effectiveness of the retrieval mechanism, we run ablations where we freeze the retriever during training. As shown in Table 6, learned retrieval improves results for all tasks.\\n\\nWe compare RAG\\u2019s dense retriever to a word overlap-based BM25 retriever. Here, we replace RAG\\u2019s retriever with a fixed BM25 system, and use BM25 retrieval scores as logits when calculating p(z|x). Table 6 shows the results. For FEVER, BM25 performs best, perhaps since FEVER claims are heavily entity-centric and thus well-suited for word overlap-based retrieval. Differentiable retrieval improves results on all other tasks, especially for Open-Domain QA, where it is crucial.\\n\\nIndex hot-swapping: An advantage of non-parametric memory models like RAG is that knowledge can be easily updated at test time. Parametric-only models like T5 or BART need further training to update their behavior as the world changes. To demonstrate, we build an index using the DrQA Wikipedia dump from December 2016 and compare outputs from RAG using this index to the newer index from our main results (December 2018). We prepare a list of 82 world leaders who had changed\\n---\\n## Table 4: Human assessments for the Jeopardy Question Generation Task\\n\\n| |Factuality|Specificity|\\n|---|---|---|\\n|BART better|7.1%|16.8%|\\n|RAG better|42.7%|37.4%|\\n|Both good|11.7%|11.8%|\\n|Both poor|17.7%|6.9%|\\n|No majority|20.8%|20.1%|\\n\\n## Table 5: Ratio of distinct to total tri-grams for generation tasks\\n\\n| |MSMARCO|Jeopardy QGen|\\n|---|---|---|\\n|Gold|89.6%|90.0%|\\n|BART|70.7%|32.4%|\\n|RAG-Token|77.8%|46.8%|\\n|RAG-Seq.|83.5%|53.8%|\\n\\n## Table 6: Ablations on the dev set\\n\\n|Model|NQ|TQA|WQ|CT|Jeopardy-QGen|MSMarco|FVR-3|FVR-2|\\n|---|---|---|---|---|---|---|---|---|\\n|RAG-Token-BM25|29.7|41.5|32.1|33.1|17.5|22.3|55.5|48.4|75.1|91.6|\\n|RAG-Sequence-BM25|31.8|44.1|36.6|33.8|11.1|19.5|56.5|46.9|\\n|RAG-Token-Frozen|37.8|50.1|37.1|51.1|16.7|21.7|55.9|49.4|72.9|89.4|\\n|RAG-Sequence-Frozen|41.2|52.1|41.8|52.6|11.8|19.6|56.7|47.3|\\n|RAG-Token|43.5|54.8|46.5|51.9|17.9|22.6|56.2|49.4|74.5|90.6|\\n|RAG-Sequence|44.0|55.8|44.9|53.4|15.3|21.5|57.2|47.5|\\n\\nBetween these dates and use a template \\u201cWho is {position}?\\u201d (e.g. \\u201cWho is the President of Peru?\\u201d) to query our NQ RAG model with each index. RAG answers 70% correctly using the 2016 index for 2016 world leaders and 68% using the 2018 index for 2018 world leaders. Accuracy with mismatched indices is low (12% with the 2018 index and 2016 leaders, 4% with the 2016 index and 2018 leaders). This shows we can update RAG\\u2019s world knowledge by simply replacing its non-parametric memory.\\n\\nEffect of Retrieving more documents: Models are trained with either 5 or 10 retrieved latent documents, and we do not observe significant differences in performance between them. We have the flexibility to adjust the number of retrieved documents at test time, which can affect performance and runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.\\n\\n| |44|80|Bleu-1 / Rouge-L score|\\n|---|---|---|---|\\n| | |NQ Answer Recall @ K|56|\\n|NQ Exact Match| |54| |\\n| | | |RAG-Tok R-L| |\\n| | | |RAG-Tok B-1| |\\n| | | |RAG-Seq R-L| |\\n| | | |RAG-Seq B-1| |\\n\\nFigure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall performance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.\\n\\n## Related Work\\n\\nSingle-Task Retrieval: Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering, fact checking, fact completion, long-form question answering, Wikipedia article generation, dialogue, translation, and language modeling. Our work unifies previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.\\n---\\n## General-Purpose Architectures for NLP\\n\\nPrior work on general-purpose architectures for NLP tasks has shown great success without the use of retrieval. A single, pre-trained language model has been shown to achieve strong performance on various classification tasks in the GLUE benchmarks [60, 61] after fine-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right, pre-trained language model could achieve strong performance across both discriminative and generative tasks. For further improvement, BART [32] and T5 [51, 52] propose a single, pre-trained encoder-decoder model that leverages bi-directional attention to achieve stronger performance on discriminative and generative tasks. Our work aims to expand the space of possible tasks with a single, unified architecture, by learning a retrieval module to augment pre-trained, generative language models.\\n\\n## Learned Retrieval\\n\\nThere is significant work on learning to retrieve documents in information retrieval, more recently with pre-trained, neural language models [44, 26] similar to ours. Some work optimizes the retrieval module to aid in a specific, downstream task such as question answering, using search [46], reinforcement learning [6, 63, 62], or a latent variable approach [31, 20] as in our work. These successes leverage different retrieval-based architectures and optimization techniques to achieve strong performance on a single task, while we show that a single retrieval-based architecture can be fine-tuned for strong performance on a variety of tasks.\\n\\n## Memory-based Architectures\\n\\nOur document index can be seen as a large external memory for neural networks to attend to, analogous to memory networks [64, 55]. Concurrent work [14] learns to retrieve a trained embedding for each entity in the input, rather than to retrieve raw text as in our work. Other work improves the ability of dialog models to generate factual text by attending over fact embeddings [15, 13]. A key feature of our memory is that it is comprised of raw text rather distributed representations, which makes the memory both (i) human-readable, lending a form of interpretability to our model, and (ii) human-writable, enabling us to dynamically update the model\\u2019s memory by editing the document index. This approach has also been used in knowledge-intensive dialog, where generators have been conditioned on retrieved text directly, albeit obtained via TF-IDF rather than end-to-end learnt retrieval [9].\\n\\n## Retrieve-and-Edit approaches\\n\\nOur method shares some similarities with retrieve-and-edit style approaches, where a similar training input-output pair is retrieved for a given input, and then edited to provide a final output. These approaches have proved successful in a number of domains including Machine Translation [18, 22] and Semantic Parsing [21]. Our approach does have several differences, including less of emphasis on lightly editing a retrieved item, but on aggregating content from several pieces of retrieved content, as well as learning latent retrieval, and retrieving evidence documents rather than related training pairs. This said, RAG techniques may work well in these settings, and could represent promising future work.\\n\\n## Discussion\\n\\nIn this work, we presented hybrid generation models with access to parametric and non-parametric memory. We showed that our RAG models obtain state of the art results on open-domain QA. We found that people prefer RAG\\u2019s generation over purely parametric BART, finding RAG more factual and specific. We conducted an thorough investigation of the learned retrieval component, validating its effectiveness, and we illustrated how the retrieval index can be hot-swapped to update the model without requiring any retraining. In future work, it may be fruitful to investigate if the two components can be jointly pre-trained from scratch, either with a denoising objective similar to BART or some another objective. Our work opens up new research directions on how parametric and non-parametric memories interact and how to most effectively combine them, showing promise in being applied to a wide variety of NLP tasks.\\n---\\n## Broader Impact\\n\\nThis work offers several positive societal benefits over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it \\u201challucinate\\u201d less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct benefit to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs.\\n\\nWith these advantages also come potential downsides: Wikipedia, or any potential external knowledge source, will probably never be entirely factual and completely devoid of bias. Since RAG can be employed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably to a lesser extent, including that it might be used to generate abuse, faked or misleading content in the news or on social media; to impersonate others; or to automate the production of spam/phishing content [54]. Advanced language models may also lead to the automation of various jobs in the coming decades [16]. In order to mitigate these risks, AI systems could be employed to fight against misleading content and automated spam/phishing.\\n\\n## Acknowledgments\\n\\nThe authors would like to thank the reviewers for their thoughtful and constructive feedback on this paper, as well as HuggingFace for their help in open-sourcing code to run RAG models. The authors would also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. EP thanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR PhD program.\\n\\n## References\\n\\n[1] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. arXiv:1611.09268 [cs], November 2016. URL http://arxiv.org/abs/1611.09268. arXiv: 1611.09268.\\n[2] Petr Baudi\\u0161 and Jan \\u0160ediv` y. Modeling of pe question answering task in pe yodaqa system. In International Conference of pe Cross-Language Evaluation Forum for European Languages, pages 222\\u2013228. Springer, 2015. URL https://link.springer.com/chapter/10.1007% 2F978-3-319-24027-5_20.\\n[3] Jonapan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic Parsing on Freebase from Question-Answer Pairs. In Proceedings of pe 2013 Conference on Empirical Mepods in Natural Language Processing, pages 1533\\u20131544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL http://www.aclweb.org/anpology/ D13-1160.\\n[4] Bin Bi, Chenliang Li, Chen Wu, Ming Yan, and Wei Wang. Palm: Pre-training an autoencod- ing&autoregressive language model for context-conditioned generation. ArXiv, abs/2004.07159, 2020. URL https://arxiv.org/abs/2004.07159.\\n[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer Open-Domain Questions. In Proceedings of pe 55p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 1870\\u20131879, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://www.aclweb.org/anpology/P17-1171.\\n[6] Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and Jonapan Berant. Coarse-to-fine question answering for long documents. In Proceedings of pe 55p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 209\\u2013220, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1020. URL https://www.aclweb.org/anpology/P17-1020.\\n---\\nChristopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Comprehension. arXiv:1710.10723 [cs], October 2017. URL http://arxiv.org/abs/1710.10723. arXiv: 1710.10723.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of pe 2019 Conference of pe Norp American Chapter of pe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\\u20134186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://www.aclweb.org/anpology/N19-1423.\\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wizard of wikipedia: Knowledge-powered conversational agents. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=r1l73iRqKm.\\nMatpew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. SearchQA: A New Q&A Dataset Augmented wip Context from a Search Engine. arXiv:1704.05179 [cs], April 2017. URL http://arxiv.org/abs/1704.05179. arXiv: 1704.05179.\\nAngela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceedings of pe 56p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 889\\u2013898, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1082. URL https://www.aclweb.org/anpology/P18-1082.\\nAngela Fan, Yacine Jernite, Epan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: Long form question answering. In Proceedings of pe 57p Annual Meeting of pe Association for Computational Linguistics, pages 3558\\u20133567, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1346. URL https://www.aclweb.org/anpology/P19-1346.\\nAngela Fan, Claire Gardent, Chloe Braud, and Antoine Bordes. Augmenting transformers wip KNN-based composite memory, 2020. URL https://openreview.net/forum?id=H1gx1CNKPH.\\nThibault F\\u00e9vry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, and Tom Kwiatkowski. Entities as experts: Sparse memory access wip entity supervision. ArXiv, abs/2004.07202, 2020. URL https://arxiv.org/abs/2004.07202.\\nMarjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wentau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16710.\\nKatja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. When will AI exceed human performance? evidence from AI experts. CoRR, abs/1705.08807, 2017. URL http://arxiv.org/abs/1705.08807.\\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282.\\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, pages 5133\\u20135140. AAAI press, 2018. 32nd AAAI Conference on Artificial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.\\nKelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by editing prototypes. Transactions of pe Association for Computational Linguistics, 6:437\\u2013450, 2018. doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anpology/Q18-1031.\\n---\\n## References\\n\\n|[20]|Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. REALM: Retrieval-augmented language model pre-training. ArXiv, abs/2002.08909, 2020. URL https://arxiv.org/abs/2002.08909.|\\n|---|---|\\n|[21]|Tatsunori B Hashimoto, Kelvin Guu, Yonatan Oren, and Percy S Liang. A retrieve-and-edit framework for predicting structured outputs. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 10052\\u201310062. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/8209-a-retrieve-and-edit-framework-for-predicting-structured-outputs.pdf.|\\n|[22]|Nabil Hossain, Marjan Ghazvininejad, and Luke Zettlemoyer. Simple and effective retrieve-edit-rerank text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2532\\u20132538, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.228. URL https://www.aclweb.org/anthology/2020.acl-main.228.|\\n|[23]|Jeff Johnson, Matthijs Douze, and Herv\\u00e9 J\\u00e9gou. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.08734, 2017. URL https://arxiv.org/abs/1702.08734.|\\n|[24]|Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601\\u20131611, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1147. URL https://www.aclweb.org/anthology/P17-1147.|\\n|[25]|Armand Joulin and Tomas Mikolov. Inferring algorithmic patterns with stack-augmented recurrent nets. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1, NIPS\\u201915, page 190\\u2013198, Cambridge, MA, USA, 2015. MIT Press. URL https://papers.nips.cc/paper/5857-inferring-algorithmic-patterns-with-stack-augmented-recurrent-nets.|\\n|[26]|Vladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906, 2020. URL https://arxiv.org/abs/2004.04906.|\\n|[27]|Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.|\\n|[28]|Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412.6980.|\\n|[29]|Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural Questions: a Benchmark for Question Answering Research. Transactions of the Association of Computational Linguistics, 2019. URL https://tomkwiat.users.x20web.corp.google.com/papers/natural-questions/main-1455-kwiatkowski.pdf.|\\n|[30]|Guillaume Lample, Alexandre Sablayrolles, Marc\\u2019 Aurelio Ranzato, Ludovic Denoyer, and Herve Jegou. Large memory layers with product keys. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\\u2019 Alch\\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8548\\u20138559. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf.|\\n|[31]|Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association|\\n---\\n|Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.|BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461.|\\n|---|---|\\n|Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan.|A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110\\u2013119, San Diego, California, June 2016. Association for Computational Linguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/N16-1014.|\\n|Margaret Li, Jason Weston, and Stephen Roller.|Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL https://arxiv.org/abs/1909.03087.|\\n|Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He.|Robust neural machine translation with joint textual and phonetic embedding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3044\\u20133049, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL https://www.aclweb.org/anthology/P19-1291.|\\n|Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer.|Generating wikipedia by summarizing long sequences. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=Hyg0vbWC-.|\\n|Yury A. Malkov and D. A. Yashunin.|Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:824\\u2013836, 2016. URL https://arxiv.org/abs/1603.09320.|\\n|Gary Marcus.|The next decade in ai: four steps towards robust artificial intelligence. arXiv preprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177.|\\n|Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rockt\\u00e4schel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel.|How decoding strategies affect the verifiability of generated text. arXiv preprint arXiv:1911.03587, 2019. URL https://arxiv.org/abs/1911.03587.|\\n|Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu.|Mixed precision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ.|\\n|Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra.|Towards exploiting background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2322\\u20132332, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255.|\\n|Preksha Nema and Mitesh M. Khapra.|Towards a better metric for evaluating question generation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3950\\u20133959, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/anthology/D18-1429.|\\n|Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.|MS MARCO: A human generated machine reading comprehension dataset. In Tarek Richard Besold, Antoine Bordes, Artur S. d\\u2019Avila Garcez, and Greg Wayne, editors, Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic.|\\n---\\napproaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016, volume 1773 of CEUR Workshop Proceedings. CEUR-WS.org, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf.\\n\\n[44] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. arXiv preprint arXiv:1901.04085, 2019. URL https://arxiv.org/abs/1901.04085.\\n\\n[45] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48\\u201353, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-4009. URL https://www.aclweb.org/anthology/N19-4009.\\n\\n[46] Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe Kiela, and Kyunghyun Cho. Finding generalizable evidence by learning to convince q&a models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2402\\u20132411, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.\\n\\n[47] Fabio Petroni, Tim Rockt\\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463\\u20132473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://www.aclweb.org/anthology/D19-1250.\\n\\n[48] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rockt\\u00e4schel, Yuxiang Wu, Alexander H. Miller, and Sebastian Riedel. How context affects language models\\u2019 factual predictions. In Automated Knowledge Base Construction, 2020. URL https://openreview.net/forum?id=025X0zPfn.\\n\\n[49] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving Language Understanding by Generative Pre-Training, 2018. URL https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf.\\n\\n[50] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners, 2019. URL https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.\\n\\n[51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv e-prints, 2019. URL https://arxiv.org/abs/1910.10683.\\n\\n[52] Adam Roberts, Colin Raffel, and Noam Shazeer. How much knowledge can you pack into the parameters of a language model? arXiv e-prints, 2020. URL https://arxiv.org/abs/2002.08910.\\n\\n[53] Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr., 3(4):333\\u2013389, April 2009. ISSN 1554-0669. doi: 10.1561/1500000019. URL https://doi.org/10.1561/1500000019.\\n\\n[54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, and Jian-Bing Wang. Release strategies and the social impacts of language models. ArXiv, abs/1908.09203, 2019.\\n\\n[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440\\u20132448. Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf.\\n---\\n# References\\n\\n[56] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In Proceedings of pe 2018 Conference of pe Norp American Chapter of pe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809\\u2013819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL https://www.aclweb.org/anpology/N18-1074.\\n[57] James H. Thorne and Andreas Vlachos. Avoiding catastrophic forgetting in mitigating model biases in sentence-pair classification wip elastic weight consolidation. ArXiv, abs/2004.14366, 2020. URL https://arxiv.org/abs/2004.14366.\\n[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanapan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5998\\u20136008. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf.\\n[59] Ashwin Vijayakumar, Michael Cogswell, Ramprasaap Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes. AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17329.\\n[60] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of pe 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353\\u2013355, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5446. URL https://www.aclweb.org/anpology/W18-5446.\\n[61] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3261\\u20133275. Curran Associates, Inc., 2019. URL https://arxiv.org/abs/1905.00537.\\n[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain question answering. In Sheila A. McIlraip and Kilian Q. Weinberger, editors, Proceedings of pe Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), pe 30p innovative Applications of Artificial Intelligence (IAAI-18), and pe 8p AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 5981\\u20135988. AAAI Press, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16712.\\n[63] Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, and Murray Campbell. Evidence aggregation for answer re-ranking in open-domain question answering. In ICLR, 2018. URL https://openreview.net/forum?id=rJl3yM-Ab.\\n[64] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1410.3916.\\n[65] Jason Weston, Emily Dinan, and Alexander Miller. Retrieve and refine: Improved sequence generation models for dialogue. In Proceedings of pe 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI, pages 87\\u201392, Brussels, Belgium, October 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5713. URL https://www.aclweb.org/anpology/W18-5713.\\n---\\n## References\\n\\n[66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anpony Moi, Pierric Cistac, Tim Rault, R\\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Huggingface\\u2019s transformers: State-of-pe-art natural language processing. ArXiv, abs/1910.03771, 2019.\\n[67] Shiyue Zhang and Mohit Bansal. Addressing semantic drift in question generation for semi-supervised question answering. In Proceedings of pe 2019 Conference on Empirical Mepods in Natural Language Processing and pe 9p International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2495\\u20132509, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1253. URL https://www.aclweb.org/anpology/D19-1253.\\n[68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019. URL https://arxiv.org/abs/1909.03745.\\n---\\n## Appendices for Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\n\\n### Implementation Details\\n\\nFor Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models. For RAG-Sequence models, we report test results using 50 retrieved documents, and we use the Thorough Decoding approach since answers are generally short. We use greedy decoding for QA as we did not find beam search improved results. For Open-MSMarco and Jeopardy question generation, we report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence, and we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast Decoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.\\n\\n### Human Evaluation\\n\\n|Which sentence is more factually true?|Select option|\\n|---|---|\\n|Noje: Scna Guesucn?|snterzt \\\"The8r Nuso Rists S7lerce|\\n|IncicateFich Farcncllic AM; on Im Iclbwng sentarces Is Mca luclualy Injb[ealecllo ZLbko Uaino cnoc urdoco| |\\n\\nFigure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions and a worked example appear when clicking \\\"view tool guide\\\".\\n\\nFigure 4 shows the user interface for human evaluation. To avoid any biases for screen position, which model corresponded to sentence A and sentence B was randomly selected for each example. Annotators were encouraged to research the topic using the internet, and were given detailed instructions and worked examples in a full instructions tab. We included some gold sentences in order to assess the accuracy of the annotators. Two annotators did not perform well on these examples and their annotations were removed from the results.\\n\\n### Training Setup Details\\n\\nWe train all RAG models and BART baselines using Fairseq [45]. We train with mixed precision floating point arithmetic, distributing training across 8, 32GB NVIDIA V100 GPUs, though training and inference can be run on one GPU. We find that doing Maximum Inner Product Search with FAISS is sufficiently fast on CPU, so we store document index vectors on CPU, requiring \\u223c 100 GB of CPU memory for all of Wikipedia. After submission, We have ported our code to HuggingFace Transformers, which achieves equivalent performance to the previous version but is a cleaner and easier to use implementation. This version is also open-sourced. We also compress the document index using FAISS\\u2019s compression tools, reducing the CPU memory requirement to 36GB. Scripts to run experiments with RAG can be found at https://github.com/huggingface/transformers/blob/master/examples/rag/README.md and an interactive demo of a RAG model can be found at https://huggingface.co/rag/\\n\\n2. https://github.com/pytorch/fairseq\\n\\n3. https://github.com/huggingface/transformers\\n---\\n## Further Details on Open-Domain QA\\n\\nFor open-domain QA, multiple answer annotations are often available for a given question. These answer annotations are exploited by extractive models during training as typically all the answer annotations are used to find matches within documents when preparing training data. For RAG, we also make use of multiple annotation examples for Natural Questions and WebQuestions by training the model with each (q, a) pair separately, leading to a small increase in accuracy. For TriviaQA, there are often many valid answers to a given question, some of which are not suitable training targets, such as emoji or spelling variants. For TriviaQA, we filter out answer candidates if they do not occur in top 1000 documents for the query.\\n\\n## CuratedTrec preprocessing\\n\\nThe answers for CuratedTrec are given in the form of regular expressions, which has been suggested as a reason why it is unsuitable for answer-generation models [20]. To overcome this, we use a pre-processing step where we first retrieve the top 1000 documents for each query, and use the answer that most frequently matches the regex pattern as the supervision target. If no matches are found, we resort to a simple heuristic: generate all possible permutations for each regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\\n\\n## TriviaQA Evaluation setups\\n\\nThe open-domain QA community customarily uses public development datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading comprehension purposes. We report our results using the datasets splits used in DPR [26], which are consistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public TriviaQA Web Development split. Roberts et al. [52] used the TriviaQA official Wikipedia test set instead. F\\u00e9vry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See appendix of [14]). We report results on both test sets to enable fair comparison to both approaches. We find that our performance is much higher using the official Wiki test set, rather than the more conventional open-domain test set, which we attribute to the official Wiki test set questions being simpler to answer from Wikipedia.\\n\\n## Further Details on FEVER\\n\\nFor FEVER classification, we follow the practice from [32], and first re-generate the claim, and then classify using the representation of the final hidden state, before finally marginalizing across documents to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The first is to classify the claim as either \\\"Supported\\\", \\\"Refuted\\\" or \\\"Not Enough Info\\\", which is the task we explore in the main paper. FEVER\\u2019s other sub-task involves extracting sentences from Wikipedia as evidence supporting the classification prediction. As FEVER uses a different Wikipedia dump to us, directly tackling this task is not straightforward. We hope to address this in future work.\\n\\n## Null Document Probabilities\\n\\nWe experimented with adding \\\"Null document\\\" mechanism to RAG, similar to REALM [20] in order to model cases where no useful information could be retrieved for a given input. Here, if k documents were retrieved, we would additionally \\\"retrieve\\\" an empty document and predict a logit for the null document, before marginalizing over k + 1 predictions. We explored modelling this null document logit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or (iii) a neural network to predict the logit. We did not find that these improved performance, so in the interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents cannot always be retrieved, we observe that the model learns to always retrieve a particular set of documents for questions that are less likely to benefit from retrieval, suggesting that null document mechanisms may not be necessary for RAG.\\n\\n## Parameters\\n\\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of DPR, with 110M parameters each (although we do not train the document encoder ourselves) and 406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable.\\n---\\n|Task|Train|Development|Test|\\n|---|---|---|---|\\n|Natural Questions|79169|8758|3611|\\n|TriviaQA|78786|8838|11314|\\n|WebQuestions|3418|362|2033|\\n|CuratedTrec|635|134|635|\\n|Jeopardy Question Generation|97392|13714|26849|\\n|MS-MARCO|153726|12468|101093*|\\n|FEVER-3-way|145450|10000|10000|\\n|FEVER-2-way|96966|6666|6666|\\n\\nparameters. The best performing \\\"closed-book\\\" (parametric only) open-domain QA model is T5-11B\\nwith 11 Billion trainable parameters. The T5 model with the closest number of parameters to our\\nmodels is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions [52],\\nsubstantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/non-\\nparametric models require far fewer trainable parameters for strong open-domain QA performance.\\nThe non-parametric memory index does not consist of trainable parameters, but does consists of 21M\\n728 dimensional vectors, consisting of 15.3B values. These can be easily be stored at 8-bit floating\\npoint precision to manage memory and disk footprints.\\n\\n## Retrieval Collapse\\n\\nIn preliminary experiments, we observed that for some tasks such as story generation [11], the\\nretrieval component would \\u201ccollapse\\u201d and learn to retrieve the same documents regardless of the\\ninput. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents,\\nand the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit\\nrequirement for factual knowledge in some tasks, or the longer target sequences, which could result\\nin less informative gradients for the retriever. Perez et al. [46] also found spurious retrieval results\\nwhen optimizing a retrieval component in order to improve performance on downstream tasks.\\n\\n## Number of instances per dataset\\n\\nThe number of training, development and test datapoints in each of our datasets is shown in Table 7.\",\n    \"paper\": \"## Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\n\\nPatrick Lewis\\u2020\\u2021, Ethan Perez\\u22c6, Aleksandra Piktus\\u2020, Fabio Petroni\\u2020, Vladimir Karpukhin\\u2020, Naman Goyal\\u2020, Heinrich K\\u00fcttler\\u2020\\n\\narXiv:2005.11401v4 [cs.CL] 12 Apr 2021\\n\\nMike Lewis\\u2020, Wen-tau Yih\\u2020, Tim Rockt\\u00e4schel\\u2020\\u2021, Sebastian Riedel\\u2020\\u2021, Douwe Kiela\\u2020\\n\\n\\u2020Facebook AI Research; \\u2021University College London; \\u22c6New York University;\\n\\nplewis@fb.com\\n\\n### Abstract\\n\\nLarge pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) \\u2014 models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.\\n\\n### Introduction\\n\\nPre-trained neural language models have been shown to learn a substantial amount of in-depth knowledge from data [47]. They can do so without any access to an external memory, as a parameterized implicit knowledge base [51, 52]. While this development is exciting, such models do have downsides: They cannot easily expand or revise their memory, can\\u2019t straightforwardly provide insight into their predictions, and may produce \\u201challucinations\\u201d [38]. Hybrid models that combine parametric memory with non-parametric (i.e., retrieval-based) memories [20, 26, 48] can address some of these issues because knowledge can be directly revised and expanded, and accessed knowledge can be inspected and interpreted. REALM [20] and ORQA [31], two recently introduced models that combine masked language models [8] with a differentiable retriever, have shown promising results.\\n---\\n## Define \\\"middle ear\\\"(x)\\n\\nThe middle ear includes the tympanic cavity and the three ossicles.\\n\\n## Question Answering:\\n\\n|Question Query|Query|Retriever p|\\u03b7|Document|Generator p|\\u03b8|\\n|---|---|---|---|---|---|---|\\n|Barack Obama was born in Hawaii.(x)|Encoder|(Non-Parametric)|Index|(Parametric)|Answer Generation|supports (y)|\\n\\n## Fact Verification: Fact Query\\n\\nThe Divine Comedy (x)\\n\\n## Jeopardy Question Generation:\\n\\nAnswer Query\\n\\nFigure 1: Overview of our approach. We combine a pre-trained retriever (Query Encoder + Document Index) with a pre-trained seq2seq model (Generator) and fine-tune end-to-end. For query x, we use Maximum Inner Product Search (MIPS) to find the top-K documents zi. For final prediction y, we treat z as a latent variable and marginalize over seq2seq predictions given different documents. but have only explored open-domain extractive question answering. Here, we bring hybrid parametric and non-parametric memory to the \\u201cworkhorse of NLP,\\u201d i.e. sequence-to-sequence (seq2seq) models. We endow pre-trained, parametric-memory generation models with a non-parametric memory through a general-purpose fine-tuning approach which we refer to as retrieval-augmented generation (RAG). We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We combine these components in a probabilistic model trained end-to-end (Fig. 1). The retriever (Dense Passage Retriever [26], henceforth DPR) provides latent documents conditioned on the input, and the seq2seq model (BART [32]) then conditions on these latent documents together with the input to generate the output. We marginalize the latent documents with a top-K approximation, either on a per-output basis (assuming the same document is responsible for all tokens) or a per-token basis (where different documents are responsible for different tokens). Like T5 [51] or BART, RAG can be fine-tuned on any seq2seq task, whereby both the generator and retriever are jointly learned. There has been extensive previous work proposing architectures to enrich systems with non-parametric memory which are trained from scratch for specific tasks, e.g. memory networks [64, 55], stack-augmented networks [25] and memory layers [30]. In contrast, we explore a setting where both parametric and non-parametric memory components are pre-trained and pre-loaded with extensive knowledge. Crucially, by using pre-trained access mechanisms, the ability to access knowledge is present without additional training. Our results highlight the benefits of combining parametric and non-parametric memory with generation for knowledge-intensive tasks\\u2014tasks that humans could not reasonably be expected to perform without access to an external knowledge source. Our RAG models achieve state-of-the-art results on open Natural Questions [29], WebQuestions [3] and CuratedTrec [2] and strongly outperform recent approaches that use specialised pre-training objectives on TriviaQA [24]. Despite these being extractive tasks, we find that unconstrained generation outperforms previous extractive approaches. For knowledge-intensive generation, we experiment with MS-MARCO [1] and Jeopardy question generation, and we find that our models generate responses that are more factual, specific, and diverse than a BART baseline. For FEVER [56] fact verification, we achieve results within 4.3% of state-of-the-art pipeline models which use strong retrieval supervision. Finally, we demonstrate that the non-parametric memory can be replaced to update the models\\u2019 knowledge as the world changes.\\n\\n## Methods\\n\\nWe explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y. As shown in Figure 1, our models leverage two components: (i) a retriever p\\u03b7(z|x) with parameters \\u03b7 that returns (top-K truncated) distributions over text passages given a query x and (ii) a generator p\\u03b8(yi|x, z, y1:i\\u22121) parametrized\\n\\n1 Code to run experiments with RAG has been open-sourced as part of the HuggingFace Transformers Library [66] and can be found at https://github.com/huggingface/transformers/blob/master/ examples/rag/. An interactive demo of RAG models can be found at https://huggingface.co/rag/\\n---\\n## by \\u03b8 that generates a current token based on a context of the previous i \\u2212 1 tokens y1:i\\u22121, the original input x and a retrieved passage z.\\n\\nTo train the retriever and generator end-to-end, we treat the retrieved document as a latent variable. We propose two models that marginalize over the latent documents in different ways to produce a distribution over generated text. In one approach, RAG-Sequence, the model uses the same document to predict each target token. The second approach, RAG-Token, can predict each target token based on a different document. In the following, we formally introduce both models and then describe the p\\u03b7 and p\\u03b8 components, as well as the training and decoding procedure.\\n\\n### Models\\n\\n|RAG-Sequence Model|The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized,|\\n|---|---|\\n| |pRAG-Sequence(y|x) \\u2248 p\\u03b7(z|x)p\\u03b8(y|x, z) = p\\u03b7(z|x) \\u03a3 p\\u03b8(yi|x, z, y1:i\\u22121) z\\u2208top-k(p(\\u00b7|x)) z\\u2208top-k(p(\\u00b7|x)) i|\\n|RAG-Token Model|In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we define:|\\n| |pRAG-Token(y|x) \\u2248 \\u03a3 z\\u2208top-k(p(\\u00b7|x)) p\\u03b7(z|x)p\\u03b8(yi|x, z, y1:i\\u22121)|\\n\\nFinally, we note that RAG can be used for sequence classification tasks by considering the target class as a target sequence of length one, in which case RAG-Sequence and RAG-Token are equivalent.\\n\\n### Retriever: DPR\\n\\nThe retrieval component p\\u03b7(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture: p\\u03b7(z|x) \\u221d exp d(z)\\u22a4q(x) d(z) = BERTd(z), q(x) = BERTq(x) where d(z) is a dense representation of a document produced by a BERTBASE document encoder [8], and q(x) a query representation produced by a query encoder, also based on BERTBASE. Calculating top-k(p\\u03b7(\\u00b7|x)), the list of k documents z with highest prior probability p\\u03b7(z|x), is a Maximum Inner Product Search (MIPS) problem, which can be approximately solved in sub-linear time [23]. We use a pre-trained bi-encoder from DPR to initialize our retriever and to build the document index. This retriever was trained to retrieve documents which contain answers to TriviaQA [24] questions and Natural Questions [29]. We refer to the document index as the non-parametric memory.\\n\\n### Generator: BART\\n\\nThe generator component p\\u03b8(yi|x, z, y1:i\\u22121) could be modelled using any encoder-decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them. BART was pre-trained using a denoising objective and a variety of different noising functions. It has obtained state-of-the-art results on a diverse set of generation tasks and outperforms comparably-sized T5 models [32]. We refer to the BART generator parameters \\u03b8 as the parametric memory henceforth.\\n\\n### Training\\n\\nWe jointly train the retriever and generator components without any direct supervision on what document should be retrieved. Given a fine-tuning training corpus of input/output pairs (xj, yj), we\\n---\\n## Decoding\\n\\nAt test time, RAG-Sequence and RAG-Token require different ways to approximate arg max y p(y|x).\\n\\n|RAG-Token| |\\n|---|---|\\n|The RAG-Token model can be seen as a standard, autoregressive seq2seq generator with transition probability: p'\\u03b8(yi|x, y1:i-1) = \\u03a3z\\u2208top-k(p(\\u00b7|x)) p\\u03b7(zi|x)p\\u03b8(yi|x, zi, y1:i-1) To decode, we can plug p'\\u03b8(yi|x, y1:i-1) into a standard beam decoder.| |\\n\\n|RAG-Sequence| |\\n|---|---|\\n|For RAG-Sequence, the likelihood p(y|x) does not break into a conventional per-token likelihood, hence we cannot solve it with a single beam search. Instead, we run beam search for each document z, scoring each hypothesis using p\\u03b8(yi|x, z, y1:i-1). This yields a set of hypotheses Y, some of which may not have appeared in the beams of all documents. To estimate the probability of a hypothesis y we run an additional forward pass for each document z for which y does not appear in the beam, multiply generator probability with p\\u03b7(z|x) and then sum the probabilities across beams for the marginals. We refer to this decoding procedure as \\u201cThorough Decoding.\\u201d For longer output sequences, |Y| can become large, requiring many forward passes. For more efficient decoding, we can make a further approximation that p\\u03b8(y|x, zi) \\u2248 0 where y was not generated during beam search from x, zi. This avoids the need to run additional forward passes once the candidate set Y has been generated. We refer to this decoding procedure as \\u201cFast Decoding.\\u201d| |\\n\\n## Experiments\\n\\nWe experiment with RAG in a wide range of knowledge-intensive tasks. For all experiments, we use a single Wikipedia dump for our non-parametric knowledge source. Following Lee et al. [31] and Karpukhin et al. [26], we use the December 2018 dump. Each Wikipedia article is split into disjoint 100-word chunks, to make a total of 21M documents. We use the document encoder to compute an embedding for each document, and build a single MIPS index using FAISS [23] with a Hierarchical Navigable Small World approximation for fast retrieval [37]. During training, we retrieve the top k documents for each query. We consider k \\u2208 {5, 10} for training and set k for test time using dev data. We now discuss experimental details for each task.\\n\\n## Open-domain Question Answering\\n\\nOpen-domain question answering (QA) is an important real-world application and common testbed for knowledge-intensive tasks [20]. We treat questions and answers as input-output text pairs (x, y) and train RAG by directly minimizing the negative log-likelihood of answers. We compare RAG to the popular extractive QA paradigm [5, 7, 31, 26], where answers are extracted spans from retrieved documents, relying primarily on non-parametric knowledge. We also compare to \\u201cClosed-Book QA\\u201d approaches [52], which, like RAG, generate answers, but which do not exploit retrieval, instead relying purely on parametric knowledge. We consider four popular open-domain QA datasets: Natural Questions (NQ) [29], TriviaQA (TQA) [24]. WebQuestions (WQ) [3] and CuratedTrec (CT) [2]. As CT and WQ are small, we follow DPR [26] by initializing CT and WQ models with our NQ RAG model. We use the same train/dev/test splits as prior work [31, 26] and report Exact Match (EM) scores. For TQA, to compare with T5 [52], we also evaluate on the TQA Wiki test set.\\n\\n## Abstractive Question Answering\\n\\nRAG models can go beyond simple extractive QA and answer questions with free-form, abstractive text generation. To test RAG\\u2019s natural language generation (NLG) in a knowledge-intensive setting, we use the MSMARCO NLG task v2.1 [43]. The task consists of questions, ten gold passages retrieved from a search engine for each question, and a full sentence answer annotated from the retrieved passages. We do not use the supplied passages, only the questions and answers, to treat\\n---\\nMSMARCO as an open-domain abstractive QA task. MSMARCO has some questions that cannot be answered in a way that matches the reference answer without access to the gold passages, such as \\\"What is the weather in Volcano, CA?\\\" so performance will be lower without using gold passages. We also note that some MSMARCO questions cannot be answered using Wikipedia alone. Here, RAG can rely on parametric knowledge to generate reasonable responses.\\n\\nJeopardy Question Generation\\n\\nTo evaluate RAG\\u2019s generation abilities in a non-QA setting, we study open-domain question generation. Rather than use questions from standard open-domain QA tasks, which typically consist of short, simple questions, we propose the more demanding task of generating Jeopardy questions. Jeopardy is an unusual format that consists of trying to guess an entity from a fact about that entity. For example, \\\"The World Cup\\\" is the answer to the question \\\"In 1986 Mexico scored as the first country to host this international sports competition twice.\\\" As Jeopardy questions are precise, factual statements, generating Jeopardy questions conditioned on their answer entities constitutes a challenging knowledge-intensive generation task.\\n\\nWe use the splits from SearchQA [10], with 100K train, 14K dev, and 27K test examples. As this is a new task, we train a BART model for comparison. Following [67], we evaluate using the SQuAD-tuned Q-BLEU-1 metric [42]. Q-BLEU is a variant of BLEU with a higher weight for matching entities and has higher correlation with human judgment for question generation than standard metrics. We also perform two human evaluations, one to assess generation factuality, and one for specificity. We define factuality as whether a statement can be corroborated by trusted external sources, and specificity as high mutual dependence between the input and output [33]. We follow best practice and use pairwise comparative evaluation [34]. Evaluators are shown an answer and two generated questions, one from BART and one from RAG. They are then asked to pick one of four options\\u2014question A is better, question B is better, both are good, or neither is good.\\n\\nFact Verification\\n\\nFEVER [56] requires classifying whether a natural language claim is supported or refuted by Wikipedia, or whether there is not enough information to decide. The task requires retrieving evidence from Wikipedia relating to the claim and then reasoning over this evidence to classify whether the claim is true, false, or unverifiable from Wikipedia alone. FEVER is a retrieval problem coupled with a challenging entailment reasoning task. It also provides an appropriate testbed for exploring the RAG models\\u2019 ability to handle classification rather than generation. We map FEVER class labels (supports, refutes, or not enough info) to single output tokens and directly train with claim-class pairs. Crucially, unlike most other approaches to FEVER, we do not use supervision on retrieved evidence. In many real-world applications, retrieval supervision signals aren\\u2019t available, and models that do not require such supervision will be applicable to a wider range of tasks. We explore two variants: the standard 3-way classification task (supports/refutes/not enough info) and the 2-way (supports/refutes) task studied in Thorne and Vlachos [57]. In both cases we report label accuracy.\\n\\nResults\\n\\nOpen-domain Question Answering\\n\\n|Task|RAG|State-of-the-art Models|\\n|---|---|---|\\n|All four open-domain QA tasks|RAG sets a new state of the art|Only on the T5-comparable split for TQA|\\n|RAG combines the generation flexibility of the \\\"closed-book\\\" (parametric only) approaches and the performance of \\\"open-book\\\" retrieval-based approaches| | |\\n|Unlike REALM and T5+SSM, RAG enjoys strong results without expensive, specialized \\\"salient span masking\\\" pre-training [20]| | |\\n|RAG's retriever is initialized using DPR's retriever, which uses retrieval supervision on Natural Questions and TriviaQA| | |\\n|RAG compares favorably to the DPR QA system, which uses a BERT-based \\\"cross-encoder\\\" to re-rank documents, along with an extractive reader| | |\\n|RAG demonstrates that neither a re-ranker nor extractive reader is necessary for state-of-the-art performance| | |\\n\\nThere are several advantages to generating answers even when it is possible to extract them. Documents with clues about the answer but do not contain the answer verbatim can still contribute towards a correct answer being generated, which is not possible with standard extractive approaches, leading\\n---\\n## Table 1: Open-Domain QA Test Scores\\n\\n|Model|NQ|TQA|WQ|CT|\\n|---|---|---|---|---|\\n|Closed Book T5-11B [52]|34.5|- /50.1|37.4|-|\\n|Book T5-11B+SSM[52]|36.6|- /60.5|44.7|-|\\n|Open Book REALM [20]|40.4|- / -|40.7|46.8|\\n|Book DPR [26]|41.5|57.9/ -|41.1|50.6|\\n|RAG-Token|44.1|55.2/66.1|45.5|50.0|\\n|RAG-Seq.|44.5|56.8/68.0|45.2|52.2|\\n\\n## Table 2: Generation and classification Test Scores\\n\\n|Model|Jeopardy|MSMARCO|FVR3|FVR2|\\n|---|---|---|---|---|\\n|B-1|QB-1|R-L|B-1|Label Acc.|\\n|BART|15.1|19.7|38.2|41.6|\\n|RAG-Tok.|17.3|22.2|40.1|41.5|\\n|RAG-Seq.|14.7|21.4|40.8|44.2|\\n\\n4.2 Abstractive Question Answering\\n\\nAs shown in Table 2, RAG-Sequence outperforms BART on Open MS-MARCO NLG by 2.6 Bleu points and 2.6 Rouge-L points. RAG approaches state-of-the-art model performance, which is impressive given that (i) those models access gold passages with specific information required to generate the reference answer, (ii) many questions are unanswerable without the gold passages, and (iii) not all questions are answerable from Wikipedia alone. Table 3 shows some generated answers from our models. Qualitatively, we find that RAG models hallucinate less and generate factually correct text more often than BART. Later, we also show that RAG generations are more diverse than BART generations (see \\u00a74.5).\\n\\n4.3 Jeopardy Question Generation\\n\\nTable 2 shows that RAG-Token performs better than RAG-Sequence on Jeopardy question generation, with both models outperforming BART on Q-BLEU-1. 4 shows human evaluation results, over 452 pairs of generations from BART and RAG-Token. Evaluators indicated that BART was more factual than RAG in only 7.1% of cases, while RAG was more factual in 42.7% of cases, and both RAG and BART were factual in a further 17% of cases, clearly demonstrating the effectiveness of RAG on the task over a state-of-the-art generation model. Evaluators also find RAG generations to be more specific by a large margin. Table 3 shows typical generations from each model.\\n\\nJeopardy questions often contain two separate pieces of information, and RAG-Token may perform best because it can generate responses that combine content from several documents. Figure 2 shows an example. When generating \\u201cSun\\u201d, the posterior is high for document 2 which mentions \\u201cThe Sun Also Rises\\u201d. Similarly, document 1 dominates the posterior when \\u201cA Farewell to Arms\\u201d is generated. Intriguingly, after the first token of each book is generated, the document posterior flattens. This observation suggests that the generator can complete the titles without depending on specific documents. In other words, the model\\u2019s parametric knowledge is sufficient to complete the titles. We find evidence for this hypothesis by feeding the BART-only baseline with the partial decoding \\\"The Sun. BART completes the generation \\\"The Sun Also Rises\\\" is a novel by this author of \\\"The Sun Also Rises\\\" indicating the title \\\"The Sun Also Rises\\\" is stored in BART\\u2019s parameters. Similarly, BART will complete the partial decoding \\\"The Sun Also Rises\\\" is a novel by this author of \\\"A with \\\"The Sun Also Rises\\\" is a novel by this author of \\\"A Farewell to Arms\\\". This example shows how parametric and non-parametric memories work together\\u2014the non-parametric component helps to guide the generation, drawing out specific knowledge stored in the parametric memory.\\n\\n4.4 Fact Verification\\n\\nTable 2 shows our results on FEVER. For 3-way classification, RAG scores are within 4.3% of state-of-the-art models, which are complex pipeline systems with domain-specific architectures and substantial engineering, trained using intermediate retrieval supervision, which RAG does not require.\\n---\\n## Document 1\\n\\nHis works are considered classics of American literature ... His wartime experiences formed the basis for his novel \\\"A Farewell to Arms\\\" (1929) ...\\n\\n## Document 2\\n\\n... artists of the 1920s \\\"Lost Generation\\\" expatriate community. His debut novel, \\\"The Sun Also Rises\\\", was published in 1926.\\n\\nFigure 2: RAG-Token document posterior p(zi|x, yi, y\\u2212i) for each generated token for input \\u201cHemingway\\\" for Jeopardy generation with 5 retrieved documents. The posterior for document 1 is high when generating \\u201cA Farewell to Arms\\\" and for document 2 when generating \\u201cThe Sun Also Rises\\\".\\n\\n|Task|Input|Model|Generation|\\n|---|---|---|---|\\n|define middle ear|BART|?|The middle ear is the part of the ear between the middle ear and the nose.|\\n| |RAG-T| |The middle ear is the portion of the ear internal to the eardrum.|\\n|MS-MARCO|what currency needed in Scotland|BART|The currency needed in Scotland is Pound sterling.|\\n| |RAG-T| |Pound is the currency needed in Scotland.|\\n| |RAG-S| |The currency needed in Scotland is the pound sterling.|\\n| |BART|?|This state has the largest number of counties in the U.S.|\\n|Jeopardy Question Generation|Washington|RAG-T|It\\u2019s the only U.S. state named for a U.S. president|\\n| |RAG-S| |It\\u2019s the state where you\\u2019ll find Mount Rainier National Park|\\n| |BART|*|This epic poem by Dante is divided into 3 parts: the Inferno, the Purgatorio & the Purgatorio|\\n|The Divine Comedy|RAG-T| |Dante\\u2019s \\\"Inferno\\\" is the first part of this epic poem|\\n| |RAG-S| |This 14th century work is divided into 3 sections: \\\"Inferno\\\", \\\"Purgatorio\\\" & \\\"Paradiso\\\"|\\n\\nFor 2-way classification, we compare against Thorne and Vlachos [57], who train RoBERTa [35] to classify the claim as true or false given the gold evidence sentence. RAG achieves an accuracy within 2.7% of this model, despite being supplied with only the claim and retrieving its own evidence. We also analyze whether documents retrieved by RAG correspond to documents annotated as gold evidence in FEVER. We calculate the overlap in article titles between the top k documents retrieved by RAG and gold evidence annotations. We find that the top retrieved document is from a gold article in 71% of cases, and a gold article is present in the top 10 retrieved articles in 90% of cases.\\n\\n## Additional Results\\n\\nGeneration Diversity: Section 4.3 shows that RAG models are more factual and specific than BART for Jeopardy question generation. Following recent work on diversity-promoting decoding, we also investigate generation diversity by calculating the ratio of distinct ngrams to total ngrams generated by different models. Table 5 shows that RAG-Sequence\\u2019s generations are more diverse than RAG-Token\\u2019s, and both are significantly more diverse than BART without needing any diversity-promoting decoding.\\n\\nRetrieval Ablations: A key feature of RAG is learning to retrieve relevant information for the task. To assess the effectiveness of the retrieval mechanism, we run ablations where we freeze the retriever during training. As shown in Table 6, learned retrieval improves results for all tasks.\\n\\nWe compare RAG\\u2019s dense retriever to a word overlap-based BM25 retriever. Here, we replace RAG\\u2019s retriever with a fixed BM25 system, and use BM25 retrieval scores as logits when calculating p(z|x). Table 6 shows the results. For FEVER, BM25 performs best, perhaps since FEVER claims are heavily entity-centric and thus well-suited for word overlap-based retrieval. Differentiable retrieval improves results on all other tasks, especially for Open-Domain QA, where it is crucial.\\n\\nIndex hot-swapping: An advantage of non-parametric memory models like RAG is that knowledge can be easily updated at test time. Parametric-only models like T5 or BART need further training to update their behavior as the world changes. To demonstrate, we build an index using the DrQA Wikipedia dump from December 2016 and compare outputs from RAG using this index to the newer index from our main results (December 2018). We prepare a list of 82 world leaders who had changed\\n---\\n## Table 4: Human assessments for the Jeopardy Question Generation Task\\n\\n| |Factuality|Specificity|\\n|---|---|---|\\n|BART better|7.1%|16.8%|\\n|RAG better|42.7%|37.4%|\\n|Both good|11.7%|11.8%|\\n|Both poor|17.7%|6.9%|\\n|No majority|20.8%|20.1%|\\n\\n## Table 5: Ratio of distinct to total tri-grams for generation tasks\\n\\n| |MSMARCO|Jeopardy QGen|\\n|---|---|---|\\n|Gold|89.6%|90.0%|\\n|BART|70.7%|32.4%|\\n|RAG-Token|77.8%|46.8%|\\n|RAG-Seq.|83.5%|53.8%|\\n\\n## Table 6: Ablations on the dev set\\n\\n|Model|NQ|TQA|WQ|CT|Jeopardy-QGen|MSMarco|FVR-3|FVR-2|\\n|---|---|---|---|---|---|---|---|---|\\n|RAG-Token-BM25|29.7|41.5|32.1|33.1|17.5|22.3|55.5|48.4|75.1|91.6|\\n|RAG-Sequence-BM25|31.8|44.1|36.6|33.8|11.1|19.5|56.5|46.9|\\n|RAG-Token-Frozen|37.8|50.1|37.1|51.1|16.7|21.7|55.9|49.4|72.9|89.4|\\n|RAG-Sequence-Frozen|41.2|52.1|41.8|52.6|11.8|19.6|56.7|47.3|\\n|RAG-Token|43.5|54.8|46.5|51.9|17.9|22.6|56.2|49.4|74.5|90.6|\\n|RAG-Sequence|44.0|55.8|44.9|53.4|15.3|21.5|57.2|47.5|\\n\\nBetween these dates and use a template \\u201cWho is {position}?\\u201d (e.g. \\u201cWho is the President of Peru?\\u201d) to query our NQ RAG model with each index. RAG answers 70% correctly using the 2016 index for 2016 world leaders and 68% using the 2018 index for 2018 world leaders. Accuracy with mismatched indices is low (12% with the 2018 index and 2016 leaders, 4% with the 2016 index and 2018 leaders). This shows we can update RAG\\u2019s world knowledge by simply replacing its non-parametric memory.\\n\\nEffect of Retrieving more documents: Models are trained with either 5 or 10 retrieved latent documents, and we do not observe significant differences in performance between them. We have the flexibility to adjust the number of retrieved documents at test time, which can affect performance and runtime. Figure 3 (left) shows that retrieving more documents at test time monotonically improves Open-domain QA results for RAG-Sequence, but performance peaks for RAG-Token at 10 retrieved documents. Figure 3 (right) shows that retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, but the effect is less pronounced for RAG-Sequence.\\n\\n| |44|80|Bleu-1 / Rouge-L score|\\n|---|---|---|---|\\n| | |NQ Answer Recall @ K|56|\\n|NQ Exact Match| |54| |\\n| | | |RAG-Tok R-L| |\\n| | | |RAG-Tok B-1| |\\n| | | |RAG-Seq R-L| |\\n| | | |RAG-Seq B-1| |\\n\\nFigure 3: Left: NQ performance as more documents are retrieved. Center: Retrieval recall performance in NQ. Right: MS-MARCO Bleu-1 and Rouge-L as more documents are retrieved.\\n\\n## Related Work\\n\\nSingle-Task Retrieval: Prior work has shown that retrieval improves performance across a variety of NLP tasks when considered in isolation. Such tasks include open-domain question answering, fact checking, fact completion, long-form question answering, Wikipedia article generation, dialogue, translation, and language modeling. Our work unifies previous successes in incorporating retrieval into individual tasks, showing that a single retrieval-based architecture is capable of achieving strong performance across several tasks.\\n---\\n## General-Purpose Architectures for NLP\\n\\nPrior work on general-purpose architectures for NLP tasks has shown great success without the use of retrieval. A single, pre-trained language model has been shown to achieve strong performance on various classification tasks in the GLUE benchmarks [60, 61] after fine-tuning [49, 8]. GPT-2 [50] later showed that a single, left-to-right, pre-trained language model could achieve strong performance across both discriminative and generative tasks. For further improvement, BART [32] and T5 [51, 52] propose a single, pre-trained encoder-decoder model that leverages bi-directional attention to achieve stronger performance on discriminative and generative tasks. Our work aims to expand the space of possible tasks with a single, unified architecture, by learning a retrieval module to augment pre-trained, generative language models.\\n\\n## Learned Retrieval\\n\\nThere is significant work on learning to retrieve documents in information retrieval, more recently with pre-trained, neural language models [44, 26] similar to ours. Some work optimizes the retrieval module to aid in a specific, downstream task such as question answering, using search [46], reinforcement learning [6, 63, 62], or a latent variable approach [31, 20] as in our work. These successes leverage different retrieval-based architectures and optimization techniques to achieve strong performance on a single task, while we show that a single retrieval-based architecture can be fine-tuned for strong performance on a variety of tasks.\\n\\n## Memory-based Architectures\\n\\nOur document index can be seen as a large external memory for neural networks to attend to, analogous to memory networks [64, 55]. Concurrent work [14] learns to retrieve a trained embedding for each entity in the input, rather than to retrieve raw text as in our work. Other work improves the ability of dialog models to generate factual text by attending over fact embeddings [15, 13]. A key feature of our memory is that it is comprised of raw text rather distributed representations, which makes the memory both (i) human-readable, lending a form of interpretability to our model, and (ii) human-writable, enabling us to dynamically update the model\\u2019s memory by editing the document index. This approach has also been used in knowledge-intensive dialog, where generators have been conditioned on retrieved text directly, albeit obtained via TF-IDF rather than end-to-end learnt retrieval [9].\\n\\n## Retrieve-and-Edit approaches\\n\\nOur method shares some similarities with retrieve-and-edit style approaches, where a similar training input-output pair is retrieved for a given input, and then edited to provide a final output. These approaches have proved successful in a number of domains including Machine Translation [18, 22] and Semantic Parsing [21]. Our approach does have several differences, including less of emphasis on lightly editing a retrieved item, but on aggregating content from several pieces of retrieved content, as well as learning latent retrieval, and retrieving evidence documents rather than related training pairs. This said, RAG techniques may work well in these settings, and could represent promising future work.\\n\\n## Discussion\\n\\nIn this work, we presented hybrid generation models with access to parametric and non-parametric memory. We showed that our RAG models obtain state of the art results on open-domain QA. We found that people prefer RAG\\u2019s generation over purely parametric BART, finding RAG more factual and specific. We conducted an thorough investigation of the learned retrieval component, validating its effectiveness, and we illustrated how the retrieval index can be hot-swapped to update the model without requiring any retraining. In future work, it may be fruitful to investigate if the two components can be jointly pre-trained from scratch, either with a denoising objective similar to BART or some another objective. Our work opens up new research directions on how parametric and non-parametric memories interact and how to most effectively combine them, showing promise in being applied to a wide variety of NLP tasks.\\n---\\n## Broader Impact\\n\\nThis work offers several positive societal benefits over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it \\u201challucinate\\u201d less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct benefit to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs.\\n\\nWith these advantages also come potential downsides: Wikipedia, or any potential external knowledge source, will probably never be entirely factual and completely devoid of bias. Since RAG can be employed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably to a lesser extent, including that it might be used to generate abuse, faked or misleading content in the news or on social media; to impersonate others; or to automate the production of spam/phishing content [54]. Advanced language models may also lead to the automation of various jobs in the coming decades [16]. In order to mitigate these risks, AI systems could be employed to fight against misleading content and automated spam/phishing.\\n\\n## Acknowledgments\\n\\nThe authors would like to thank the reviewers for their thoughtful and constructive feedback on this paper, as well as HuggingFace for their help in open-sourcing code to run RAG models. The authors would also like to thank Kyunghyun Cho and Sewon Min for productive discussions and advice. EP thanks supports from the NSF Graduate Research Fellowship. PL is supported by the FAIR PhD program.\\n\\n## References\\n\\n[1] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. arXiv:1611.09268 [cs], November 2016. URL http://arxiv.org/abs/1611.09268. arXiv: 1611.09268.\\n[2] Petr Baudi\\u0161 and Jan \\u0160ediv` y. Modeling of pe question answering task in pe yodaqa system. In International Conference of pe Cross-Language Evaluation Forum for European Languages, pages 222\\u2013228. Springer, 2015. URL https://link.springer.com/chapter/10.1007% 2F978-3-319-24027-5_20.\\n[3] Jonapan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic Parsing on Freebase from Question-Answer Pairs. In Proceedings of pe 2013 Conference on Empirical Mepods in Natural Language Processing, pages 1533\\u20131544, Seattle, Washington, USA, October 2013. Association for Computational Linguistics. URL http://www.aclweb.org/anpology/ D13-1160.\\n[4] Bin Bi, Chenliang Li, Chen Wu, Ming Yan, and Wei Wang. Palm: Pre-training an autoencod- ing&autoregressive language model for context-conditioned generation. ArXiv, abs/2004.07159, 2020. URL https://arxiv.org/abs/2004.07159.\\n[5] Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to Answer Open-Domain Questions. In Proceedings of pe 55p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 1870\\u20131879, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https://www.aclweb.org/anpology/P17-1171.\\n[6] Eunsol Choi, Daniel Hewlett, Jakob Uszkoreit, Illia Polosukhin, Alexandre Lacoste, and Jonapan Berant. Coarse-to-fine question answering for long documents. In Proceedings of pe 55p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 209\\u2013220, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1020. URL https://www.aclweb.org/anpology/P17-1020.\\n---\\nChristopher Clark and Matt Gardner. Simple and Effective Multi-Paragraph Reading Comprehension. arXiv:1710.10723 [cs], October 2017. URL http://arxiv.org/abs/1710.10723. arXiv: 1710.10723.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of pe 2019 Conference of pe Norp American Chapter of pe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171\\u20134186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https://www.aclweb.org/anpology/N19-1423.\\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wizard of wikipedia: Knowledge-powered conversational agents. In International Conference on Learning Representations, 2019. URL https://openreview.net/forum?id=r1l73iRqKm.\\nMatpew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. SearchQA: A New Q&A Dataset Augmented wip Context from a Search Engine. arXiv:1704.05179 [cs], April 2017. URL http://arxiv.org/abs/1704.05179. arXiv: 1704.05179.\\nAngela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proceedings of pe 56p Annual Meeting of pe Association for Computational Linguistics (Volume 1: Long Papers), pages 889\\u2013898, Melbourne, Australia, July 2018. Association for Computational Linguistics. doi: 10.18653/v1/P18-1082. URL https://www.aclweb.org/anpology/P18-1082.\\nAngela Fan, Yacine Jernite, Epan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: Long form question answering. In Proceedings of pe 57p Annual Meeting of pe Association for Computational Linguistics, pages 3558\\u20133567, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1346. URL https://www.aclweb.org/anpology/P19-1346.\\nAngela Fan, Claire Gardent, Chloe Braud, and Antoine Bordes. Augmenting transformers wip KNN-based composite memory, 2020. URL https://openreview.net/forum?id=H1gx1CNKPH.\\nThibault F\\u00e9vry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol Choi, and Tom Kwiatkowski. Entities as experts: Sparse memory access wip entity supervision. ArXiv, abs/2004.07202, 2020. URL https://arxiv.org/abs/2004.07202.\\nMarjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wentau Yih, and Michel Galley. A knowledge-grounded neural conversation model. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16710.\\nKatja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. When will AI exceed human performance? evidence from AI experts. CoRR, abs/1705.08807, 2017. URL http://arxiv.org/abs/1705.08807.\\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17282.\\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor O.K. Li. Search engine guided neural machine translation. In 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, 32nd AAAI Conference on Artificial Intelligence, AAAI 2018, pages 5133\\u20135140. AAAI press, 2018. 32nd AAAI Conference on Artificial Intelligence, AAAI 2018 ; Conference date: 02-02-2018 Through 07-02-2018.\\nKelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, and Percy Liang. Generating sentences by editing prototypes. Transactions of pe Association for Computational Linguistics, 6:437\\u2013450, 2018. doi: 10.1162/tacl_a_00030. URL https://www.aclweb.org/anpology/Q18-1031.\\n---\\n## References\\n\\n|[20]|Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. REALM: Retrieval-augmented language model pre-training. ArXiv, abs/2002.08909, 2020. URL https://arxiv.org/abs/2002.08909.|\\n|---|---|\\n|[21]|Tatsunori B Hashimoto, Kelvin Guu, Yonatan Oren, and Percy S Liang. A retrieve-and-edit framework for predicting structured outputs. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems 31, pages 10052\\u201310062. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/8209-a-retrieve-and-edit-framework-for-predicting-structured-outputs.pdf.|\\n|[22]|Nabil Hossain, Marjan Ghazvininejad, and Luke Zettlemoyer. Simple and effective retrieve-edit-rerank text generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2532\\u20132538, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.228. URL https://www.aclweb.org/anthology/2020.acl-main.228.|\\n|[23]|Jeff Johnson, Matthijs Douze, and Herv\\u00e9 J\\u00e9gou. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.08734, 2017. URL https://arxiv.org/abs/1702.08734.|\\n|[24]|Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601\\u20131611, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1147. URL https://www.aclweb.org/anthology/P17-1147.|\\n|[25]|Armand Joulin and Tomas Mikolov. Inferring algorithmic patterns with stack-augmented recurrent nets. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1, NIPS\\u201915, page 190\\u2013198, Cambridge, MA, USA, 2015. MIT Press. URL https://papers.nips.cc/paper/5857-inferring-algorithmic-patterns-with-stack-augmented-recurrent-nets.|\\n|[26]|Vladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906, 2020. URL https://arxiv.org/abs/2004.04906.|\\n|[27]|Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.|\\n|[28]|Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412.6980.|\\n|[29]|Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural Questions: a Benchmark for Question Answering Research. Transactions of the Association of Computational Linguistics, 2019. URL https://tomkwiat.users.x20web.corp.google.com/papers/natural-questions/main-1455-kwiatkowski.pdf.|\\n|[30]|Guillaume Lample, Alexandre Sablayrolles, Marc\\u2019 Aurelio Ranzato, Ludovic Denoyer, and Herve Jegou. Large memory layers with product keys. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\\u2019 Alch\\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8548\\u20138559. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/9061-large-memory-layers-with-product-keys.pdf.|\\n|[31]|Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association|\\n---\\n|Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.|BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019. URL https://arxiv.org/abs/1910.13461.|\\n|---|---|\\n|Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan.|A diversity-promoting objective function for neural conversation models. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 110\\u2013119, San Diego, California, June 2016. Association for Computational Linguistics. doi: 10.18653/v1/N16-1014. URL https://www.aclweb.org/anthology/N16-1014.|\\n|Margaret Li, Jason Weston, and Stephen Roller.|Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons. ArXiv, abs/1909.03087, 2019. URL https://arxiv.org/abs/1909.03087.|\\n|Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong, and Zhongjun He.|Robust neural machine translation with joint textual and phonetic embedding. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3044\\u20133049, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1291. URL https://www.aclweb.org/anthology/P19-1291.|\\n|Peter J. Liu*, Mohammad Saleh*, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer.|Generating wikipedia by summarizing long sequences. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=Hyg0vbWC-.|\\n|Yury A. Malkov and D. A. Yashunin.|Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:824\\u2013836, 2016. URL https://arxiv.org/abs/1603.09320.|\\n|Gary Marcus.|The next decade in ai: four steps towards robust artificial intelligence. arXiv preprint arXiv:2002.06177, 2020. URL https://arxiv.org/abs/2002.06177.|\\n|Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim Rockt\\u00e4schel, Vassilis Plachouras, Fabrizio Silvestri, and Sebastian Riedel.|How decoding strategies affect the verifiability of generated text. arXiv preprint arXiv:1911.03587, 2019. URL https://arxiv.org/abs/1911.03587.|\\n|Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu.|Mixed precision training. In ICLR, 2018. URL https://openreview.net/forum?id=r1gs9JgRZ.|\\n|Nikita Moghe, Siddhartha Arora, Suman Banerjee, and Mitesh M. Khapra.|Towards exploiting background knowledge for building conversation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2322\\u20132332, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1255. URL https://www.aclweb.org/anthology/D18-1255.|\\n|Preksha Nema and Mitesh M. Khapra.|Towards a better metric for evaluating question generation systems. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3950\\u20133959, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1429. URL https://www.aclweb.org/anthology/D18-1429.|\\n|Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.|MS MARCO: A human generated machine reading comprehension dataset. In Tarek Richard Besold, Antoine Bordes, Artur S. d\\u2019Avila Garcez, and Greg Wayne, editors, Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic.|\\n---\\napproaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016, volume 1773 of CEUR Workshop Proceedings. CEUR-WS.org, 2016. URL http://ceur-ws.org/Vol-1773/CoCoNIPS_2016_paper9.pdf.\\n\\n[44] Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. arXiv preprint arXiv:1901.04085, 2019. URL https://arxiv.org/abs/1901.04085.\\n\\n[45] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48\\u201353, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-4009. URL https://www.aclweb.org/anthology/N19-4009.\\n\\n[46] Ethan Perez, Siddharth Karamcheti, Rob Fergus, Jason Weston, Douwe Kiela, and Kyunghyun Cho. Finding generalizable evidence by learning to convince q&a models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2402\\u20132411, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.\\n\\n[47] Fabio Petroni, Tim Rockt\\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2463\\u20132473, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1250. URL https://www.aclweb.org/anthology/D19-1250.\\n\\n[48] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rockt\\u00e4schel, Yuxiang Wu, Alexander H. Miller, and Sebastian Riedel. How context affects language models\\u2019 factual predictions. In Automated Knowledge Base Construction, 2020. URL https://openreview.net/forum?id=025X0zPfn.\\n\\n[49] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving Language Understanding by Generative Pre-Training, 2018. URL https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf.\\n\\n[50] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners, 2019. URL https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.\\n\\n[51] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv e-prints, 2019. URL https://arxiv.org/abs/1910.10683.\\n\\n[52] Adam Roberts, Colin Raffel, and Noam Shazeer. How much knowledge can you pack into the parameters of a language model? arXiv e-prints, 2020. URL https://arxiv.org/abs/2002.08910.\\n\\n[53] Stephen Robertson and Hugo Zaragoza. The probabilistic relevance framework: Bm25 and beyond. Found. Trends Inf. Retr., 3(4):333\\u2013389, April 2009. ISSN 1554-0669. doi: 10.1561/1500000019. URL https://doi.org/10.1561/1500000019.\\n\\n[54] Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, and Jian-Bing Wang. Release strategies and the social impacts of language models. ArXiv, abs/1908.09203, 2019.\\n\\n[55] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2440\\u20132448. Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf.\\n---\\n# References\\n\\n[56] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In Proceedings of pe 2018 Conference of pe Norp American Chapter of pe Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809\\u2013819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-1074. URL https://www.aclweb.org/anpology/N18-1074.\\n[57] James H. Thorne and Andreas Vlachos. Avoiding catastrophic forgetting in mitigating model biases in sentence-pair classification wip elastic weight consolidation. ArXiv, abs/2004.14366, 2020. URL https://arxiv.org/abs/2004.14366.\\n[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \\u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanapan, and R. Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5998\\u20136008. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf.\\n[59] Ashwin Vijayakumar, Michael Cogswell, Ramprasaap Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes. AAAI Conference on Artificial Intelligence, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17329.\\n[60] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of pe 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353\\u2013355, Brussels, Belgium, November 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5446. URL https://www.aclweb.org/anpology/W18-5446.\\n[61] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 3261\\u20133275. Curran Associates, Inc., 2019. URL https://arxiv.org/abs/1905.00537.\\n[62] Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, and Jing Jiang. R3: Reinforced ranker-reader for open-domain question answering. In Sheila A. McIlraip and Kilian Q. Weinberger, editors, Proceedings of pe Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), pe 30p innovative Applications of Artificial Intelligence (IAAI-18), and pe 8p AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 5981\\u20135988. AAAI Press, 2018. URL https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16712.\\n[63] Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaoxiao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger, Gerald Tesauro, and Murray Campbell. Evidence aggregation for answer re-ranking in open-domain question answering. In ICLR, 2018. URL https://openreview.net/forum?id=rJl3yM-Ab.\\n[64] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1410.3916.\\n[65] Jason Weston, Emily Dinan, and Alexander Miller. Retrieve and refine: Improved sequence generation models for dialogue. In Proceedings of pe 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI, pages 87\\u201392, Brussels, Belgium, October 2018. Association for Computational Linguistics. doi: 10.18653/v1/W18-5713. URL https://www.aclweb.org/anpology/W18-5713.\\n---\\n## References\\n\\n[66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anpony Moi, Pierric Cistac, Tim Rault, R\\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Huggingface\\u2019s transformers: State-of-pe-art natural language processing. ArXiv, abs/1910.03771, 2019.\\n[67] Shiyue Zhang and Mohit Bansal. Addressing semantic drift in question generation for semi-supervised question answering. In Proceedings of pe 2019 Conference on Empirical Mepods in Natural Language Processing and pe 9p International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2495\\u20132509, Hong Kong, China, November 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1253. URL https://www.aclweb.org/anpology/D19-1253.\\n[68] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. Reasoning over semantic-level graph for fact checking. ArXiv, abs/1909.03745, 2019. URL https://arxiv.org/abs/1909.03745.\\n---\\n## Appendices for Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\n\\n### Implementation Details\\n\\nFor Open-domain QA we report test numbers using 15 retrieved documents for RAG-Token models. For RAG-Sequence models, we report test results using 50 retrieved documents, and we use the Thorough Decoding approach since answers are generally short. We use greedy decoding for QA as we did not find beam search improved results. For Open-MSMarco and Jeopardy question generation, we report test numbers using ten retrieved documents for both RAG-Token and RAG-Sequence, and we also train a BART-large model as a baseline. We use a beam size of four, and use the Fast Decoding approach for RAG-Sequence models, as Thorough Decoding did not improve performance.\\n\\n### Human Evaluation\\n\\n|Which sentence is more factually true?|Select option|\\n|---|---|\\n|Noje: Scna Guesucn?|snterzt \\\"The8r Nuso Rists S7lerce|\\n|IncicateFich Farcncllic AM; on Im Iclbwng sentarces Is Mca luclualy Injb[ealecllo ZLbko Uaino cnoc urdoco| |\\n\\nFigure 4: Annotation interface for human evaluation of factuality. A pop-out for detailed instructions and a worked example appear when clicking \\\"view tool guide\\\".\\n\\nFigure 4 shows the user interface for human evaluation. To avoid any biases for screen position, which model corresponded to sentence A and sentence B was randomly selected for each example. Annotators were encouraged to research the topic using the internet, and were given detailed instructions and worked examples in a full instructions tab. We included some gold sentences in order to assess the accuracy of the annotators. Two annotators did not perform well on these examples and their annotations were removed from the results.\\n\\n### Training Setup Details\\n\\nWe train all RAG models and BART baselines using Fairseq [45]. We train with mixed precision floating point arithmetic, distributing training across 8, 32GB NVIDIA V100 GPUs, though training and inference can be run on one GPU. We find that doing Maximum Inner Product Search with FAISS is sufficiently fast on CPU, so we store document index vectors on CPU, requiring \\u223c 100 GB of CPU memory for all of Wikipedia. After submission, We have ported our code to HuggingFace Transformers, which achieves equivalent performance to the previous version but is a cleaner and easier to use implementation. This version is also open-sourced. We also compress the document index using FAISS\\u2019s compression tools, reducing the CPU memory requirement to 36GB. Scripts to run experiments with RAG can be found at https://github.com/huggingface/transformers/blob/master/examples/rag/README.md and an interactive demo of a RAG model can be found at https://huggingface.co/rag/\\n\\n2. https://github.com/pytorch/fairseq\\n\\n3. https://github.com/huggingface/transformers\\n---\\n## Further Details on Open-Domain QA\\n\\nFor open-domain QA, multiple answer annotations are often available for a given question. These answer annotations are exploited by extractive models during training as typically all the answer annotations are used to find matches within documents when preparing training data. For RAG, we also make use of multiple annotation examples for Natural Questions and WebQuestions by training the model with each (q, a) pair separately, leading to a small increase in accuracy. For TriviaQA, there are often many valid answers to a given question, some of which are not suitable training targets, such as emoji or spelling variants. For TriviaQA, we filter out answer candidates if they do not occur in top 1000 documents for the query.\\n\\n## CuratedTrec preprocessing\\n\\nThe answers for CuratedTrec are given in the form of regular expressions, which has been suggested as a reason why it is unsuitable for answer-generation models [20]. To overcome this, we use a pre-processing step where we first retrieve the top 1000 documents for each query, and use the answer that most frequently matches the regex pattern as the supervision target. If no matches are found, we resort to a simple heuristic: generate all possible permutations for each regex, replacing non-deterministic symbols in the regex nested tree structure with a whitespace.\\n\\n## TriviaQA Evaluation setups\\n\\nThe open-domain QA community customarily uses public development datasets as test datasets, as test data for QA datasets is often restricted and dedicated to reading comprehension purposes. We report our results using the datasets splits used in DPR [26], which are consistent with common practice in Open-domain QA. For TriviaQA, this test dataset is the public TriviaQA Web Development split. Roberts et al. [52] used the TriviaQA official Wikipedia test set instead. F\\u00e9vry et al. [14] follow this convention in order to compare with Roberts et al. [52] (See appendix of [14]). We report results on both test sets to enable fair comparison to both approaches. We find that our performance is much higher using the official Wiki test set, rather than the more conventional open-domain test set, which we attribute to the official Wiki test set questions being simpler to answer from Wikipedia.\\n\\n## Further Details on FEVER\\n\\nFor FEVER classification, we follow the practice from [32], and first re-generate the claim, and then classify using the representation of the final hidden state, before finally marginalizing across documents to obtain the class probabilities. The FEVER task traditionally has two sub-tasks. The first is to classify the claim as either \\\"Supported\\\", \\\"Refuted\\\" or \\\"Not Enough Info\\\", which is the task we explore in the main paper. FEVER\\u2019s other sub-task involves extracting sentences from Wikipedia as evidence supporting the classification prediction. As FEVER uses a different Wikipedia dump to us, directly tackling this task is not straightforward. We hope to address this in future work.\\n\\n## Null Document Probabilities\\n\\nWe experimented with adding \\\"Null document\\\" mechanism to RAG, similar to REALM [20] in order to model cases where no useful information could be retrieved for a given input. Here, if k documents were retrieved, we would additionally \\\"retrieve\\\" an empty document and predict a logit for the null document, before marginalizing over k + 1 predictions. We explored modelling this null document logit by learning (i) a document embedding for the null document, (ii) a static learnt bias term, or (iii) a neural network to predict the logit. We did not find that these improved performance, so in the interests of simplicity, we omit them. For Open MS-MARCO, where useful retrieved documents cannot always be retrieved, we observe that the model learns to always retrieve a particular set of documents for questions that are less likely to benefit from retrieval, suggesting that null document mechanisms may not be necessary for RAG.\\n\\n## Parameters\\n\\nOur RAG models contain the trainable parameters for the BERT-base query and document encoder of DPR, with 110M parameters each (although we do not train the document encoder ourselves) and 406M trainable parameters from BART-large, 406M parameters, making a total of 626M trainable.\\n---\\n|Task|Train|Development|Test|\\n|---|---|---|---|\\n|Natural Questions|79169|8758|3611|\\n|TriviaQA|78786|8838|11314|\\n|WebQuestions|3418|362|2033|\\n|CuratedTrec|635|134|635|\\n|Jeopardy Question Generation|97392|13714|26849|\\n|MS-MARCO|153726|12468|101093*|\\n|FEVER-3-way|145450|10000|10000|\\n|FEVER-2-way|96966|6666|6666|\\n\\nparameters. The best performing \\\"closed-book\\\" (parametric only) open-domain QA model is T5-11B\\nwith 11 Billion trainable parameters. The T5 model with the closest number of parameters to our\\nmodels is T5-large (770M parameters), which achieves a score of 28.9 EM on Natural Questions [52],\\nsubstantially below the 44.5 that RAG-Sequence achieves, indicating that hybrid parametric/non-\\nparametric models require far fewer trainable parameters for strong open-domain QA performance.\\nThe non-parametric memory index does not consist of trainable parameters, but does consists of 21M\\n728 dimensional vectors, consisting of 15.3B values. These can be easily be stored at 8-bit floating\\npoint precision to manage memory and disk footprints.\\n\\n## Retrieval Collapse\\n\\nIn preliminary experiments, we observed that for some tasks such as story generation [11], the\\nretrieval component would \\u201ccollapse\\u201d and learn to retrieve the same documents regardless of the\\ninput. In these cases, once retrieval had collapsed, the generator would learn to ignore the documents,\\nand the RAG model would perform equivalently to BART. The collapse could be due to a less-explicit\\nrequirement for factual knowledge in some tasks, or the longer target sequences, which could result\\nin less informative gradients for the retriever. Perez et al. [46] also found spurious retrieval results\\nwhen optimizing a retrieval component in order to improve performance on downstream tasks.\\n\\n## Number of instances per dataset\\n\\nThe number of training, development and test datapoints in each of our datasets is shown in Table 7.\"\n}\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/cdd1371d-caf7-47a7-94c5-810a868be477"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"133e41a62e904dd2b46508abcfd947ae","deepnote_cell_type":"text-cell-h3"},"source":"### OpenAI summary","block_group":"d1aeac78675841e2a325e4344648d91a"},{"cell_type":"code","metadata":{"source_hash":"71682cfc","execution_start":1710041978446,"execution_millis":1789,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"9acb24a26620429f9947432265c0a73c","deepnote_cell_type":"code"},"source":"import openai\nfrom openai import AsyncOpenAI\nimport sqlite3\n\nasync def query_info_with_gpt(arxiv_paper_markdown, arxiv_metadata, user_query):\n    MAX_CONTEXT_LENGTH = 15500 \n\n    # Initial context setup and trimming\n    context = f\"Context: {arxiv_metadata}\\n{arxiv_paper_markdown}\"\n    while count_tokens(context) > MAX_CONTEXT_LENGTH:\n        char_to_token_ratio = len(context) / count_tokens(context)\n        max_char_length = int(MAX_CONTEXT_LENGTH * char_to_token_ratio)\n        context = context[:max_char_length]\n\n    # Constructing the prompt\n    prompt = (\n        f\"Summarize this in 100 characters based on the user query {user_query}: {context}\"\n    )\n\n    # Setting up OpenAI client\n    client = AsyncOpenAI(api_key=openai_api_key)\n\n    # Making an asynchronous API call\n    try:\n        response = await client.chat.completions.create(\n            messages=[\n                {\"role\": \"system\", \"content\": prompt}\n            ],\n            model=\"gpt-4\"  # You can switch to other models if needed\n        )\n        answer = response.choices[0].message.content  # Extracting the response\n        return answer\n    except openai.error.InternalServerError as e:\n        print(f\"OpenAI API Internal Server Error: {e}\")\n\n# Define the main operation\nasync def test():\n    # Connect to the SQLite database\n    conn = connection()\n    c = conn.cursor()\n\n    # Fetch data from the Papers table\n    c.execute(\"SELECT * FROM Papers WHERE arxiv_metadata IS NOT NULL LIMIT 1\")\n    row = c.fetchone()\n\n    # Check if data exists\n    if row:\n        _, _, _, _, _, _, _, arxiv_metadata, _, arxiv_paper_markdown, _, _ = row\n        user_query = \"Insert your query here\"  # Define the user query as needed\n\n        # Call the GPT function and handle response\n        response = await query_info_with_gpt(arxiv_paper_markdown, arxiv_metadata, user_query)\n        print(\"LLM response:\", response)\n\n        # Here, insert the response into the database if needed, or handle it as necessary\n\n    else:\n        print(\"No data found in the Papers table.\")\n    if conn is not None:\n        conn.close()  # Ensure the connection is closed if it's not None\n# Execute the main operation\nimport asyncio\nasyncio.run(test())","block_group":"af90ef5021e045349b44874359e92727","execution_count":134,"outputs":[{"name":"stdout","text":"LLM response: The file is about FEVER, a large-scale dataset used for fact extraction and verification.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/b54bd03e-91e8-43d1-9ce0-4b15002d8f3b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"68c2a53f59e34471ac18e89954f9f5b9","deepnote_cell_type":"text-cell-h3"},"source":"### Relevance score (placeholder)","block_group":"f66c6c29fca947318e013ef5f42db0e8"},{"cell_type":"markdown","metadata":{"id":"v2O3rIRU34-D","deepnote_app_block_visible":true,"cell_id":"46b1b784cc1143cfa95c6439fedb8c62","deepnote_cell_type":"markdown"},"source":"# Processing loops","block_group":"39dc0b3d42fa46779e8ede7b01488c2c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"898b5400689f45138bb79c6679624950","deepnote_cell_type":"text-cell-p"},"source":"Extract search results from Google based on user query","block_group":"53ccfb646a6042d58d42f1ae63a83842"},{"cell_type":"code","metadata":{"id":"eLiFFElg4BmL","colab":{"height":211,"base_uri":"https://localhost:8080/"},"outputId":"e0289559-f816-4108-c6bc-acb3769ac955","source_hash":"21be4c4b","execution_start":1710018040408,"execution_millis":14666,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"05fbe427a60b4dccb97f79f14b4d90c7","deepnote_cell_type":"code"},"source":"import json\nimport time\n\nclass PageEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, Page):\n            return obj.dict()  # Convert Page to a dictionary\n        elif isinstance(obj, Paper):\n            return obj.dict()  # Convert Paper to a dictionary\n        elif isinstance(obj, Link):\n            return obj.dict()  # Convert Link to a dictionary\n        return json.JSONEncoder.default(self, obj)  # Handle other types\n\ndef fetch_and_process(link, query):\n    conn = None\n    try:\n        conn = connection()  # Open a new connection\n        c = conn.cursor()  # Create a new cursor\n\n        c.execute(\"SELECT scraping_status, html FROM google_search_results WHERE url = %s\", (link,))\n        result = c.fetchone()\n        if result and result[0] == '200':\n            print(f\"Status: {result[0]}, already fetched for URL: {link}\")\n            html_content = result[1].replace('\\x00', '')  # Sanitize HTML content from database\n        else:\n            response = fetch_url_content(link)\n            print(f\"Status:{response['status']} for URL: {link}\")\n            html_content = response['soup'].decode('utf-8', 'replace') if response['status'] == 200 else \"\"\n            html_content = html_content.replace('\\x00', '')\n            insert_scraping_results(link, html_content, str(response['status']), query)  # Ensure 'insert_scraping_results' correctly uses the 'conn' and 'c' objects\n\n        if html_content:\n            insert_arxiv_links_into_db(html_content, query)  # Adjust 'insert_arxiv_links_into_db' to take 'conn' and 'c' as additional parameters\n\n    except psycopg2.OperationalError as e:\n        print(f\"Database operation failed for URL: {link}, Error: {e}\")\n        if conn:\n            conn.rollback()  # Roll back any changes due to error\n\n    finally:\n        if c:\n            c.close()  # Close the cursor\n        if conn:\n            conn.close()  # Close the connection\n\ndef search_and_fetch_google(query):\n    search_results = search_google(query)  # Ensure this function is defined elsewhere\n    print(query, search_results)\n\n    # Sequential execution\n    for link in search_results:\n        try:\n            data = fetch_and_process(link, query)\n        except Exception as exc:\n            print(f'fetch_and_process exception: {exc}')\n\n    print('Finished extracting search results pages')\n\n# Example usage\nquery = \"Top academic papers on Chain of Thought\"\nsearch_and_fetch_google(query)\n","block_group":"5fc3839f5cad422fbec8edc389da989a","execution_count":109,"outputs":[{"name":"stdout","text":"Top academic papers on Chain of Thought ['https://arxiv.org/abs/2201.11903', 'https://openreview.net/pdf?id=_VjQlMeSB_J', 'https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html', 'https://www.linkedin.com/pulse/chain-thought-new-frontier-prompt-engineering-tiran-dagan-wkuce', 'https://research.google/pubs/self-consistency-improves-chain-of-thought-reasoning-in-language-models/', 'https://openreview.net/forum?id=_VjQlMeSB_J', 'https://arxiv.org/pdf/2201.11903', 'https://medium.com/@JerryCuomo/lets-think-step-by-step-advanced-reasoning-in-business-with-chain-of-thought-prompting-dd5ae8a6008', 'https://www.searchenginejournal.com/google-chain-of-thought-prompting/450106/', 'https://www.youtube.com/watch?v=538uaE-AACs']\nStatus: 200, already fetched for URL: https://arxiv.org/abs/2201.11903\narxiv_links[34]: ['https://info.arxiv.org/about/ourmembers.html', 'https://info.arxiv.org/about/donate.html', 'https://info.arxiv.org/help', 'https://arxiv.org/search/advanced', 'https://arxiv.org/', 'https://arxiv.org/login', 'https://info.arxiv.org/help', 'https://info.arxiv.org/about', 'https://arxiv.org/abs/2201.11903v1', 'https://arxiv.org/search/cs?searchtype=author&query=Wei,+J', 'https://arxiv.org/search/cs?searchtype=author&query=Wang,+X', 'https://arxiv.org/search/cs?searchtype=author&query=Schuurmans,+D', 'https://arxiv.org/search/cs?searchtype=author&query=Bosma,+M', 'https://arxiv.org/search/cs?searchtype=author&query=Ichter,+B', 'https://arxiv.org/search/cs?searchtype=author&query=Xia,+F', 'https://arxiv.org/search/cs?searchtype=author&query=Chi,+E', 'https://arxiv.org/search/cs?searchtype=author&query=Le,+Q', 'https://arxiv.org/search/cs?searchtype=author&query=Zhou,+D', 'https://arxiv.org/abs/2201.11903', 'https://arxiv.org/abs/2201.11903v6', 'https://info.arxiv.org/help/trackback.html', 'https://arxiv.org/ct?url=http://www.bibsonomy.org/BibtexHandler?requTask%3Dupload%26url%3Dhttps://arxiv.org/abs/2201.11903%26description%3DChain-of-Thought+Prompting+Elicits+Reasoning+in+Large+Language+Models&v=be299b0a', 'https://arxiv.org/ct?url=https://reddit.com/submit?url%3Dhttps://arxiv.org/abs/2201.11903%26title%3DChain-of-Thought+Prompting+Elicits+Reasoning+in+Large+Language+Models&v=f9d3bb68', 'https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer', 'https://info.arxiv.org/labs/index.html', 'https://info.arxiv.org/help/mathjax.html', 'https://info.arxiv.org/about', 'https://info.arxiv.org/help', 'https://info.arxiv.org/help/contact.html', 'https://info.arxiv.org/help/subscribe', 'https://info.arxiv.org/help/license/index.html', 'https://info.arxiv.org/help/policies/privacy_policy.html', 'https://info.arxiv.org/help/web_accessibility.html', 'https://status.arxiv.org']\nSuccessfully inserted records associated with the query 'Top academic papers on Chain of Thought' into the database.\nStatus: 200, already fetched for URL: https://openreview.net/pdf?id=_VjQlMeSB_J\narxiv_links[0]: []\nStatus: 200, already fetched for URL: https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html\narxiv_links[2]: ['https://arxiv.org/pdf/2201.11903.pdf', 'https://arxiv.org/abs/2210.03493']\nSuccessfully inserted records associated with the query 'Top academic papers on Chain of Thought' into the database.\nFailed to retrieve the page. Status code: 403\nStatus:403 for URL: https://www.linkedin.com/pulse/chain-thought-new-frontier-prompt-engineering-tiran-dagan-wkuce\nURL already exists in google_search_results. Skipping insert.\nStatus: 200, already fetched for URL: https://research.google/pubs/self-consistency-improves-chain-of-thought-reasoning-in-language-models/\narxiv_links[1]: ['https://arxiv.org/abs/2203.11171']\nSuccessfully inserted records associated with the query 'Top academic papers on Chain of Thought' into the database.\nStatus: 200, already fetched for URL: https://openreview.net/forum?id=_VjQlMeSB_J\narxiv_links[0]: []\nStatus: 200, already fetched for URL: https://arxiv.org/pdf/2201.11903\narxiv_links[0]: []\nStatus: 200, already fetched for URL: https://medium.com/@JerryCuomo/lets-think-step-by-step-advanced-reasoning-in-business-with-chain-of-thought-prompting-dd5ae8a6008\narxiv_links[4]: ['https://arxiv.org/abs/2201.11903', 'https://arxiv.org/abs/2205.11916', 'https://arxiv.org/abs/2201.11903', 'https://arxiv.org/abs/2205.11916']\nSuccessfully inserted records associated with the query 'Top academic papers on Chain of Thought' into the database.\nStatus: 200, already fetched for URL: https://www.searchenginejournal.com/google-chain-of-thought-prompting/450106/\narxiv_links[1]: ['https://arxiv.org/pdf/2201.11903.pdf']\nSuccessfully inserted records associated with the query 'Top academic papers on Chain of Thought' into the database.\nStatus: 200, already fetched for URL: https://www.youtube.com/watch?v=538uaE-AACs\narxiv_links[0]: []\nFinished extracting search results pages\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/6f9ea4de-5a0f-4503-b9eb-77f135e08611"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"586ba61c8b7b426cb5d3cbe250911e75","deepnote_cell_type":"text-cell-p"},"source":"Extracting and processing arxiv papers: pdf, markdown, metadata, citations, versions","block_group":"c09889aa5b43411483a86049e10570f4"},{"cell_type":"code","metadata":{"source_hash":"11c5662","execution_start":1710039678760,"execution_millis":396,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"43a127a8906a410d9fa9b3f2093bb753","deepnote_cell_type":"code"},"source":"import json\nimport psycopg2.extras\n\ndef get_scholar_citations_versions_loop(query):\n    conn = connection()  # Ensure this is a valid connection function\n    c = conn.cursor()\n\n    try:\n        # Fetch the first 30 Query_Papers rows associated with the given query\n        c.execute(\"\"\"\n            SELECT id, arxiv_link FROM Query_Papers \n            WHERE query = %s \n            LIMIT 30\n        \"\"\", (query,))  # Limit to the first 30 results\n        query_papers_to_update = c.fetchall()\n\n        # Prepare batch update lists\n        papers_updates = []\n        query_papers_updates = []\n\n        for paper_id, arxiv_link in query_papers_to_update:\n            try:\n                # Fetch citations and versions\n                number_of_citations, number_of_versions = get_scholar_citations_versions(arxiv_link)\n                \n                # Append data for batch update in Papers table\n                papers_updates.append((number_of_citations, number_of_versions, arxiv_link))\n                \n                # Create JSON object with citations and versions, append for batch update in Query_Papers\n                paper_stats_json = json.dumps({'citations': number_of_citations, 'versions': number_of_versions})\n                query_papers_updates.append((paper_stats_json, paper_id))\n                \n            except Exception as e:\n                print(f\"An error occurred while processing paper {arxiv_link}: {e}\")\n\n        # Perform batch updates\n        psycopg2.extras.execute_batch(c, \"UPDATE Papers SET citations = %s, versions = %s WHERE arxiv_link = %s\",\n                                      papers_updates)\n        psycopg2.extras.execute_batch(c, \"UPDATE Query_Papers SET paper_stats = %s WHERE id = %s\",\n                                      query_papers_updates)\n\n        # Commit all changes\n        conn.commit()\n\n    except Exception as e:\n        # If an exception occurs, roll back all database changes\n        conn.rollback()\n        print(f\"An error occurred while fetching Query_Papers for the query '{query}': {e}\")\n\n    finally:\n        # Ensure resources are cleaned up\n        c.close()\n        conn.close()\n\n# Assuming get_scholar_citations_versions and connection are correctly defined elsewhere\n","block_group":"cbb5a5779c464f8683c681341813c442","execution_count":132,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"66182a4e","execution_start":1709954667893,"execution_millis":241,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"aa08d8877922484d98ca1c23e525c895","deepnote_cell_type":"code"},"source":"def fetch_arxiv_paper_from_url_loop(query):\n    conn = connection()  # Ensure this is a function that returns a DB connection\n    c = conn.cursor()\n\n    # Select records from Query_Papers related to the specific query and with final_rank between 1 and 10\n    try:\n        c.execute(\"\"\"\n            SELECT Query_Papers.id, Papers.paper_title, Papers.arxiv_link\n            FROM Query_Papers\n            JOIN Papers ON Query_Papers.arxiv_link = Papers.arxiv_link\n            WHERE Query_Papers.query = %s AND final_rank BETWEEN 1 AND 10\n            ORDER BY final_rank ASC\n        \"\"\", (query,))\n\n        papers_to_update = c.fetchall()\n\n        for q_id, paper_title, arxiv_link in papers_to_update:\n            print(f\"Updating missing information for paper: {paper_title}\")\n            if arxiv_link:\n                try:\n                    # Fetch paper metadata from arXiv\n                    xml_data, pdf_url, title, file_name, abstract, published_date, authors = fetch_arxiv_paper_from_url(arxiv_link)\n\n                    # Update Papers table with fetched metadata\n                    c.execute(\"\"\"\n                        UPDATE Papers \n                        SET arxiv_title = %s, arxiv_abstract = %s, arxiv_metadata = %s, arxiv_filename = %s \n                        WHERE arxiv_link = %s\n                    \"\"\", (title, abstract, xml_data, file_name, arxiv_link))\n\n                    # Update Query_Papers table with filtered metadata and download link\n                    paper_metadata_filtered = {'title': title, 'abstract': abstract, 'published_date': published_date, 'authors': authors}\n                    c.execute(\"\"\"\n                        UPDATE Query_Papers \n                        SET paper_metadata_filtered = %s, download_link = %s \n                        WHERE id = %s\n                    \"\"\", (json.dumps(paper_metadata_filtered), pdf_url, q_id))\n\n                    # Commit the transaction\n                    conn.commit()\n\n                except Exception as e:\n                    print(f\"An error occurred while updating paper {paper_title}: {e}\")\n            else:\n                print(f\"No arXiv link found for paper: {paper_title}\")\n    except Exception as e:\n        print(f\"An error occurred while fetching Query_Papers for the query '{query}': {e}\")\n    finally:\n        if conn is not None:\n            c.close()\n            conn.close()","block_group":"d569342064174dadba839f4e063a2900","execution_count":69,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"1cef4275","execution_start":1709954724341,"execution_millis":57,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"2111b9a80cfc444f9cb9b4ca6ad28cfc","deepnote_cell_type":"code"},"source":"def download_pdf_loop(query):\n    conn = connection()  # Make sure this is a function that returns a DB connection\n    c = conn.cursor()\n\n    # Select records from Query_Papers related to the specific query and with final_rank between 1 and 10\n    try:\n        c.execute(\"\"\"\n            SELECT Query_Papers.id, Papers.paper_title, Papers.arxiv_link, Papers.arxiv_filename\n            FROM Query_Papers\n            JOIN Papers ON Query_Papers.arxiv_link = Papers.arxiv_link\n            WHERE Query_Papers.query = %s AND final_rank BETWEEN 1 AND 10\n            ORDER BY final_rank ASC\n        \"\"\", (query,))\n\n        papers_metadata = c.fetchall()\n\n        for id, paper_title, arxiv_link, file_name in papers_metadata:\n            print(f\"Downloading PDF for paper: {paper_title}\")\n            if arxiv_link and file_name:\n                # Typically, the PDF URL is derived from the arXiv link, adjust as necessary\n                pdf_url = f'https://arxiv.org/pdf/{arxiv_link.split(\"/\")[-1]}.pdf'  # Adjust based on actual URL format\n\n                # Download the PDF\n                file_path_or_error = download_pdf(pdf_url, file_name)\n                if 'Failed' not in file_path_or_error:\n                    print(f\"Download successful: {file_path_or_error}\")\n                else:\n                    print(f\"Download failed for paper: {paper_title}\")\n            else:\n                print(f\"No valid arXiv link or filename found for paper: {paper_title}\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    finally:\n        if conn is not None:\n            c.close()\n            conn.close()\n","block_group":"61966d2d6e6e4734a0352ba3647767f7","execution_count":70,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"693c1d13","execution_start":1709954736042,"execution_millis":111,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"00335e774c5c44d999561da5cf3af97d","deepnote_cell_type":"code"},"source":"def convert_pdf_to_markdown_loop():\n    # Connect to SQLite database\n    conn = connection()\n    c = conn.cursor()\n\n    # Update papers with missing arxiv_paper_markdown\n    c.execute(\"SELECT id, arxiv_filename FROM Papers WHERE (arxiv_paper_markdown IS NULL OR arxiv_paper_markdown = '' OR arxiv_paper_markdown = 'None') AND arxiv_filename IS NOT NULL AND arxiv_filename != ''\")\n    papers_to_update = c.fetchall()\n\n    for id, arxiv_filename in papers_to_update:\n        try:\n            # Convert PDF to Markdown\n            markdown_content = convert_pdf_to_markdown(arxiv_filename)\n\n            # Update Papers table with Markdown content\n            c.execute(\"UPDATE Papers SET arxiv_paper_markdown = %s WHERE id = %s\", (markdown_content, rowid))\n            conn.commit()\n        except Exception as e:\n            print(f\"An error occurred while updating paper id {id}: {e}\")\n\n    print(\"Finished converting pdfs to markdown loop\")\n    if conn is not None:\n        # Close the cursor and connection\n        c.close()\n        conn.close()\n","block_group":"390b08c028f9461aae951d96b05d5dc3","execution_count":71,"outputs":[],"outputs_reference":null},{"cell_type":"markdown","metadata":{"source_hash":null,"deepnote_to_be_reexecuted":true,"deepnote_app_block_visible":true,"cell_id":"ec0ba9d573c542f2ba4a9e45ee4ceb1e","deepnote_cell_type":"markdown"},"source":"Process papers against user query to arrive at the relevant answer and relevance score","block_group":"92258df3d96749a5b6982c9b3deb3d43"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"0ddd61f626494ad7bbf5a0eca4f777fe","deepnote_cell_type":"text-cell-p"},"source":"abstract","block_group":"265c43bea8ae4d399f461ee461120134"},{"cell_type":"code","metadata":{"source_hash":"4c8092a9","execution_start":1709958658597,"execution_millis":68,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"9ad98a148db84e4091d11f062312901b","deepnote_cell_type":"code"},"source":"import asyncio\n\nasync def LLM_process_abstract_loop(query):\n    # Connect to the database (for reading and writing)\n    conn = connection()\n    c = conn.cursor()\n\n    # Modify the SQL query to fetch rows for a given query with final_rank between 1 and 10\n    # and where the relevant_answer is missing\n    c.execute(\"\"\"\n        SELECT id, query, arxiv_link, relevance_score, final_rank, relevant_answer, paper_stats, paper_metadata_filtered, download_link\n        FROM Query_Papers\n        WHERE (relevant_answer IS NULL OR relevant_answer = 'None')\n        AND query = %s AND final_rank BETWEEN 1 AND 10\n        ORDER BY final_rank\n    \"\"\", (query,))\n    query_papers_to_update = c.fetchall()\n\n    # Count and print the total number of papers to process\n    total_papers = len(query_papers_to_update)\n    print(f\"Total papers to process for '{query}': {total_papers}\")\n\n    for i, query_paper in enumerate(query_papers_to_update):\n        id, _, arxiv_link, relevance_score, final_rank, _, paper_stats, paper_metadata_filtered, download_link = query_paper\n        print(f\"Papers to process: ({total_papers - i}). Processing query paper: {arxiv_link}\")\n\n        # Retrieve corresponding paper's abstract and metadata from Papers table\n        c.execute(\"SELECT arxiv_abstract, arxiv_metadata FROM Papers WHERE arxiv_link = %s\", (arxiv_link,))\n        paper_data = c.fetchone()\n\n        if paper_data:\n            arxiv_abstract, arxiv_metadata = paper_data\n\n            if arxiv_abstract and arxiv_metadata:\n                # Assuming query_info_with_gpt is an asynchronous function\n                relevant_answer = await query_info_with_gpt(arxiv_abstract, arxiv_metadata, query)  # Use await since this function is now async\n                print(f\"Relevant answer: {relevant_answer}\")\n\n                # Update the Query_Papers table with the relevant_answer\n                c.execute(\"UPDATE Query_Papers SET relevant_answer = %s WHERE id = %s\", (relevant_answer, id))\n                conn.commit()\n\n            else:\n                print(f\"Missing content or metadata for paper: {arxiv_link}\")\n\n        else:\n            print(f\"No corresponding paper found for query paper: {arxiv_link}\")\n\n    if conn is not None:\n        # Close the cursor and connection\n        c.close()\n        conn.close()\n\n    print(\"Finished processing query papers.\")\n","block_group":"d0471d85397b42aaaa31695aec1ed2f7","execution_count":73,"outputs":[],"outputs_reference":null},{"cell_type":"markdown","metadata":{"id":"2SvLKjS1qy6B","deepnote_app_block_visible":true,"cell_id":"092a8f1da325492e92f0f0b4844fa804","deepnote_cell_type":"markdown"},"source":"________________________________________________________________________________________________\n# RANKING\n________________________________________________________________________________________________","block_group":"79dd5951f9f0498b9bd65779c419df88"},{"cell_type":"code","metadata":{"source_hash":"fc64caf4","execution_start":1710035512587,"execution_millis":1058,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"383553be16464e71b64764923ce4e549","deepnote_cell_type":"code"},"source":"def update_final_ranks(query):\n    conn = connection()\n    c = conn.cursor()\n\n    # Fetch all unique queries from the Query_Papers table where final_rank is null\n    c.execute(\"SELECT DISTINCT query FROM Query_Papers WHERE final_rank IS NULL\")\n    queries = c.fetchall()\n\n    for query in queries:\n        # For each query, fetch the corresponding papers along with their paper_stats\n        c.execute(\"SELECT id, paper_stats FROM Query_Papers WHERE query = %s AND final_rank IS NULL\", (query[0],))\n        papers = c.fetchall()\n\n        # Initialize lists to store rankings based on citations and versions\n        citation_ranks = []\n        version_ranks = []\n\n        # First loop to collect citation and version counts\n        for paper in papers:\n            id, stats_json = paper\n            if stats_json:\n                # Check if stats_json is not null\n                stats = json.loads(stats_json)\n                citations = stats.get('citations', 0) or 0  # Ensure default is 0 if None\n                versions = stats.get('versions', 0) or 0  # Ensure default is 0 if None\n                citation_ranks.append((id, citations))\n                version_ranks.append((id, versions))\n\n        # Sort and rank based on citations and versions separately\n        citation_ranks.sort(key=lambda x: x[1], reverse=True)\n        version_ranks.sort(key=lambda x: x[1], reverse=True)\n        citation_rank_dict = {paper_id: rank + 1 for rank, (paper_id, _) in enumerate(citation_ranks)}\n        version_rank_dict = {paper_id: rank + 1 for rank, (paper_id, _) in enumerate(version_ranks)}\n\n        # Combine the rankings to calculate the final rank\n        final_ranks = []\n        for id, _ in papers:\n            # Calculate average of the ranks; use large number if paper doesn't have rank in either\n            citation_rank = citation_rank_dict.get(id, len(papers))\n            version_rank = version_rank_dict.get(id, len(papers))\n            avg_rank = (citation_rank + version_rank) / 2.0\n            final_ranks.append((id, avg_rank))\n\n        # Sort papers based on the average rank\n        final_ranks.sort(key=lambda x: x[1])\n\n        # Update the final_rank column based on this ordering\n        for rank, (id, _) in enumerate(final_ranks, start=1):\n            # start=1 for ranking starting from 1\n            c.execute(\"UPDATE Query_Papers SET final_rank = %s WHERE id = %s\", (rank, id))\n\n        # Commit the changes to the database\n        conn.commit()\n\n    # Close the database connection\n    conn.close()\n    print(\"Finished updating final ranks for query papers.\")\n\n# Example execution\nupdate_final_ranks(\"Top academic papers on RAG\")","block_group":"d85f380533824b0bbf3055141dff70b8","execution_count":130,"outputs":[{"name":"stdout","text":"Finished updating final ranks for query papers.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/1fba4329-8083-4935-a727-16e38c207f13"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"deepnote_app_block_visible":true,"cell_id":"a93bb607519d4a89848796a841b0a3f4","deepnote_cell_type":"text-cell-h1"},"source":"# Final loop","block_group":"8863b10f881f49e7960dd0ac560f84c3"},{"cell_type":"code","metadata":{"source_hash":"b594c57a","execution_start":1710042077492,"execution_millis":2182983,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"17e553a5bed3468baaa47dcb85841fe5","deepnote_cell_type":"code"},"source":"import asyncio\n\n# Connect to the SQLite database\nconn = connection()\nc = conn.cursor()\n\ntry:\n    while True:  # Infinite loop to keep checking for new jobs\n        # Query to find new jobs with status 'new'\n        c.execute(\"SELECT job_id, query FROM jobs WHERE job_status = 'new'\")\n        new_jobs = c.fetchall()\n        \n        # Check if there are any new jobs\n        if new_jobs:\n            print(\"Found new jobs:\", new_jobs)\n            # Process the new jobs\n            for job in new_jobs:\n                job_id, job_query = job  # Get the job_id and query from the tuple\n                # Update the job_status to 'running' for the new job\n                c.execute(\"UPDATE jobs SET job_status = 'running' WHERE job_id = %s\", (job_id,))\n                conn.commit()\n                print(f\"Updated job: {job_id}, query: {job_query} to 'running'\")                \n\n                # Now, process the query using your functions\n                print(f\"search_and_fetch_google: {job_query}\")\n                search_and_fetch_google(job_query)\n                print(f\"get_scholar_citations_versions_loop: {job_query}\")\n                get_scholar_citations_versions_loop(job_query)\n                print(f\"update_final_ranks: {job_query}\")\n                update_final_ranks(job_query)\n                print(f\"fetch_arxiv_paper_from_url_loop: {job_query}\")\n                fetch_arxiv_paper_from_url_loop(job_query)\n                # Process abstract loop for LLM\n                print(f\"LLM_process_abstract_loop: {job_query}\")\n\n                #download_pdf_loop(query)\n\n                try:\n                    asyncio.run(LLM_process_abstract_loop(job_query))\n                except RuntimeError:  # asyncio.run() cannot be called from a running event loop\n                    loop = asyncio.get_event_loop()\n                    if loop.is_running():\n                        loop.create_task(LLM_process_abstract_loop(job_query))\n                    else:\n                        loop.run_until_complete(LLM_process_abstract_loop(job_query))\n                \n                # Update the job_status to 'done' after processing is complete\n                c.execute(\"UPDATE jobs SET job_status = 'done' WHERE job_id = %s\", (job_id,))\n                conn.commit()\n                print(f\"Updated job {job_id} to 'done'\")\n        \n        # Wait for half a second before checking again\n        time.sleep(0.5)\nexcept KeyboardInterrupt:\n    print(\"Stopped by user\")\nfinally:\n    # Close the database connection when done\n    conn.close()\n","block_group":"7e60dd81daa94869b0f1394485105627","execution_count":133,"outputs":[{"name":"stdout","text":"Found new jobs: [(6, 'Top academic papers on RAG')]\nUpdated job: 6, query: Top academic papers on RAG to 'running'\nsearch_and_fetch_google: Top academic papers on RAG\nTop academic papers on RAG ['https://isamu-website.medium.com/literature-review-on-rag-retrieval-augmented-generation-for-custom-domains-325bcef98be4', 'https://paperswithcode.com/method/rag', 'https://typeset.io/questions/what-are-the-latest-papers-on-rag-42ftizufgr', 'https://arxiv.org/abs/2312.10997', 'https://www.pinecone.io/blog/rag-study/', 'https://www.promptingguide.ai/research/rag', 'https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00530/114590/Improving-the-Domain-Adaptation-of-Retrieval', 'https://nexla.com/ai-infrastructure/retrieval-augmented-generation/', 'https://medium.com/@thedatabeast/revolutionizing-ai-with-rag-implementing-retrieval-augmented-generation-for-breakthrough-f1509b5c9db0', 'https://arxiv.org/html/2401.05856v1']\nStatus:200 for URL: https://isamu-website.medium.com/literature-review-on-rag-retrieval-augmented-generation-for-custom-domains-325bcef98be4\narxiv_links[3]: ['https://arxiv.org/abs/2005.11401', 'https://arxiv.org/abs/2210.02627', 'https://arxiv.org/abs/2310.01352']\nStatus:200 for URL: https://paperswithcode.com/method/rag\narxiv_links[2]: ['https://arxiv.org/abs/2005.11401v4', 'https://arxiv.org/abs/2005.11401v4']\nStatus:200 for URL: https://typeset.io/questions/what-are-the-latest-papers-on-rag-42ftizufgr\narxiv_links[0]: []\nStatus:200 for URL: https://arxiv.org/abs/2312.10997\narxiv_links[39]: ['https://info.arxiv.org/about/ourmembers.html', 'https://info.arxiv.org/about/donate.html', 'https://info.arxiv.org/help', 'https://arxiv.org/search/advanced', 'https://arxiv.org/', 'https://arxiv.org/login', 'https://info.arxiv.org/help', 'https://info.arxiv.org/about', 'https://arxiv.org/abs/2312.10997v1', 'https://arxiv.org/search/cs?searchtype=author&query=Gao,+Y', 'https://arxiv.org/search/cs?searchtype=author&query=Xiong,+Y', 'https://arxiv.org/search/cs?searchtype=author&query=Gao,+X', 'https://arxiv.org/search/cs?searchtype=author&query=Jia,+K', 'https://arxiv.org/search/cs?searchtype=author&query=Pan,+J', 'https://arxiv.org/search/cs?searchtype=author&query=Bi,+Y', 'https://arxiv.org/search/cs?searchtype=author&query=Dai,+Y', 'https://arxiv.org/search/cs?searchtype=author&query=Sun,+J', 'https://arxiv.org/search/cs?searchtype=author&query=Guo,+Q', 'https://arxiv.org/search/cs?searchtype=author&query=Wang,+M', 'https://arxiv.org/search/cs?searchtype=author&query=Wang,+H', 'https://arxiv.org/html/2312.10997v4', 'https://arxiv.org/abs/2312.10997', 'https://arxiv.org/abs/2312.10997v4', 'https://arxiv.org/html/2312.10997v4', 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'https://info.arxiv.org/help/trackback.html', 'https://arxiv.org/ct?url=http://www.bibsonomy.org/BibtexHandler?requTask%3Dupload%26url%3Dhttps://arxiv.org/abs/2312.10997%26description%3DRetrieval-Augmented+Generation+for+Large+Language+Models:+A+Survey&v=72f6e31b', 'https://arxiv.org/ct?url=https://reddit.com/submit?url%3Dhttps://arxiv.org/abs/2312.10997%26title%3DRetrieval-Augmented+Generation+for+Large+Language+Models:+A+Survey&v=fca53d9d', 'https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer', 'https://info.arxiv.org/labs/index.html', 'https://info.arxiv.org/help/mathjax.html', 'https://info.arxiv.org/about', 'https://info.arxiv.org/help', 'https://info.arxiv.org/help/contact.html', 'https://info.arxiv.org/help/subscribe', 'https://info.arxiv.org/help/license/index.html', 'https://info.arxiv.org/help/policies/privacy_policy.html', 'https://info.arxiv.org/help/web_accessibility.html', 'https://status.arxiv.org']\nStatus:200 for URL: https://www.pinecone.io/blog/rag-study/\narxiv_links[13]: ['https://arxiv.org/abs/2309.15217', 'https://arxiv.org/pdf/2211.08411.pdf', 'https://arxiv.org/pdf/2312.05934.pdf', 'https://arxiv.org/pdf/2212.10511.pdf', 'https://arxiv.org/abs/2309.15217', 'https://arxiv.org/pdf/2306.01116.pdf', 'https://arxiv.org/abs/2307.03109', 'https://arxiv.org/pdf/2204.04991.pdf', 'https://arxiv.org/abs/2309.15217', 'https://arxiv.org/pdf/2211.08411.pdf', 'https://arxiv.org/pdf/2312.05934.pdf', 'https://arxiv.org/pdf/2212.10511.pdf', 'https://arxiv.org/abs/2310.01558']\nStatus:200 for URL: https://www.promptingguide.ai/research/rag\narxiv_links[84]: ['https://arxiv.org/abs/2312.10997', 'https://arxiv.org/abs/2310.06117', 'https://arxiv.org/abs/2212.10496', 'https://arxiv.org/abs/2303.07678', 'https://arxiv.org/abs/2305.15294', 'https://arxiv.org/abs/2305.17331', 'https://arxiv.org/abs/2301.12652', 'https://arxiv.org/abs/2303.08518', 'https://arxiv.org/abs/2310.04408', 'https://arxiv.org/abs/2305.04757', 'https://arxiv.org/abs/2112.04426', 'https://arxiv.org/abs/2112.04426', 'https://arxiv.org/abs/2310.20158', 'https://arxiv.org/abs/2212.10509', 'https://arxiv.org/abs/2310.14696', 'https://arxiv.org/abs/2305.06983', 'https://arxiv.org/abs/2310.11511', 'https://arxiv.org/abs/2308.10633v2', 'https://arxiv.org/abs/2309.01431', 'https://arxiv.org/abs/2311.08147', 'https://arxiv.org/abs/2309.15217', 'https://arxiv.org/abs/2311.09476', 'https://arxiv.org/abs/2312.10997', 'https://arxiv.org/abs/2312.10997', 'https://arxiv.org/abs/2401.15884', 'https://arxiv.org/abs/2401.18059', 'https://arxiv.org/abs/2401.12178', 'https://arxiv.org/abs/2311.06595', 'https://arxiv.org/abs/2311.09210', 'https://arxiv.org/abs/2310.13682', 'https://arxiv.org/abs/2310.12836', 'https://arxiv.org/abs/2309.01431', 'https://arxiv.org/abs/2310.11511', 'https://arxiv.org/abs/2310.20158', 'https://arxiv.org/abs/2310.07713', 'https://arxiv.org/abs/2310.01352', 'https://arxiv.org/abs/2310.01558', 'https://arxiv.org/abs/2310.03025', 'https://arxiv.org/abs/2310.04408', 'https://arxiv.org/abs/2310.05149', 'https://arxiv.org/abs/2310.14696', 'https://arxiv.org/abs/2310.05002', 'https://arxiv.org/abs/2309.15217', 'https://arxiv.org/abs/2209.10063', 'https://arxiv.org/abs/2308.11761', 'https://arxiv.org/abs/2308.07922', 'https://arxiv.org/abs/2308.10633', 'https://arxiv.org/abs/2307.03172', 'https://arxiv.org/abs/2305.15294', 'https://arxiv.org/abs/2305.06983', 'https://arxiv.org/abs/2305.17331', 'https://arxiv.org/abs/2305.19912', 'https://arxiv.org/abs/2305.13269', 'https://arxiv.org/abs/2305.18846', 'https://arxiv.org/abs/2305.14283', 'https://arxiv.org/abs/2305.02437', 'https://arxiv.org/abs/2305.04757', 'https://arxiv.org/abs/2305.14322', 'https://arxiv.org/abs/2305.17653', 'https://arxiv.org/abs/2303.08518', 'https://arxiv.org/abs/2303.08559', 'https://arxiv.org/abs/2212.10496', 'https://arxiv.org/abs/2212.14024', 'https://arxiv.org/abs/2212.10509', 'https://arxiv.org/abs/2211.08411', 'https://arxiv.org/abs/2210.01296', 'https://arxiv.org/abs/2209.11755', 'https://arxiv.org/abs/2208.03299', 'https://arxiv.org/abs/2203.08773', 'https://arxiv.org/abs/2201.12431', 'https://arxiv.org/abs/2112.04426', 'https://arxiv.org/abs/2108.13934', 'https://arxiv.org/abs/2005.11401', 'https://arxiv.org/abs/2004.04906', 'https://arxiv.org/abs/2311.05232', 'https://arxiv.org/abs/2005.11401', 'https://arxiv.org/abs/2211.12561', 'https://arxiv.org/abs/2302.00083', 'https://arxiv.org/abs/2212.10496', 'https://arxiv.org/pdf/2312.10997.pdf', 'https://arxiv.org/abs/2301.12652', 'https://arxiv.org/abs/2303.07678', 'https://arxiv.org/abs/2305.15294', 'https://arxiv.org/abs/2212.10496']\nStatus:200 for URL: https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00530/114590/Improving-the-Domain-Adaptation-of-Retrieval\narxiv_links[0]: []\nStatus:200 for URL: https://nexla.com/ai-infrastructure/retrieval-augmented-generation/\narxiv_links[0]: []\nStatus:200 for URL: https://medium.com/@thedatabeast/revolutionizing-ai-with-rag-implementing-retrieval-augmented-generation-for-breakthrough-f1509b5c9db0\narxiv_links[0]: []\nStatus:200 for URL: https://arxiv.org/html/2401.05856v1\narxiv_links[0]: []\nFinished extracting search results pages\nget_scholar_citations_versions_loop: Top academic papers on RAG\nupdate_final_ranks: Top academic papers on RAG\nFinished updating final ranks for query papers.\nfetch_arxiv_paper_from_url_loop: Top academic papers on RAG\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2004.04906\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2004.04906&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2004.04906v3\nTitle: Dense Passage Retrieval for Open-Domain Question Answering\nFile Name: Dense_Passage_Retrieval_for_Open-Domain_Question_Answering.pdf\nAbstract: Open-domain question answering relies on efficient passage retrieval to\nselect candidate contexts, w...\nPublished Date: 2020-04-10T04:53:17Z\nAuthors: Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-tau Yih\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2005.11401\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2005.11401&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2005.11401v4\nTitle: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\nFile Name: Retrieval-Augmented_Generation_for_Knowledge-Intensive_NLP_Tasks.pdf\nAbstract: Large pre-trained language models have been shown to store factual knowledge\nin their parameters, an...\nPublished Date: 2020-05-22T21:34:34Z\nAuthors: Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2302.00083\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2302.00083&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2302.00083v3\nTitle: In-Context Retrieval-Augmented Language Models\nFile Name: In-Context_Retrieval-Augmented_Language_Models.pdf\nAbstract: Retrieval-Augmented Language Modeling (RALM) methods, which condition a\nlanguage model (LM) on relev...\nPublished Date: 2023-01-31T20:26:16Z\nAuthors: Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2211.08411\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2211.08411&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2211.08411v2\nTitle: Large Language Models Struggle to Learn Long-Tail Knowledge\nFile Name: Large_Language_Models_Struggle_to_Learn_Long-Tail_Knowledge.pdf\nAbstract: The Internet contains a wealth of knowledge -- from the birthdays of\nhistorical figures to tutorials...\nPublished Date: 2022-11-15T18:49:27Z\nAuthors: Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, Colin Raffel\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2112.04426\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2112.04426&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2112.04426v3\nTitle: Improving language models by retrieving from trillions of tokens\nFile Name: Improving_language_models_by_retrieving_from_trillions_of_tokens.pdf\nAbstract: We enhance auto-regressive language models by conditioning on document chunks\nretrieved from a large...\nPublished Date: 2021-12-08T17:32:34Z\nAuthors: Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, Laurent Sifre\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2212.10496\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2212.10496&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2212.10496v1\nTitle: Precise Zero-Shot Dense Retrieval without Relevance Labels\nFile Name: Precise_Zero-Shot_Dense_Retrieval_without_Relevance_Labels.pdf\nAbstract: While dense retrieval has been shown effective and efficient across tasks and\nlanguages, it remains ...\nPublished Date: 2022-12-20T18:09:52Z\nAuthors: Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2305.06983\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2305.06983&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2305.06983v2\nTitle: Active Retrieval Augmented Generation\nFile Name: Active_Retrieval_Augmented_Generation.pdf\nAbstract: Despite the remarkable ability of large language models (LMs) to comprehend\nand generate language, t...\nPublished Date: 2023-05-11T17:13:40Z\nAuthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2209.11755\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2209.11755&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2209.11755v1\nTitle: Promptagator: Few-shot Dense Retrieval From 8 Examples\nFile Name: Promptagator_Few-shot_Dense_Retrieval_From_8_Examples.pdf\nAbstract: Much recent research on information retrieval has focused on how to transfer\nfrom one task (typicall...\nPublished Date: 2022-09-23T17:59:06Z\nAuthors: Zhuyun Dai, Vincent Y. Zhao, Ji Ma, Yi Luan, Jianmo Ni, Jing Lu, Anton Bakalov, Kelvin Guu, Keith B. Hall, Ming-Wei Chang\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2203.08773\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2203.08773&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2203.08773v1\nTitle: Training Data is More Valuable than You Think: A Simple and Effective\n  Method by Retrieving from Training Data\nFile Name: Training_Data_is_More_Valuable_than_You_Think_A_Simple_and_Effective\n__Method_by_Retrieving_from_Training_Data.pdf\nAbstract: Retrieval-based methods have been shown to be effective in NLP tasks via\nintroducing external knowle...\nPublished Date: 2022-03-16T17:37:27Z\nAuthors: Shuohang Wang, Yichong Xu, Yuwei Fang, Yang Liu, Siqi Sun, Ruochen Xu, Chenguang Zhu, Michael Zeng\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2209.10063\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2209.10063&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2209.10063v3\nTitle: Generate rather than Retrieve: Large Language Models are Strong Context\n  Generators\nFile Name: Generate_rather_than_Retrieve_Large_Language_Models_are_Strong_Context\n__Generators.pdf\nAbstract: Knowledge-intensive tasks, such as open-domain question answering (QA),\nrequire access to a large am...\nPublished Date: 2022-09-21T01:30:59Z\nAuthors: Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, Michael Zeng, Meng Jiang\nLLM_process_abstract_loop: Top academic papers on RAG\nTotal papers to process for 'Top academic papers on RAG': 10\nPapers to process: (10). Processing query paper: https://arxiv.org/abs/2004.04906\nRelevant answer: \"Dense Passage Retrieval\" paper shows dense representations can improve open-domain QA systems' passage retrieval accuracy by 9%-19%.\nPapers to process: (9). Processing query paper: https://arxiv.org/abs/2005.11401\nRelevant answer: \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\" explores RAG models, setting new standards on QA tasks.\nPapers to process: (8). Processing query paper: https://arxiv.org/abs/2302.00083\nRelevant answer: \"In-Context Retrieval-Augmented Language Models\" explores simple, effective LM grounding without altering architectures.\nPapers to process: (7). Processing query paper: https://arxiv.org/abs/2211.08411\nRelevant answer: Paper explores correlation of large language models' knowledge with pre-training data; reveals need for scaling models.\nPapers to process: (6). Processing query paper: https://arxiv.org/abs/2112.04426\nRelevant answer: \"Improving language models by retrieving from trillions of tokens\" enhances auto-regressive language models with a 2 trillion token database.\nPapers to process: (5). Processing query paper: https://arxiv.org/abs/2212.10496\nRelevant answer: The paper introduces Hypothetical Document Embeddings (HyDE) for effective zero-shot dense retrieval.\nPapers to process: (4). Processing query paper: https://arxiv.org/abs/2305.06983\nRelevant answer: Paper \"Active Retrieval Augmented Generation\" proposes FLARE, a method to optimize language models for long-form generation by actively retrieving information.\nPapers to process: (3). Processing query paper: https://arxiv.org/abs/2209.11755\nRelevant answer: \"Promptagator\" system for Few-shot Dense Retrieval effectively uses large language models, outperforming models trained on MS MARCO.\nPapers to process: (2). Processing query paper: https://arxiv.org/abs/2203.08773\nRelevant answer: \"REtrieving from the traINing datA (REINA)\" method enhances performance on various NLG and NLU tasks.\nPapers to process: (1). Processing query paper: https://arxiv.org/abs/2209.10063\nRelevant answer: \"Generate rather than Retrieve\" paper presents GenRead, replacing retrievers with large language models for knowledge-intensive tasks.\nFinished processing query papers.\nUpdated job 6 to 'done'\nFound new jobs: [(7, 'Top academic papers on LLMs')]\nUpdated job: 7, query: Top academic papers on LLMs to 'running'\nsearch_and_fetch_google: Top academic papers on LLMs\nTop academic papers on LLMs ['https://www.topbots.com/top-llm-research-papers-2023/', 'https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f', 'https://levelup.gitconnected.com/best-papers-on-large-language-models-ac01b13b94b3', 'https://community.openai.com/t/foundational-must-read-gpt-llm-papers/197003', 'https://www.reddit.com/r/MLQuestions/comments/ze9e5x/can_anyone_recommend_an_llm_that_handles_research/', 'https://analyticsindiamag.com/13-not-to-miss-research-papers-on-llms/', 'https://github.com/Hannibal046/Awesome-LLM', 'https://yousefhosni.medium.com/top-important-llm-papers-for-the-week-from-01-01-to-07-01-4e3be08ac69b', 'https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023']\nStatus:200 for URL: https://www.topbots.com/top-llm-research-papers-2023/\narxiv_links[10]: ['https://arxiv.org/abs/2302.13971', 'https://arxiv.org/abs/2307.09288', 'https://arxiv.org/abs/2303.08774', 'https://arxiv.org/abs/2303.12712', 'https://arxiv.org/abs/2301.12597', 'https://arxiv.org/abs/2305.06500', 'https://arxiv.org/abs/2303.03378', 'https://arxiv.org/abs/2305.10403', 'https://arxiv.org/abs/2302.04761', 'https://arxiv.org/abs/2305.10601']\nStatus:200 for URL: https://medium.com/@thedatabeast/top-10-breakthrough-research-papers-on-large-language-models-llms-in-2023-pioneering-7abfcb69da7f\narxiv_links[4]: ['https://arxiv.org/abs/1810.04805', 'https://arxiv.org/abs/2208.03188', 'https://arxiv.org/abs/2209.14375', 'https://arxiv.org/abs/2001.08361']\nStatus:200 for URL: https://levelup.gitconnected.com/best-papers-on-large-language-models-ac01b13b94b3\narxiv_links[11]: ['https://arxiv.org/abs/1706.03762', 'https://arxiv.org/abs/1810.04805', 'https://arxiv.org/abs/1910.13461', 'https://arxiv.org/abs/2201.08239', 'https://arxiv.org/abs/2212.14034', 'https://arxiv.org/abs/2205.14135', 'https://arxiv.org/abs/2212.08073', 'https://arxiv.org/abs/2203.02155', 'https://arxiv.org/abs/2208.03188', 'https://arxiv.org/abs/2209.14375', 'https://arxiv.org/abs/2211.05100']\nStatus: 200, already fetched for URL: https://community.openai.com/t/foundational-must-read-gpt-llm-papers/197003\narxiv_links[29]: ['https://arxiv.org/pdf/2303.12712.pdf', 'https://arxiv.org/abs/2304.05332', 'https://arxiv.org/abs/2304.05332', 'https://arxiv.org/abs/2305.02301', 'https://arxiv.org/abs/2305.02301', 'https://arxiv.org/abs/2303.08774', 'https://arxiv.org/abs/2303.08774', 'https://arxiv.org/abs/2304.03442', 'https://arxiv.org/abs/2304.03442', 'https://arxiv.org/abs/2305.03047', 'https://arxiv.org/abs/2305.03047', 'https://arxiv.org/abs/2212.08073', 'https://arxiv.org/abs/2212.08073', 'https://arxiv.org/abs/2305.04091', 'https://arxiv.org/abs/2305.04091', 'https://arxiv.org/abs/2210.00720', 'https://arxiv.org/abs/2210.00720', 'https://arxiv.org/abs/2305.05176', 'https://arxiv.org/abs/2305.05176', 'https://arxiv.org/abs/2210.03629', 'https://arxiv.org/abs/2210.03629', 'https://arxiv.org/pdf/2305.10601.pdf', 'https://arxiv.org/pdf/2305.10601.pdf', 'https://arxiv.org/pdf/2305.10601.pdf', 'https://arxiv.org/abs/2205.11822', 'https://arxiv.org/abs/2205.11822', 'https://arxiv.org/abs/2305.15324', 'https://arxiv.org/abs/2305.15324', 'https://arxiv.org/abs/2305.18654']\nFailed to retrieve the page. Status code: 403\nStatus:403 for URL: https://www.reddit.com/r/MLQuestions/comments/ze9e5x/can_anyone_recommend_an_llm_that_handles_research/\nStatus:200 for URL: https://analyticsindiamag.com/13-not-to-miss-research-papers-on-llms/\narxiv_links[11]: ['https://arxiv.org/pdf/1706.03762.pdf', 'https://arxiv.org/pdf/2203.02155.pdf', 'https://arxiv.org/pdf/2211.05100.pdf', 'https://arxiv.org/pdf/1810.04805.pdf', 'https://arxiv.org/pdf/2208.03188.pdf', 'https://arxiv.org/pdf/2209.14375.pdf', 'https://arxiv.org/pdf/2001.08361.pdf', 'https://arxiv.org/pdf/1910.13461.pdf', 'https://arxiv.org/pdf/2004.03705.pdf', 'https://arxiv.org/pdf/2212.14034.pdf', 'https://arxiv.org/pdf/2205.14135.pdf']\nStatus:200 for URL: https://github.com/Hannibal046/Awesome-LLM\narxiv_links[44]: ['https://arxiv.org/pdf/1706.03762.pdf', 'https://arxiv.org/pdf/1909.08053.pdf', 'https://arxiv.org/pdf/1910.02054.pdf', 'https://arxiv.org/pdf/2001.08361.pdf', 'https://arxiv.org/pdf/2101.03961.pdf', 'https://arxiv.org/pdf/2107.03374.pdf', 'https://arxiv.org/pdf/2108.07258.pdf', 'https://arxiv.org/abs/2110.08207', 'https://arxiv.org/pdf/2112.06905.pdf', 'https://arxiv.org/pdf/2112.11446.pdf', 'https://arxiv.org/pdf/2201.11903.pdf', 'https://arxiv.org/pdf/2201.08239.pdf', 'https://arxiv.org/abs/2206.14858', 'https://arxiv.org/pdf/2201.11990.pdf', 'https://arxiv.org/pdf/2203.02155.pdf', 'https://arxiv.org/pdf/2204.02311.pdf', 'https://arxiv.org/pdf/2205.01068.pdf', 'https://arxiv.org/abs/2205.05131v1', 'https://arxiv.org/pdf/2206.06336.pdf', 'https://arxiv.org/pdf/2209.14375.pdf', 'https://arxiv.org/pdf/2210.11416.pdf', 'https://arxiv.org/pdf/2210.02414.pdf', 'https://arxiv.org/pdf/2211.09110.pdf', 'https://arxiv.org/pdf/2211.05100.pdf', 'https://arxiv.org/pdf/2211.09085.pdf', 'https://arxiv.org/pdf/2212.12017', 'https://arxiv.org/pdf/2301.13688.pdf', 'https://arxiv.org/abs/2302.14045', 'https://arxiv.org/abs/2304.01373', 'https://arxiv.org/abs/2305.03047', 'https://arxiv.org/abs/2305.13048', 'https://arxiv.org/pdf/2305.18290.pdf', 'https://arxiv.org/pdf/2307.09288.pdf', 'https://arxiv.org/pdf/2310.06825.pdf%5D%5D%3E', 'https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf', 'https://arxiv.org/abs/2302.13971', 'https://arxiv.org/abs/2210.17323', 'https://arxiv.org/abs/1910.10683', 'https://arxiv.org/abs/2110.08207', 'https://arxiv.org/abs/2205.01068', 'https://arxiv.org/abs/2205.05131v1', 'https://arxiv.org/abs/2005.14165', 'https://arxiv.org/abs/2306.11644', 'https://arxiv.org/abs/2309.05463']\nStatus:200 for URL: https://yousefhosni.medium.com/top-important-llm-papers-for-the-week-from-01-01-to-07-01-4e3be08ac69b\narxiv_links[0]: []\nStatus:200 for URL: https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023\narxiv_links[46]: ['https://arxiv.org/abs/2304.01373', 'https://arxiv.org/abs/2304.01373', 'https://arxiv.org/abs/2307.09288', 'https://arxiv.org/abs/2307.09288', 'https://arxiv.org/abs/2307.09288', 'https://arxiv.org/abs/2307.09288', 'https://arxiv.org/abs/2305.14314', 'https://arxiv.org/abs/2303.15647', 'https://arxiv.org/abs/2305.14314', 'https://arxiv.org/abs/2303.17564', 'https://arxiv.org/abs/2309.09530', 'https://arxiv.org/abs/2305.18290', 'https://arxiv.org/abs/2305.18290', 'https://arxiv.org/abs/2305.18290', 'https://arxiv.org/abs/2310.16944', 'https://arxiv.org/abs/2306.05685', 'https://arxiv.org/abs/2310.16944', 'https://arxiv.org/abs/2310.06825', 'https://arxiv.org/abs/2310.06825', 'https://arxiv.org/abs/1904.10509', 'https://arxiv.org/abs/2004.05150', 'https://arxiv.org/abs/2310.06825', 'https://arxiv.org/abs/2101.03961', 'https://arxiv.org/abs/1701.06538', 'https://arxiv.org/abs/2006.16668', 'https://arxiv.org/abs/2211.15841', 'https://arxiv.org/abs/2305.14705', 'https://arxiv.org/abs/2309.05463', 'https://arxiv.org/abs/2306.11644', 'https://arxiv.org/abs/2309.05463', 'https://arxiv.org/abs/2311.11045', 'https://arxiv.org/abs/2212.10560', 'https://arxiv.org/abs/2305.11206', 'https://arxiv.org/abs/2305.11206', 'https://arxiv.org/abs/2311.11045', 'https://arxiv.org/abs/2305.15717', 'https://arxiv.org/abs/2310.16764', 'https://arxiv.org/abs/2310.16764', 'https://arxiv.org/abs/1506.02640', 'https://arxiv.org/abs/1703.06870v3', 'https://arxiv.org/abs/2304.02643', 'https://arxiv.org/abs/2304.02643', 'https://arxiv.org/abs/2304.02643', 'https://arxiv.org/abs/2311.10709', 'https://arxiv.org/abs/2311.10709', 'https://arxiv.org/abs/2311.16452']\nFinished extracting search results pages\nget_scholar_citations_versions_loop: Top academic papers on LLMs\nupdate_final_ranks: Top academic papers on LLMs\nFinished updating final ranks for query papers.\nfetch_arxiv_paper_from_url_loop: Top academic papers on LLMs\nUpdating missing information for paper: None\nFetching information for arXiv ID: 1706.03762\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=1706.03762&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/1706.03762v7\nTitle: Attention Is All You Need\nFile Name: Attention_Is_All_You_Need.pdf\nAbstract: The dominant sequence transduction models are based on complex recurrent or\nconvolutional neural net...\nPublished Date: 2017-06-12T17:57:34Z\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nUpdating missing information for paper: None\nFetching information for arXiv ID: 1810.04805\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=1810.04805&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/1810.04805v2\nTitle: BERT: Pre-training of Deep Bidirectional Transformers for Language\n  Understanding\nFile Name: BERT_Pre-training_of_Deep_Bidirectional_Transformers_for_Language\n__Understanding.pdf\nAbstract: We introduce a new language representation model called BERT, which stands\nfor Bidirectional Encoder...\nPublished Date: 2018-10-11T00:50:01Z\nAuthors: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova\nUpdating missing information for paper: None\nFetching information for arXiv ID: 1506.02640\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=1506.02640&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/1506.02640v5\nTitle: You Only Look Once: Unified, Real-Time Object Detection\nFile Name: You_Only_Look_Once_Unified,_Real-Time_Object_Detection.pdf\nAbstract: We present YOLO, a new approach to object detection. Prior work on object\ndetection repurposes class...\nPublished Date: 2015-06-08T19:52:52Z\nAuthors: Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2005.14165\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2005.14165&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2005.14165v4\nTitle: Language Models are Few-Shot Learners\nFile Name: Language_Models_are_Few-Shot_Learners.pdf\nAbstract: Recent work has demonstrated substantial gains on many NLP tasks and\nbenchmarks by pre-training on a...\nPublished Date: 2020-05-28T17:29:03Z\nAuthors: Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei\nUpdating missing information for paper: None\nFetching information for arXiv ID: 1910.10683\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=1910.10683&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/1910.10683v4\nTitle: Exploring the Limits of Transfer Learning with a Unified Text-to-Text\n  Transformer\nFile Name: Exploring_the_Limits_of_Transfer_Learning_with_a_Unified_Text-to-Text\n__Transformer.pdf\nAbstract: Transfer learning, where a model is first pre-trained on a data-rich task\nbefore being fine-tuned on...\nPublished Date: 2019-10-23T17:37:36Z\nAuthors: Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2203.02155\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2203.02155&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2203.02155v1\nTitle: Training language models to follow instructions with human feedback\nFile Name: Training_language_models_to_follow_instructions_with_human_feedback.pdf\nAbstract: Making language models bigger does not inherently make them better at\nfollowing a user's intent. For...\nPublished Date: 2022-03-04T07:04:42Z\nAuthors: Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe\nUpdating missing information for paper: None\nFetching information for arXiv ID: 1701.06538\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=1701.06538&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/1701.06538v1\nTitle: Outrageously Large Neural Networks: The Sparsely-Gated\n  Mixture-of-Experts Layer\nFile Name: Outrageously_Large_Neural_Networks_The_Sparsely-Gated\n__Mixture-of-Experts_Layer.pdf\nAbstract: The capacity of a neural network to absorb information is limited by its\nnumber of parameters. Condi...\nPublished Date: 2017-01-23T18:10:00Z\nAuthors: Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean\nUpdating missing information for paper: None\nFetching information for arXiv ID: 1910.13461\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=1910.13461&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/1910.13461v1\nTitle: BART: Denoising Sequence-to-Sequence Pre-training for Natural Language\n  Generation, Translation, and Comprehension\nFile Name: BART_Denoising_Sequence-to-Sequence_Pre-training_for_Natural_Language\n__Generation,_Translation,_and_Comprehension.pdf\nAbstract: We present BART, a denoising autoencoder for pretraining sequence-to-sequence\nmodels. BART is traine...\nPublished Date: 2019-10-29T18:01:00Z\nAuthors: Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2110.08207\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2110.08207&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2110.08207v3\nTitle: Multitask Prompted Training Enables Zero-Shot Task Generalization\nFile Name: Multitask_Prompted_Training_Enables_Zero-Shot_Task_Generalization.pdf\nAbstract: Large language models have recently been shown to attain reasonable zero-shot\ngeneralization on a di...\nPublished Date: 2021-10-15T17:08:57Z\nAuthors: Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, Alexander M. Rush\nUpdating missing information for paper: None\nFetching information for arXiv ID: 2001.08361\nFinal API Request URL: http://export.arxiv.org/api/query?id_list=2001.08361&max_results=1\nRaw XML response received\nPDF URL: http://arxiv.org/pdf/2001.08361v1\nTitle: Scaling Laws for Neural Language Models\nFile Name: Scaling_Laws_for_Neural_Language_Models.pdf\nAbstract: We study empirical scaling laws for language model performance on the\ncross-entropy loss. The loss s...\nPublished Date: 2020-01-23T03:59:20Z\nAuthors: Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei\nLLM_process_abstract_loop: Top academic papers on LLMs\nTotal papers to process for 'Top academic papers on LLMs': 10\nPapers to process: (10). Processing query paper: https://arxiv.org/abs/1706.03762\nRelevant answer: \"Attention is All You Need” paper introduces a novel architecture, the Transformer, to improve machine translation.\nPapers to process: (9). Processing query paper: https://arxiv.org/abs/1810.04805\nRelevant answer: \"BERT\" paper presents a new model for deep bidirectional language understanding, improving various NLP tasks.\nPapers to process: (8). Processing query paper: https://arxiv.org/abs/1506.02640\nRelevant answer: The academic paper \"YOLO: Unified, Real-Time Object Detection\" presents a fast, efficient method for object detection.\nPapers to process: (7). Processing query paper: https://arxiv.org/abs/2005.14165\nRelevant answer: The paper discusses the impressive performance of GPT-3, a language model, on various NLP tasks and its few-shot learning struggles.\nPapers to process: (6). Processing query paper: https://arxiv.org/abs/1910.10683\nRelevant answer: \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\" paper studies NLP transfer learning.\nPapers to process: (5). Processing query paper: https://arxiv.org/abs/2203.02155\nRelevant answer: Study shows InstructGPT models, fine-tuned using human feedback, improve in truthfulness and reduce toxicity.\nPapers to process: (4). Processing query paper: https://arxiv.org/abs/1701.06538\nRelevant answer: Paper: Sparsely-Gated Mixture-of-Experts (MoE) layer increases neural network model capacity, improving results.\nPapers to process: (3). Processing query paper: https://arxiv.org/abs/1910.13461\nRelevant answer: \"BART\" paper discusses a denoising autoencoder for pretraining sequence-to-sequence models, improving language tasks.\nPapers to process: (2). Processing query paper: https://arxiv.org/abs/2110.08207\nRelevant answer: \"Multitask Prompted Training Enables Zero-Shot Task Generalization\" paper details enhancing large language models via explicit multitask learning.\nPapers to process: (1). Processing query paper: https://arxiv.org/abs/2001.08361\nRelevant answer: \"Scaling Laws for Neural Language Models\" discusses model performance, efficiency of large models, and optimal allocation of compute budget.\nFinished processing query papers.\nUpdated job 7 to 'done'\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/3f13bde4-85d4-4cbf-b330-5cc638b2aa96"},{"cell_type":"code","metadata":{"source_hash":"8e84d3eb","execution_start":1710021389169,"execution_millis":1008,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"9864637443744404a5bc9c6c2256e82c","deepnote_cell_type":"code"},"source":"# def erase_all_data():\n#     # List of all your table names\n#     table_names = ['google_search_results', 'Papers', 'Query_Papers', 'jobs']\n\n#     # Open a new connection\n#     conn = connection()\n#     c = conn.cursor()\n\n#     try:\n\n#         # Truncate each table\n#         for table in table_names:\n#             c.execute(f\"TRUNCATE TABLE {table} RESTART IDENTITY CASCADE;\")  # RESTART IDENTITY resets serial counters, CASCADE deletes data in dependent tables as well\n\n#         # Commit the transaction\n#         conn.commit()\n#         print(\"All data has been erased from all tables.\")\n#     except Exception as e:\n#         # If an error occurs, rollback any changes made during the transaction\n#         conn.rollback()\n#         print(f\"An error occurred: {e}. Transaction rolled back.\")\n#     finally:\n#         # Close the cursor and connection\n#         c.close()\n#         conn.close()\n\n# # Call the function\n# erase_all_data()\n","block_group":"ae2434ba568f41bb9fb86a583e85188a","execution_count":115,"outputs":[{"name":"stdout","text":"All data has been erased from all tables.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/909ff58e-a004-4de6-b22a-a18b95762f82"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6d52007a-f237-4857-b1f1-3ccb95216ee4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_full_width":true,"deepnote_app_layout":"powerful-article","deepnote_app_hide_all_code_blocks_enabled":true,"deepnote_app_reactivity_enabled":true,"deepnote_notebook_id":"669fac77c2144914ba44f01ac43e97dd","deepnote_execution_queue":[]}}