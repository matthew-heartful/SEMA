{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1709771878501,"execution_millis":83,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"15fdb985f7c742fb9532154af957d9be","deepnote_cell_type":"code"},"source":"","block_group":"15fdb985f7c742fb9532154af957d9be","execution_count":null,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"a01e0112","execution_start":1710020193560,"execution_millis":18,"deepnote_input_label":"Your search query here:","deepnote_variable_name":"input_query","deepnote_variable_value":"ReAct framework for agents","deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"cell_id":"0d12df444d3941ea9782c85b51f6aa9b","deepnote_cell_type":"input-text"},"source":"input_query = 'ReAct framework for agents'","block_group":"e19f0be04c9b49a192fa39a3858da19f","execution_count":50,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"bb9bc971","execution_start":1710020195564,"execution_millis":610,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"15a9423a4f54485497ecb05b9e9158c3","deepnote_cell_type":"code"},"source":"import psycopg2\nimport os\n\ndef connection():\n    \"\"\"Creates and returns a new database connection.\"\"\"\n    try:\n        conn = psycopg2.connect(\n            user=os.environ[\"MY_INTEGRATION_USER\"],\n            password=os.environ[\"MY_INTEGRATION_PASSWORD\"],\n            host=os.environ[\"MY_INTEGRATION_HOST\"],\n            port=os.environ[\"MY_INTEGRATION_PORT\"],\n            database=os.environ[\"MY_INTEGRATION_DATABASE\"]\n        )\n        \n        # Test the connection\n        with conn.cursor() as cursor:\n            cursor.execute(\"SELECT version();\")\n            record = cursor.fetchone()\n        \n        return conn  # Return the connection object if successful\n\n    except (Exception, psycopg2.Error) as error:\n        print(\"Error while connecting to database\", error)\n        return None  # Return None if connection was not successful\n\nconn = connection()","block_group":"35d1b25ccdc845448a6a60cc7807e612","execution_count":51,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"ab60358e","execution_start":1710023420701,"execution_millis":56,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"c2c4c9c84d3f42d78bfa325545dca282","deepnote_cell_type":"code"},"source":"from rich.console import Console\nfrom rich.table import Table\nfrom rich.text import Text\n\ndef display_query_papers(job_query):\n    # Create a console object for Rich output\n    console = Console()\n\n    # Connect to SQLite database\n    conn = connection()\n    c = conn.cursor()\n\n    # Fetch the number of ranks already printed for the given query\n    c.execute(\"SELECT printed_ranks FROM jobs WHERE query = %s\", (job_query,))\n    result = c.fetchone()\n    printed_ranks = result[0] if result else 0  # Use the fetched number or default to 0 if not found\n\n    start_rank = printed_ranks + 1  # Start from the next rank\n\n    # Fetch records for the given query starting from the next rank to be printed\n    c.execute(\"\"\"\n        SELECT * FROM Query_Papers \n        WHERE query = %s AND final_rank >= %s AND final_rank IS NOT NULL \n        AND relevant_answer IS NOT NULL AND paper_stats IS NOT NULL \n        AND paper_metadata_filtered IS NOT NULL AND download_link IS NOT NULL\n        ORDER BY final_rank ASC\n        LIMIT 10\n    \"\"\", (job_query, start_rank))\n\n    # Fetch the column names\n    columns = [description[0] for description in c.description]\n\n    rows = c.fetchall()\n\n    # Counter for the number of ranks printed during this function call\n    ranks_printed_now = 0\n\n    if rows:\n        # Initialize a Rich table with improved formatting\n        table = Table(show_header=True, title=job_query, expand=True, leading=1, show_lines=True)\n        table.add_column(\"No.\", style=\"cyan\", justify=\"right\", ratio=1)\n        table.add_column(\"Paper\", overflow=\"fold\", ratio=20)  # This has twice the ratio of \"Details\", meaning it will be larger\n        table.add_column(\"Details\", overflow=\"fold\", ratio=8)  # Half the 'ratio' of \"Paper\", making it relatively smaller\n        table.add_column(\"Link\", justify=\"center\", ratio=2)\n        for row in rows:\n            # Extract the necessary fields from the row\n            final_rank = row[columns.index('final_rank')]\n            arxiv_link = row[columns.index('arxiv_link')]\n            relevant_answer = row[columns.index('relevant_answer')]\n            paper_stats = json.loads(row[columns.index('paper_stats')])\n            paper_metadata_filtered = json.loads(row[columns.index('paper_metadata_filtered')])\n            \n            # Format extracted data\n            title = paper_metadata_filtered.get('title', 'N/A')\n            abstract = paper_metadata_filtered.get('abstract', 'N/A')\n            abstract = (abstract[:197] + '...') if len(abstract) > 200 else abstract\n            published_date = paper_metadata_filtered.get('published_date', 'N/A').split('T')[0] if paper_metadata_filtered.get('published_date', 'N/A') != 'N/A' else 'N/A'\n            authors = paper_metadata_filtered.get('authors', ['N/A'])\n            authors_str = \", \".join(authors[:3]) + (\"...\" if len(authors) > 3 else \"\")\n            citations = paper_stats.get('citations', 'N/A')\n            versions = paper_stats.get('versions', 'N/A')\n\n            # Add the clickable 'Link' text\n            link_text = f\"[link={arxiv_link}]Link[/link]\"\n\n            # Format the Paper and Details columns\n            paper_column = Text(f\"{title}\\n\\nLLM response: {relevant_answer}\\n\\nAbstract: {abstract}\", justify=\"left\")\n            details_column = Text(f\"Citations: {citations}\\nVersions: {versions}\\nDate Published: {published_date}\\nAuthors: {authors_str} \\n\", justify=\"left\")\n            \n            # Add row with formatted data\n            table.add_row(str(final_rank), paper_column, details_column, link_text)\n            table.add_section()\n            table.add_row()\n\n            ranks_printed_now += 1\n\n        # Update the number of printed ranks in the jobs table for this query\n        new_total_printed = printed_ranks + ranks_printed_now\n        c.execute(\"UPDATE jobs SET printed_ranks = %s WHERE query = %s\", (new_total_printed, job_query))\n        conn.commit()\n    # Print the table to the console\n    if ranks_printed_now > 0:\n        console.print(table)\n    # Closing database connections\n    c.close()\n    conn.close()\n\n    return ranks_printed_now  # Optionally return the number of ranks printed in this call\n\n# # Example usage\n# job_query = \"Top academic papers on ReAct framework for agents\"\n# ranks_printed_now = display_query_papers(job_query)\n# print(f\"Ranks printed this time: {ranks_printed_now}\")\n","block_group":"1ee78ed7927d45708541c2dd376b88e7","execution_count":80,"outputs":[],"outputs_reference":null},{"cell_type":"code","metadata":{"source_hash":"f42be822","execution_start":1710021556345,"execution_millis":709,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"ca5e4b7dbccb46c98171167049eedb67","deepnote_cell_type":"code"},"source":"def add_new_job(query):\n    # Connect to the SQLite database\n    conn = connection()\n    c = conn.cursor()\n\n    # SQL statement to insert a new job\n    c.execute(\"INSERT INTO jobs (query, job_status) VALUES (%s, 'new')\", (query,))\n    print(\"\\nHello there, we're busy working on your query: '{}'.\".format(job_query))\n    # Commit the changes and close the connection\n    conn.commit()\n    conn.close()\n\n# Usage\njob_query = \"Top academic papers on \" + input_query\nadd_new_job(job_query)\nprint(job_query)","block_group":"90e9c9b2cc7140b9900be848b05e99b0","execution_count":56,"outputs":[{"name":"stdout","text":"Top academic papers on ReAct framework for agents\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/089aa433-f436-4ff8-a1e2-4bed69b43ca7"},{"cell_type":"code","metadata":{"source_hash":"cec6ab79","execution_start":1710023429762,"execution_millis":1735,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":true,"deepnote_app_is_code_hidden":true,"cell_id":"a70c2578389e4b14b3a47a0798616c78","deepnote_cell_type":"code"},"source":"import sqlite3\nimport time\nimport datetime  # Import the datetime module\nimport os  # Import the os module for clearing the terminal\nfrom IPython.display import clear_output\n\ndef wait_for_job_completion(job_query):\n    # Connect to the SQLite database\n    conn = connection()\n    c = conn.cursor()\n    counter = 0  # Initialize the counter\n    try:\n        while True:  # Keep checking until the job is done\n            # SQL statement to find the status of a job given its query\n            c.execute(\"SELECT job_status FROM jobs WHERE query = %s\", (job_query,))\n            result = c.fetchone()\n            if result:\n                job_status = result[0]\n                if job_status == 'done':\n                    print(\"\\nThe job '{}' is complete.\".format(job_query))  # Ensure new line before final status\n                    display_query_papers(job_query)\n                    break  # Exit the loop if the job is done\n                elif job_status == 'running':\n                    print(f\".\", end=' ')  # Print counter with \"Running...\"\n                    # clear_output(wait=True)  # Clear output and wait for the next\n                    counter += 1\n                    # print(f\"{counter}\", end=' ')  # Print counter with \"Running...\"\n                    # print(\"\\nThe status of the job '{}' is currently '{}'. Waiting for completion...\".format(job_query, job_status))\n                    display_query_papers(job_query)\n                    time.sleep(1)\n                # else:\n                #     print(\"\\nThe status of the job '{}' is currently '{}'. Waiting for completion...\".format(job_query, job_status))\n                #     display_query_papers(job_query)  # Indented to match the 'else' block\n            else:\n                print(\"\\nHello there, we're busy working on your query: '{}'.\".format(job_query))\n                break  # Exit the loop if no such job exists\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Usage\nwait_for_job_completion(job_query)\n","block_group":"2bf8387b66b34b4986a7603189c6dfd1","execution_count":81,"outputs":[{"name":"stdout","text":"\nThe job 'Top academic papers on ReAct framework for agents' is complete.\n","output_type":"stream"},{"data":{"text/plain":"\u001b[3m                                 Top academic papers on ReAct framework for agents                                 \u001b[0m\n┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mN…\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPaper                                                                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDetails                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mLink \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m 1\u001b[0m\u001b[36m \u001b[0m│ Chain-of-Thought Prompting Elicits Reasoning in Large Language Models │ Citations: 3769            │ \u001b]8;id=885907;https://arxiv.org/abs/2201.11903\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│                                                                       │ Versions: 12               │       │\n│\u001b[36m    \u001b[0m│ LLM response: Paper: \"Chain-of-Thought Prompting Elicits Reasoning in │ Date Published: 2022-01-28 │       │\n│\u001b[36m    \u001b[0m│ Large Language Models\" discusses enhancing reasoning in models.       │ Authors: Jason Wei, Xuezhi │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Wang, Dale Schuurmans...   │       │\n│\u001b[36m    \u001b[0m│ Abstract: We explore how generating a chain of thought -- a series of │                            │       │\n│\u001b[36m    \u001b[0m│ intermediate                                                          │                            │       │\n│\u001b[36m    \u001b[0m│ reasoning steps -- significantly improves the ability of large        │                            │       │\n│\u001b[36m    \u001b[0m│ language models                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ to perform complex reasoning. In particular, ...                      │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 2\u001b[0m\u001b[36m \u001b[0m│ FEVER: a large-scale dataset for Fact Extraction and VERification     │ Citations: 1288            │ \u001b]8;id=167110;https://arxiv.org/abs/1803.05355\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│                                                                       │ Versions: 14               │       │\n│\u001b[36m    \u001b[0m│ LLM response: FEVER dataset introduces claim verification challenges, │ Date Published: 2018-03-14 │       │\n│\u001b[36m    \u001b[0m│ aiding progress in textual source verification.                       │ Authors: James Thorne,     │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Andreas Vlachos, Christos  │       │\n│\u001b[36m    \u001b[0m│ Abstract: In this paper we introduce a new publicly available dataset │ Christodoulopoulos...      │       │\n│\u001b[36m    \u001b[0m│ for verification                                                      │                            │       │\n│\u001b[36m    \u001b[0m│ against textual sources, FEVER: Fact Extraction and VERification. It  │                            │       │\n│\u001b[36m    \u001b[0m│ consists                                                              │                            │       │\n│\u001b[36m    \u001b[0m│ of 185,445 claims generated by altering se...                         │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 3\u001b[0m\u001b[36m \u001b[0m│ HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question       │ Citations: 1613            │ \u001b]8;id=98795;https://arxiv.org/abs/1809.09600\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│   Answering                                                           │ Versions: 9                │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Date Published: 2018-09-25 │       │\n│\u001b[36m    \u001b[0m│ LLM response: HotpotQA dataset enables complex reasoning in QA with   │ Authors: Zhilin Yang, Peng │       │\n│\u001b[36m    \u001b[0m│ explanations, challenging latest systems.                             │ Qi, Saizheng Zhang...      │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ Abstract: Existing question answering (QA) datasets fail to train QA  │                            │       │\n│\u001b[36m    \u001b[0m│ systems to perform                                                    │                            │       │\n│\u001b[36m    \u001b[0m│ complex reasoning and provide explanations for answers. We introduce  │                            │       │\n│\u001b[36m    \u001b[0m│ HotpotQA,                                                             │                            │       │\n│\u001b[36m    \u001b[0m│ a new dataset with 113k Wikipedia-based ...                           │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 4\u001b[0m\u001b[36m \u001b[0m│ ReAct: Synergizing Reasoning and Acting in Language Models            │ Citations: 706             │ \u001b]8;id=71104;https://arxiv.org/abs/2210.03629\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│                                                                       │ Versions: 6                │       │\n│\u001b[36m    \u001b[0m│ LLM response: ReAct framework enhances LLMs by interleaving reasoning │ Date Published: 2022-10-06 │       │\n│\u001b[36m    \u001b[0m│ and acting for better task performance and interpretability.          │ Authors: Shunyu Yao,       │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Jeffrey Zhao, Dian Yu...   │       │\n│\u001b[36m    \u001b[0m│ Abstract: While large language models (LLMs) have demonstrated        │                            │       │\n│\u001b[36m    \u001b[0m│ impressive capabilities                                               │                            │       │\n│\u001b[36m    \u001b[0m│ across tasks in language understanding and interactive decision       │                            │       │\n│\u001b[36m    \u001b[0m│ making, their                                                         │                            │       │\n│\u001b[36m    \u001b[0m│ abilities for reasoning (e.g. chain-of-tho...                         │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 5\u001b[0m\u001b[36m \u001b[0m│ WebShop: Towards Scalable Real-World Web Interaction with Grounded    │ Citations: 110             │ \u001b]8;id=318587;https://arxiv.org/abs/2207.01206\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│   Language Agents                                                     │ Versions: 6                │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Date Published: 2022-07-04 │       │\n│\u001b[36m    \u001b[0m│ LLM response: Academic paper on WebShop tool for agents: Simulates    │ Authors: Shunyu Yao,       │       │\n│\u001b[36m    \u001b[0m│ real-world web interactions for agent training.                       │ Howard Chen, John Yang...  │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ Abstract: Existing benchmarks for grounding language in interactive   │                            │       │\n│\u001b[36m    \u001b[0m│ environments either                                                   │                            │       │\n│\u001b[36m    \u001b[0m│ lack real-world linguistic elements, or prove difficult to scale up   │                            │       │\n│\u001b[36m    \u001b[0m│ due to                                                                │                            │       │\n│\u001b[36m    \u001b[0m│ substantial human involvement in the collect...                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 6\u001b[0m\u001b[36m \u001b[0m│ ALFWorld: Aligning Text and Embodied Environments for Interactive     │ Citations: 204             │ \u001b]8;id=209117;https://arxiv.org/abs/2010.03768\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│   Learning                                                            │ Versions: 5                │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Date Published: 2020-10-08 │       │\n│\u001b[36m    \u001b[0m│ LLM response: Top academic paper on the ReAct framework for agents:   │ Authors: Mohit Shridhar,   │       │\n│\u001b[36m    \u001b[0m│ \"ALFWorld: Aligning Text and Embodied Environments for Interactive    │ Xingdi Yuan,               │       │\n│\u001b[36m    \u001b[0m│ Learning.\"                                                            │ Marc-Alexandre Côté...     │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ Abstract: Given a simple request like Put a washed apple in the       │                            │       │\n│\u001b[36m    \u001b[0m│ kitchen fridge, humans                                                │                            │       │\n│\u001b[36m    \u001b[0m│ can reason in purely abstract terms by imagining action sequences and │                            │       │\n│\u001b[36m    \u001b[0m│ scoring                                                               │                            │       │\n│\u001b[36m    \u001b[0m│ their likelihood of success, prototypicali...                         │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 7\u001b[0m\u001b[36m \u001b[0m│ Check Your Facts and Try Again: Improving Large Language Models with  │ Citations: 208             │ \u001b]8;id=928847;https://arxiv.org/abs/2302.12813\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│   External Knowledge and Automated Feedback                           │ Versions: 2                │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Date Published: 2023-02-24 │       │\n│\u001b[36m    \u001b[0m│ LLM response: Academic paper presents LLM-Augmenter system improving  │ Authors: Baolin Peng,      │       │\n│\u001b[36m    \u001b[0m│ ChatGPT responses with external knowledge.                            │ Michel Galley, Pengcheng   │       │\n│\u001b[36m    \u001b[0m│                                                                       │ He...                      │       │\n│\u001b[36m    \u001b[0m│ Abstract: Large language models (LLMs), such as ChatGPT, are able to  │                            │       │\n│\u001b[36m    \u001b[0m│ generate                                                              │                            │       │\n│\u001b[36m    \u001b[0m│ human-like, fluent responses for many downstream tasks, e.g.,         │                            │       │\n│\u001b[36m    \u001b[0m│ task-oriented                                                         │                            │       │\n│\u001b[36m    \u001b[0m│ dialog and question answering. However, applying LLMs...              │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 8\u001b[0m\u001b[36m \u001b[0m│ MRKL Systems: A modular, neuro-symbolic architecture that combines    │ Citations: 44              │ \u001b]8;id=583930;https://arxiv.org/abs/2205.00445\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│ large                                                                 │ Versions: 2                │       │\n│\u001b[36m    \u001b[0m│   language models, external knowledge sources and discrete reasoning  │ Date Published: 2022-05-01 │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Authors: Ehud Karpas, Omri │       │\n│\u001b[36m    \u001b[0m│ LLM response: Academic paper on MRKL Systems: Neuro-symbolic          │ Abend, Yonatan Belinkov... │       │\n│\u001b[36m    \u001b[0m│ architecture combining large language models with reasoning modules.  │                            │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ Abstract: Huge language models (LMs) have ushered in a new era for    │                            │       │\n│\u001b[36m    \u001b[0m│ AI, serving as a                                                      │                            │       │\n│\u001b[36m    \u001b[0m│ gateway to natural-language-based knowledge tasks. Although an        │                            │       │\n│\u001b[36m    \u001b[0m│ essential                                                             │                            │       │\n│\u001b[36m    \u001b[0m│ element of modern AI, LMs are also inherently limi...                 │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m 9\u001b[0m\u001b[36m \u001b[0m│ ReWOO: Decoupling Reasoning from Observations for Efficient Augmented │ Citations: 27              │ \u001b]8;id=901349;https://arxiv.org/abs/2305.18323\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│   Language Models                                                     │ Versions: 4                │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Date Published: 2023-05-23 │       │\n│\u001b[36m    \u001b[0m│ LLM response: ReWOO boosts ALMs by separating reasoning &             │ Authors: Binfeng Xu,       │       │\n│\u001b[36m    \u001b[0m│ observations, enhancing efficiency & scalability.                     │ Zhiyuan Peng, Bowen Lei... │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ Abstract: Augmented Language Models (ALMs) blend the reasoning        │                            │       │\n│\u001b[36m    \u001b[0m│ capabilities of Large                                                 │                            │       │\n│\u001b[36m    \u001b[0m│ Language Models (LLMs) with tools that allow for knowledge retrieval  │                            │       │\n│\u001b[36m    \u001b[0m│ and action                                                            │                            │       │\n│\u001b[36m    \u001b[0m│ execution. Existing ALM systems trigger LL...                         │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m10\u001b[0m\u001b[36m \u001b[0m│ Keep CALM and Explore: Language Models for Action Generation in       │ Citations: None            │ \u001b]8;id=516962;https://arxiv.org/pdf/2010.02903.pdf\u001b\\Link\u001b]8;;\u001b\\  │\n│\u001b[36m    \u001b[0m│   Text-based Games                                                    │ Versions: None             │       │\n│\u001b[36m    \u001b[0m│                                                                       │ Date Published: 2020-10-06 │       │\n│\u001b[36m    \u001b[0m│ LLM response: ReAct framework for agents: Contextual Action Language  │ Authors: Shunyu Yao, Rohan │       │\n│\u001b[36m    \u001b[0m│ Model (CALM) for text-based games.                                    │ Rao, Matthew Hausknecht... │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│                                                                       │                            │       │\n│\u001b[36m    \u001b[0m│ Abstract: Text-based games present a unique challenge for autonomous  │                            │       │\n│\u001b[36m    \u001b[0m│ agents to operate                                                     │                            │       │\n│\u001b[36m    \u001b[0m│ in natural language and handle enormous action spaces. In this paper, │                            │       │\n│\u001b[36m    \u001b[0m│ we                                                                    │                            │       │\n│\u001b[36m    \u001b[0m│ propose the Contextual Action Language Model (C...                    │                            │       │\n│    │                                                                       │                            │       │\n│\u001b[36m \u001b[0m\u001b[36m  \u001b[0m\u001b[36m \u001b[0m│                                                                       │                            │       │\n└────┴───────────────────────────────────────────────────────────────────────┴────────────────────────────┴───────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                 Top academic papers on ReAct framework for agents                                 </span>\n┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━┓\n┃<span style=\"font-weight: bold\"> N… </span>┃<span style=\"font-weight: bold\"> Paper                                                                 </span>┃<span style=\"font-weight: bold\"> Details                    </span>┃<span style=\"font-weight: bold\"> Link  </span>┃\n┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">  1 </span>│ Chain-of-Thought Prompting Elicits Reasoning in Large Language Models │ Citations: 3769            │ <a href=\"https://arxiv.org/abs/2201.11903\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Versions: 12               │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: Paper: \"Chain-of-Thought Prompting Elicits Reasoning in │ Date Published: 2022-01-28 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Large Language Models\" discusses enhancing reasoning in models.       │ Authors: Jason Wei, Xuezhi │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Wang, Dale Schuurmans...   │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: We explore how generating a chain of thought -- a series of │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ intermediate                                                          │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ reasoning steps -- significantly improves the ability of large        │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ language models                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ to perform complex reasoning. In particular, ...                      │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  2 </span>│ FEVER: a large-scale dataset for Fact Extraction and VERification     │ Citations: 1288            │ <a href=\"https://arxiv.org/abs/1803.05355\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Versions: 14               │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: FEVER dataset introduces claim verification challenges, │ Date Published: 2018-03-14 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ aiding progress in textual source verification.                       │ Authors: James Thorne,     │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Andreas Vlachos, Christos  │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: In this paper we introduce a new publicly available dataset │ Christodoulopoulos...      │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ for verification                                                      │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ against textual sources, FEVER: Fact Extraction and VERification. It  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ consists                                                              │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ of 185,445 claims generated by altering se...                         │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  3 </span>│ HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question       │ Citations: 1613            │ <a href=\"https://arxiv.org/abs/1809.09600\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   Answering                                                           │ Versions: 9                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Date Published: 2018-09-25 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: HotpotQA dataset enables complex reasoning in QA with   │ Authors: Zhilin Yang, Peng │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ explanations, challenging latest systems.                             │ Qi, Saizheng Zhang...      │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Existing question answering (QA) datasets fail to train QA  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ systems to perform                                                    │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ complex reasoning and provide explanations for answers. We introduce  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ HotpotQA,                                                             │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ a new dataset with 113k Wikipedia-based ...                           │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  4 </span>│ ReAct: Synergizing Reasoning and Acting in Language Models            │ Citations: 706             │ <a href=\"https://arxiv.org/abs/2210.03629\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Versions: 6                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: ReAct framework enhances LLMs by interleaving reasoning │ Date Published: 2022-10-06 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ and acting for better task performance and interpretability.          │ Authors: Shunyu Yao,       │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Jeffrey Zhao, Dian Yu...   │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: While large language models (LLMs) have demonstrated        │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ impressive capabilities                                               │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ across tasks in language understanding and interactive decision       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ making, their                                                         │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ abilities for reasoning (e.g. chain-of-tho...                         │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  5 </span>│ WebShop: Towards Scalable Real-World Web Interaction with Grounded    │ Citations: 110             │ <a href=\"https://arxiv.org/abs/2207.01206\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   Language Agents                                                     │ Versions: 6                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Date Published: 2022-07-04 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: Academic paper on WebShop tool for agents: Simulates    │ Authors: Shunyu Yao,       │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ real-world web interactions for agent training.                       │ Howard Chen, John Yang...  │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Existing benchmarks for grounding language in interactive   │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ environments either                                                   │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ lack real-world linguistic elements, or prove difficult to scale up   │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ due to                                                                │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ substantial human involvement in the collect...                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  6 </span>│ ALFWorld: Aligning Text and Embodied Environments for Interactive     │ Citations: 204             │ <a href=\"https://arxiv.org/abs/2010.03768\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   Learning                                                            │ Versions: 5                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Date Published: 2020-10-08 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: Top academic paper on the ReAct framework for agents:   │ Authors: Mohit Shridhar,   │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ \"ALFWorld: Aligning Text and Embodied Environments for Interactive    │ Xingdi Yuan,               │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Learning.\"                                                            │ Marc-Alexandre Côté...     │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Given a simple request like Put a washed apple in the       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ kitchen fridge, humans                                                │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ can reason in purely abstract terms by imagining action sequences and │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ scoring                                                               │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ their likelihood of success, prototypicali...                         │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  7 </span>│ Check Your Facts and Try Again: Improving Large Language Models with  │ Citations: 208             │ <a href=\"https://arxiv.org/abs/2302.12813\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   External Knowledge and Automated Feedback                           │ Versions: 2                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Date Published: 2023-02-24 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: Academic paper presents LLM-Augmenter system improving  │ Authors: Baolin Peng,      │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ ChatGPT responses with external knowledge.                            │ Michel Galley, Pengcheng   │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ He...                      │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Large language models (LLMs), such as ChatGPT, are able to  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ generate                                                              │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ human-like, fluent responses for many downstream tasks, e.g.,         │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ task-oriented                                                         │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ dialog and question answering. However, applying LLMs...              │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  8 </span>│ MRKL Systems: A modular, neuro-symbolic architecture that combines    │ Citations: 44              │ <a href=\"https://arxiv.org/abs/2205.00445\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ large                                                                 │ Versions: 2                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   language models, external knowledge sources and discrete reasoning  │ Date Published: 2022-05-01 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Authors: Ehud Karpas, Omri │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: Academic paper on MRKL Systems: Neuro-symbolic          │ Abend, Yonatan Belinkov... │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ architecture combining large language models with reasoning modules.  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Huge language models (LMs) have ushered in a new era for    │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ AI, serving as a                                                      │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ gateway to natural-language-based knowledge tasks. Although an        │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ essential                                                             │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ element of modern AI, LMs are also inherently limi...                 │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">  9 </span>│ ReWOO: Decoupling Reasoning from Observations for Efficient Augmented │ Citations: 27              │ <a href=\"https://arxiv.org/abs/2305.18323\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   Language Models                                                     │ Versions: 4                │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Date Published: 2023-05-23 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: ReWOO boosts ALMs by separating reasoning &amp;             │ Authors: Binfeng Xu,       │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ observations, enhancing efficiency &amp; scalability.                     │ Zhiyuan Peng, Bowen Lei... │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Augmented Language Models (ALMs) blend the reasoning        │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ capabilities of Large                                                 │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Language Models (LLMs) with tools that allow for knowledge retrieval  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ and action                                                            │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ execution. Existing ALM systems trigger LL...                         │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\"> 10 </span>│ Keep CALM and Explore: Language Models for Action Generation in       │ Citations: None            │ <a href=\"https://arxiv.org/pdf/2010.02903.pdf\" target=\"_blank\">Link</a>  │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│   Text-based Games                                                    │ Versions: None             │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │ Date Published: 2020-10-06 │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ LLM response: ReAct framework for agents: Contextual Action Language  │ Authors: Shunyu Yao, Rohan │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Model (CALM) for text-based games.                                    │ Rao, Matthew Hausknecht... │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ Abstract: Text-based games present a unique challenge for autonomous  │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ agents to operate                                                     │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ in natural language and handle enormous action spaces. In this paper, │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ we                                                                    │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│ propose the Contextual Action Language Model (C...                    │                            │       │\n│    │                                                                       │                            │       │\n│<span style=\"color: #008080; text-decoration-color: #008080\">    </span>│                                                                       │                            │       │\n└────┴───────────────────────────────────────────────────────────────────────┴────────────────────────────┴───────┘\n</pre>\n"},"metadata":{},"output_type":"display_data"}],"outputs_reference":"s3:deepnote-cell-outputs-production/e0698769-7bc3-410f-9085-24997d685016"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6d52007a-f237-4857-b1f1-3ccb95216ee4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_full_width":true,"deepnote_app_clear_outputs":false,"deepnote_app_layout":"powerful-article","deepnote_app_hide_all_code_blocks_enabled":true,"deepnote_app_width":"full-width","deepnote_app_reactivity_enabled":true,"deepnote_notebook_id":"86f0990f6f9e4298bc5338753986dd91","deepnote_execution_queue":[]}}